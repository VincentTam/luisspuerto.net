var store = [{
        "title": "First blog post",
        "excerpt":"This is my very blog post… this post should’ve been a way earlier than it is being, but life is as it is. I was thinking also into change the “featured image” WordPress is offering but I thought that is fine, since we are in America and this is my first post of my American writing period. The photo is New York City if you haven’t notice, so a really good for an opening post from USA. This blog has several purposes. I think that the first one is to practice my writing in English and make me more fluent in the Shakespeare language. Yes, I need to improve. Second one, is try to express myself and to put in black and white my experiences, personal and professional ones. I’m trying to write about myself, my opinions, what I like and what I don’t like (or hate), my hobbies and last but not least my profession. Summing it up, what it seemed as a good idea in the moment I wrote about it, so don’t take it too seriously, perhaps my ideas have already evolve in the moment you’re reading about them. So, what kind of topics can you expect here? Forestry, GIS, remote sensing, LiDAR, science &amp; research, politics, nature, hiking, photography, technology and probably many many other topics that they will come across my mind the future and they don’t come to my mind right now. I usually like to talk and draw comparisons about the countries where I’ve been or lived. So be prepare to read about Spain, Sweden, Finland and Europe in general, and of course USA, specially Oregon where I live now, and NYC, my favorite city in the world. My style of writing around here is going to be really informal, but I’ll try to keep my grammar and style in shape. I’m here to look for a honest conversation. First with myself and then with you. Yes, you, because if it were a conversation just with myself this would be a monologue and pretty boring, so please comment. Since English isn’t my native language, I’m sure I’m going to make a lot of mistakes, typos, grammatical horrors and probably my style is going to leave a lot to be desired. However, you’re there to take care of that, you that hero of the grammar and style. I really encourage you to tell me if you see anything wrong in my writing, Please, I’m here to learn. Returning to the topic of, why I didn’t write earlier? Well, for a lot of reasons. First, I didn’t feel the need, and second, this blog wasn’t ready. Now, today, in this instant, I’m feeling the need to start blogging again and this is good. Currently, I’m with my wife Olalla, in Corvallis (OR) and we are going to be here at least until September, learning. Learning about forest, English, american life and getting new experiences. Isn’t life made of experiences? SEE YOU AROUND! PS1/ You’ll se more New York in September, when we’ll reach there. PS2/ Edit: I’ve edited this on 15 May, to fix some typos and grammar mistakes. ","categories": ["Personal"],
        "tags": ["myself","USA"],
        "url": "https://luisspuerto.net/blog/2017/05/15/first-blog-post/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/hwijjf7rwopgej1nb4zb_img_3773.jpg"},{
        "title": "Back to Joensuu",
        "excerpt":"More or less a month ago we came back from US to Finland. There is no so much to tell about his, but just that the return has been a little bit hard. We returned to an apartment that we have to set in motion again after we were 5 month away. And we have to battle the jet-lag, that it’s really something when you return from US to Europe. For me it wasn’t something new, but that doesn’t make it any easy. We were almost for a week out of the game, not every day, but at least with some minor problem. The third day after the landing for me was the worse, and I even have some dizziness and nausea. All of these was nothing that we didn’t expect, but on top of these was also something else. It was the return to our little street and our little apartment in Joensuu. Don’t get me wrong, we are really and perfectly happy here, and we missed a lot of things while we were in Corvallis (for starters, our privacy, our bed, our TV and entertaining system, our sofa and our kitchen). But, there is no more drama and craziness, and not more great landscape and diverse people, and no more easy understanding of the people surrounding you or spontaneous talking. We came straight to the Finnish fall / winter without almost any transition in the middle. Well, it’s true that we were in NYC for almost two weeks and with the best of the companies we could have expected. A really unforgettable trip that I hope to write about in the future and that it was a great colophon for our trip. However, the weather there and the landscape was even more south that it was in Corvallis.  It was hot and nice, even when we were in the beginning of September, and instead of mountains there were big valleys made of glass and steel. Life, urban life. Now, we are almost in the brink of the dark winter here in Finland, kaamos as Finnish people call it. Not the best to be cheerful and positive about life, since probably until end of November or December we aren’t going to see any snow, which give some bright to the lack of light. The problem for me isn’t the reduce amount of hours of light during the day, but the totally lack of Sun. This country is beautiful when the Sun shines in the sky, even when it’s that low like in this period of the year (it creates a stunning light, really), but the clouds really block almost any hope to see Lorenzo (Lorenzo is the given name we give to the Sun in Spain). This is really depressing, even for me that I come from a really rainy region in Spain. We have to sum up to this, that these last days have been quite something in the Spanish political scene, being almost in the verge of the its greatest political crisis since the 23-F, that attempt of coup d’état Spain suffered little before I was in this world, in 1981. Even the King was on TV, to the astonishment and confusion of some (they thought that Christmas came earlier this year), to the disappointment of others, and the pleasure of many. This time the culprits weren’t a handful of militar personnel that have a old and cheesy vision of Spain, but a bunch of politicians that doesn’t have an idea of what they were doing and the guts of take aside what separate them and sit on the table to negotiate. Not to talk about defend they position in a referendum and debating and developing ideas and stating facts. Anyhow, I think we’ll survive and soon I’ll write more.   ","categories": ["Personal"],
        "tags": ["Finland","Joensuu","myself","thoughts"],
        "url": "https://luisspuerto.net/blog/2017/10/12/back-to-joensuu/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/IMG_0736.jpg"},{
        "title": "Blade Runner",
        "excerpt":"Last Friday, it was the World Premiere for Blade Runner 2049 so we decided to rewatch the 2019 one on Friday night to have all the details fresh and on Saturday go to watch the continuation of the story thirty years later on our local cinema here in Joensuu. I decided to watch the 2D version because I don’t see the point of paying a plus for something that in my opinion doesn’t add anything to the cinema experience. What is more, sometimes it makes the experience even worse if you have to read subtitles. Blade Runner (2019) is one of my favorite movies. It’s a really well told story, that mix a little bit of everything and keep you thinking after you watch it, in other words food for thought. It’s a puzzle, full of details that keep the conversation alive during decades after its release and stirs the discussion up. Over the years, I’ve had several debates with my friends about if Deckard is a replicant or not, the meaning of the unicorn dream and the origami figure, the color and glaze of Deckard eyes in comparison with the other replicants’ eyes…  you can go on and on until you finally realize that is a no point conversation because the ambiguity is there to you enjoy it. It makes you to create your own feelings and connect with the story in a unique and personal way. The interpretation and themes of the movie are endless, as you can read in the wiki article of the movie, as well as in the specific for the themes the movie touch. Some of those themes are:   Human cloning and the rights of those clones. Since those clones are the intelectual property of a company or individual, as a result of genetic improvement, do they have the same rights as humans?  The previous point can be clone, if you excuse the redundancy, for robots and artificial intelligence. If at any point we’ll be able to get birth to a machine that it’s intelligent enough (in whatever quantity we feel it should be), what are the rights of that machine? Does it have entity?  Empathy… Deckard feels empathy for those he hunts down and probably that was the reason because he left the job in the first place.  Love… interracial love, specifically love between a replicant, a thing without rights, and an “alleged” human. We have to take into account that replicants doesn’t have emotions, and it’s something they develop little by little over their life and for that reason they usually have a really short life. The development of those emotions make them dangerous. Deckard is able to develop that felling on Rachel. Is love that powerful?  The sparsity ephemeral1 or how life is too short and not enough. How replicants life in constant fear of dying since they don’t know their conception or expiration dates. Also, the importance of your.  The notion that we are our memories and experiences, and how your personality is developed through them. How do you know that your memories are yours and not someone’s else.  Philosophical and religious symbolism relating replicants with angels and Roy with Nietzsche’s Superman.  Blade Runner’s World is environmentally destroyed and totally globalized. The climate in Los Angeles has change drastically and the population there is a mixture of cultures and languages. Even some of then speak a kind of neolingua or interligua make of different languages.  Souls, eyes and doves. Eyes in Blade Runner are quite important because they are the way that Blade Runner have to identify replicants using the Voight-Kampff test, due to the replicants lack of emotions. Eyes are windows to those emotions and to the soul, implying that perhaps replicants don’t have soul. However, at the end of the movie there is an allegory of Roy’s soul departing from him in a classical christian way of a dove flying to the sky.There are other details that make the movie a masterpiece, from my point of view. One of those details is the light. All the time there is a continuous motion of light and darkness, mostly at apartments (J. F. Sebastian’s and Deckard ones) but also in other places, creating something similar to a chiaroscuro. The other great detail is the music, created by Vangelis, that gives perfect touches of new technological, dramatic and dark future as well as delicacy and magic when necessary. Such as in the love moments or in tear in the rain scene. All of these details make it an almost perfect movie. Perfection doesn’t exist, but some movies as this one are close.   On the contrary, its continuation, Blade Runner 2049, lacks of all of these themes or barely develop or touch them. The only new one developed is the possibility for replicants to bear children, something that would make then more human. The story is more flat or at least, and in my opinion, much more less complex and detailed. No philosophical or religious implications this time, or at least I haven’t perceived them (I can be wrong though). Don’t get me wrong, I don’t think that the new movie is bad at all, but just another Si-Fi movie. I really think that it’s well made and the story is interesting, with some moment where you can literally blow your imagination. I also recognize that it’s really difficult to create a masterpiece every time you get behind of the camera, they are rare creatures in the history of cinema and you are lucky if you can witness or see one every year. Besides, usually there are few movies (or series) out there where the first one is really good and then the following ones are as good or even better. Perhaps some examples are the Godfather’s Trilogy or Nolan’s Batman Trilogy, where in the latter one the second installment is far superior to any Batman movie out there while the other two are also quite good. Anyhow… usually magic is difficult to make to happen and this time didn’t happen.             Update 10th November 2017: When I wrote his post I was looking for this specific work but I could find it… I had it in the tip of my tongue but never came out. Now, it came to my mind like an act of magic. &#8617;       ","categories": ["Movies","Personal"],
        "tags": ["movies","si-fi"],
        "url": "https://luisspuerto.net/blog/2017/10/13/blade-runner/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/blade-runner.jpg"},{
        "title": "Installing Raspbian in a Raspberry without keyboard and external screen",
        "excerpt":"A few months ago we acquired a Raspberry Pi 3 Model 3 in the hopes to play a little bit around with it to learn some Linux and perhaps to use it as a computer to host rStudio Server and run some scripts on it. But things have been little by little been delayed, mainly because we didn’t have at hand a proper monitor nor USB keyboard. So… last week I finally decided to do something with the Pi and started to research if it would be possible to do an install without keyboard and screen… and it turned out that it’s totally possible. First I want to mention that I’m doing this from MacBook Pro with El Capitan installed, and I’m going to install the Stretch version of Raspbian, the last one at the moment. The way we are going to configure Raspbian remotely is connecting to the Pi through SSH (Secure SHell) and we are going to access to the remote desktop using VNC (Virtual Network Computing). Getting ready The first thing you need to do is download the OS image from the Raspberry Pi site, where at least in my case I chose the desktop one, and you should too if you want to have a desktop where you log in later, even if it’s just remotely. To flash the OS in the memory card you can just use Etcher, what makes thinks a little bit easier. You just have drag and drop the unzipped image to the app window and then choose the flash card you want to put the OS in, after you’ve inserted it in the computer. Once you have flashed the card and to make it possible to log in after in the OS from the ssh console you have to create a file named “ssh” without extension in the root of the FAT partition of the card. The FAT partition is the one that you can access from your Mac after you flash OS in the card. You can do it in the terminal using this command: 1$ touch /Volumes/boot/ssh          File named ssh with extension on the FAT partition.  From then on, you just have to put the SD card in the Pi and wait for the rest of the installation to finish, which probably won’t take more than a couple of minutes, and connect the Pi through LAN to the same network you are connected. In my case I connected the Pi to one of my Airport Express, but you can plug it in directly to your router. Connecting to the Pi Now you just have to open terminal and type 1$ ssh pi@192.168.1.XWhere ssh is the command in terminal to establish the ssh connection, pi is the default username in  on Raspbian, and 192.168.1.X is the usual IP the router is going to assign to the IP, being the X a number between 1 and 255 (well actually from 2 to 255, because the 1 usually is the router). Please, be aware that your IP could be totally different and depends on how your router is configure. To find out what are the IP of your Pi you just need to log into your router and check the device list or IP table. Other option is just download an IP scan software (like Angry IP Scanner) and run it on your computer to see the different IPs of the devices on your network. You can also try to establish contact using the hostname instead of the IP, which in this case is like this: 1$ ssh pi@raspberrypi.localThen you’ll be faced with a screen similar to this one.           Login into the Pi using the SSH connection  Where you are going to be asked about adding the key fingerprint of your Pi to your knowhost file of your Mac for secure connections (yes, you want to continue connecting) and then you’ll be prompted for the password of the Pi. The default password is: raspberry. Configuring the Pi Now, you are logged on the terminal/shell of your Pi, and you can start configuring using shell commands. First of all is to login as root user to make things a little bit easier and then enter in the configuration wizard (or software configuration tool) using the command raspi-config. 12$ sudo su # if you want to login as root and don't type sudo in every command$ sudo raspi-config          Raspberry config tool  Now, from here, you can change your password, the hostname, etc as you can see in the screenshot. I recommend you to change your password and leave your hostname as it is, unless you have more than one pi in your network. You should activate the VCN interface, in the Interface Options and set your Localization Options, or at least take a look to check that everything is OK. When you hit Finish. If you want to connect your Pi to your network via wi-fi, you can also do it. You can find more info in this tutorial, but basically you first scan for wi-fi networks. 1$ sudo iwlist wlan0 scanAnd then you edit the wpa_supplicant.conf configuration file with the info of the network you want to connect. 1$ sudo nano /etc/wpa_supplicant/wpa_supplicant.confUsing the previous command you open the config file on nano (a really simple editor) and you add at the end of the file. 1234network={    ssid=\"your wifi network name\"    psk=\"the password for your network\"}To save you press crtl-o and to exit crtl-x. Now you can disconnect the LAN cable from your Pi to the router if you wish and restart the SSH connection using the command exit   and reconnect whether using the new IP that was assigned to the wi-fi connection or again the host (raspberrypi.local if you didn’t change it). Sometimes you need to reboot the Pi, to make it work. You can see the wi-fi config with the following command. 1$ ifconfig wlan0Perhaps, it’s also a good idea update and upgrade the system before you continue. 12$ sudo apt-get update$ sudo apt-get dist-upgradeInstalling the VNC Server When you are done, you can install the VNC server in the Pi. You can find a more detailed tutorial here, but basically you type in the SSH connection: 1$ sudo apt-get install realvnc-vnc-server realvnc-vnc-viewerYou also have to install the VNC client in your Mac, set it up and then log into the Pi using as username pi and as password raspberry or the one you’ve set up.           Remote desktop of Raspberry Pi.            VNC server dialog  There are further configuration you can do in the server-side of the VNC connection, as it’s explained in the tutorial. I would recommend you to activate the experimental direct capture mode to be able to see apps that are directly render remotely (like Minecraft and I believe some of the settings windows). To do that you go to the VNC server dialog in your Pi and you click on the Menu and go to** **Options &gt; Troubleshooting and select Enable experimental direct capture mode.           Menu in the VNC server on Pi  Now you can access completely to your Raspberry Pi desktop and you didn’t need and won’t need a keyboard or an additional screen. Addendum: There is another options to access to the remote desktop of your Pi, that doesn’t need to install any additional software on your Mac, since the connection is carried out by the Finder.app, but they aren’t as optimal as this one that it’s recommended by the official Raspberry Pi documentation. Additional configuration Perhaps you are interested into mount NTFS, exFAT and samba volumes, i.e. hard drives that whether you connect to the USB port or you connect through your local network. The first two things are pretty easy to make it to happen. You just have to type in the SSH console or in the shell on the desktop: 12$ sudo apt-get install ntfs-3g$ sudo apt-get install exfat-fuse          Mounting a usb stick on the Pi  With this you are going to mount more or less any drive you want. Usually drives mount automatically, when you connect them to the Pi, and you can find them on /home/pi/Media/pi. Now please, remember that like in Mac you have you unmount your units - volumes before you extract them from the USB port. You do so you can clip on the eject icon on the top right corner of the desktop. If you wanted to do the same in the terminal or in the SSH console you have to use the command mount  . A little bit more info about how to mount exFAT and NTFS can be found here and here. 12345sudo fdisk -f # this is to list all the volumes availablemkdir /mnt/usb # directory where you are going to mountsudo mount /dev/sda1 /mnt/usb # mounting the unitsudo ntfs-3g /dev/sda1 /mnt/usb # alternative way of mounting if it's NTFSsudo umount /mnt/usb # to unmount the volumeNow, if you want to mount some samba shares you have connected in your network, like in your router or in the Time Capsule, like it’s my case you have to proceed as follows, being aware that you have to create the mounting (point) directory before. 1$ sudo mount -t cifs //192.168.1.X/share /mnt/box/Change the IP for the one of your sharing device and “share” for the path to the volume / hard drive in that device. If the name of the volume you are sharing in that device has a space, you have to introduce \\040 in the spaces. For example is the name of your share is “share with spaces” and you want to mount in the route /mnt/my share you type. 1$ sudo mount -t cifs //192.168.1.2/share\\040with\\040spaces /mnt/my\\040share/Now, if you want to mount any those shares on boot, to make it available all the time for other apps, you have to modify fstab  file. To do that you have to run this command on the shell. 1$ sudo nano /etc/fstabAnd now you add to the end of the file: 1//192.168.1.2/share\\040with\\040spaces /mnt/my\\040share/ cifs user=youruser,pass=yourpassword,rw,uid=1000,iocharset=utf8,sec=ntlm 0 0And as previously you did in nano, to save you press crtl-o  and to exit crtl-x . You have to also tell the pi to wait until the network it’s up to boot. For that you have to run again raspi-config. 1$ sudo raspi-configAnd in boot options you select Wait for Network at Boot. And that’s it, now you have a Raspberry Pi to play around. ","categories": ["Professional","Technology"],
        "tags": ["how to","linux","raspberry pi","raspbian"],
        "url": "https://luisspuerto.net/blog/2017/10/14/installing-raspbian-stretch-in-a-raspberry-without-keyboard-and-external-screen/",
        "teaser":"https://i.imgur.com/b7WS6uG.png"},{
        "title": "Jääkarhut",
        "excerpt":"Yesterday was the first time in while I’ve been in Jääkarhut. It’s a really especial place and quite singular, or at least it’s what I’ve been told. It’s really true that at least the scenery, if the weather is favorable (I don’t mean necessarily sunny), it’s really awe and jaw-droping, as you can see in the header image of the post or in the image below.           Sunset from Jääkarhut bay yesterday.  Jääkarhut is a swimming club in Joensuu that is located in the Southwest part of the city in a bay with a quite narrow access to the Pyhäselkä, which make it a really nice and quiet (what is not quiet in Finland?) place to swim because the water it isn’t insanely cold. Ok, sometimes it’s, but not always. I say that it’s a swimming club because it’s how they define themselves, but the reality is that they are more than that.           Staircase to the avanto in winter.  Jääkarhut means polar bears in Finnish, a name that it’s quite accurate for the club, since the purpose is to swim all year around in the lake, even when the lake is frozen. They even organize competitions. At the end of the jetty there are a couple of hoses connected to a pump that move the water all the time to keep the avanto (a hole in the ice) open during freezing temperatures in winter. You can see jet stream caused by the pump surfacing a little bit in the photo on the right. You have to imagine that temperatures in Joensuu are usually around -10 ºC or -20 ºC in winter months, and they can reach during a couple of weeks less than -30 ºC. On those months are when more pleasurable the experience is. When temperatures are inferior to -10 ºC the water of the lake is warm in contrast with the outside temperatures. You have to think that as a liquid, with a quite compact structure and high density, water needs to lose a lot of energy from its molecules to freeze and for that reason lakes and other water bodies just freeze a thin crust. I say thin because and some point in winter the ice can have more than 40 cm of thickness, and cars can drive over the lakes. The trade-off here is that being more dense, water makes you lose more energy (temperature) and the cold sensation is much more greater than if you are standing outside, even when the water isn’t usually less than 2 ºC and outside it’s -20 ºC. Something that, if I recall correctly, is related to the heat capacity of the matter. But… are we crazy or we have been drinking too much vodka to start swimming in the lake in winter? No, the secret is that Jääkarhut is more a sauna club than a swimming club, at least for me and I think for the bast majority if the mortals around here. At the other end of the jetty there is a big cottage with a really nice sauna and big warm stove that usually heat the sauna until 80 ºC. Therefore, the trick is to go to the sauna and stay there enjoying the warm for 5’, 10’, 15’ or whatever you want to stay and then go to the freezing waters and have a quick dip. That is how most of the people survive. Here, it comes one of the biggest differences between the people who goes to the club. Some of them are real Jääkarhut, polar bears, and go to have a dip before they go the sauna, but others, like me, are Saunakarhut, sauna bears, and usually go to the sauna before we have our first dip in the water.           The entrance to Jääkarhut in winter  Sauna + avanto (or at least a cold shower), is one of the most relaxing things you can experience in your life and I highly recommend it. In Finland, saunas are something really sacred, and almost every building have a sauna, so it’s really customary to have a sauna at least once a week to clean your self. That doesn’t mean that you don’t have a daily shower, as you should, but that you have an extra once a week. However, my biggest reason to go the sauna is the relaxing sensation you have after you enjoy one, even more if you go the avanto and in the particular case of Jääkarhut the social and visual aspects. Usually, you don’t go alone to the sauna, and if you go is perhaps a good place to meet other people and chat. Sauna is a social place for Finnish people as much as the bar, or even more, and it’s where they are more chatty. Besides, Jääkarhut has one of the most stunning views of the sunset and it’s really a pleasure to enjoy it, it the weather permits. I’ll try to write a little bit more about saunas in the future because they a whole universe here in Finland. Returning to Jääkarhut, it’s not special only for all what I’ve already mentioned, but because as a sauna / swimming club it’s really unique in Finland, and as far as we know there is nothing similar in the rest of country. As I’ve mentioned there are millions of saunas in Finland (private and public) and probably at least a hundred, or more, sauna / ice swimming clubs. I don’t really know about a latter figure, but guess that almost every city has something. Nonetheless, Jääkarhut is the only one open to the public completely and that you don’t need to be member of the club to be able to enjoy it. Usually, in other clubs you need to pay a year membership to enjoy the facilities, or at least you have to attend with a member, as a sample. Here, you just need to buy a ticket in the machine inside of the main house and you are ready to enjoy. The price is quite cheap, for Finland, 6€ and you can swim and use the sauna all your want that day. You’ll  have access to the changing facilities too.  However, if you want to enjoy a hot shower after your sauna and swim you have to pay and extra and insert 1 € per 2 minutes of a hot shower.           Me swimming in the “fresh” water.  Another great thing of Jääkarhut is the broad operation hours, it’s usually open until 11 at night and you the ticked machine can be operated with cash (coins) or calling from your phone, it’ll charge the amount in your phone bill, bu you have to have a Finnish number. Also, be aware, that from 10 to 11 PM there is usually held the kuumaryhmä or hot group. Nothing sexual here, not worry. It’s usually when the regulars get together to have an extra hot and humid sauna. As much water you pour to the stove (within a reasonable range) the more humid is the sauna and the head is better transmitted to your skin, even to the point that you can feel a little bit of a scorching sensation. If you are new to sauna, don’t go at that time, you aren’t going to enjoy it at all although the people is really friendly and even sometimes they want to mock and kid new participants. If you want to try the kuumaryhmä, a good tactic is go a little bit earlier and enjoy at least half and hour of normal sauna, to then be introduced to the hot session. Finally, you need to know that the place is not open always. They have an events room in the second floor of the main building that they rent, so check the week before you go just in case there is something going on there. it’s not the first time that I have the dinner of a wedding there or other kind of even. I have to say that be able to hit the sauna after the dinner is a plus. ","categories": ["Personal"],
        "tags": ["Finland","Finnish life","Joensuu","sauna"],
        "url": "https://luisspuerto.net/blog/2017/10/16/jaakarhut/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/IMG_4290-e1508086408810.jpg"},{
        "title": "trash instead of rm",
        "excerpt":"I just discovered that there is a way to send files to the trash instead of just delete them using the shell and I think it’s really useful when you don’t want to totally discard something to the oblivion. I found out about this because I was working on the shell and I needed to remove some files to check if app could work without them. Move or rename them was an option, but I thought that perhaps there were a more efficient way to that and thought that send then the trash was the most efficient way, since from there they could be deleted forever or restored. think I thought that perhaps the command rm    could have some flag or option that send the files or directories you wish to remove to the trash instead of delete immediately them. However, after read a little bit about the topic, I realized that use rm command is a bad idea and practice to send files to the trash. You can read a little bit more about it here and here, but to summarize a little bit, it’s basically not safe. You can get use to use rm    to send thing to the trash and if for a moment you are on other computer or with other username you can delete things permanently. For that reason you can install other commands like trash-cli, and in macOS you can also install rmtrash. On macOS you can install both things using homebrew and in Linux with apt-get  . 123456# On Mac you can install with Brew$ brew install trash-cli$ brew install rmtrash# On linux you can install with apt-get$ sudo apt-get install trash-cliOn the previous links about the commands you have all the options you can implement in both commands. Happy trashing. PS/ You have to be aware that the shell trash is not the same you can see in your desktop or at least I could find them there. Perhaps, further config is needed.           Trashing files.  ","categories": ["Professional","Technology"],
        "tags": ["how to","linux","macOS","shell"],
        "url": "https://luisspuerto.net/blog/2017/10/19/trash-instead-of-rm/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/mac-trash.jpg"},{
        "title": "Backing up your Pi's SD card",
        "excerpt":"I’ve been trying make something work in my Pi, but so far I’ve just messing things up and I had to install Raspbian a couple of times from scratch. For that reason I’ve decided to make a copy of the SD card before I repeat the process and try to figure out what is going on. To make a back up of your SD card using macOS I’ve found two options.   On one hand, you can install dd utility and use a graphical interface to make the backup to happen.  On the other, you can use the dd command [ref.] on the shell to create the backup.If want to try the dd utility you can download it from the site and normally installing it on macOS or you can install it using Homebrew Cask and the following command. 1$ brew cask install dd-utilityBacking up When you executes the dd utility you only have two options: backup or restore a card with an image. Here you don’t have a lot of complication. However, you have to take into account that at least in my case the internal card reader of the Mac doesn’t work with this app in particular, and I need to insert the app in a external usb SD card reader.           dd utility, backup or restore  I did my backup with the dd utility first, but in the end of the process it gave me an error message. I have the back up file in my hard drive and it works, or at least it unzips and I can mount the image. To be sure that everything is OK and I I’m not less without a back up, I decided to do it with the shell commands as it’s explained here. The commands are the following ones: First we use diskutil [ref.] to see all the volumes connected. 1$ diskutil list          List of volumes  Now you just need to choose what are you going to back up and where using the dd command. 1$ sudo dd if=/dev/diskX of=users/YOURUSERNAME/Downloads/SDCardBackup.dmgYou can see that I haven’t used the same path that they use in the linked instructions because using the diskX that represent your SD card. In my case was the number 4, but in your case could be different. dd command doesn’t produce any feedback of how much of the process is left. The only indication that is running is that the prompt hasn’t returned to be the normal terminal prompt. Wait until the process finish and don’t close the window or kill he process. It probably going to take time, much more time that with the previous method. At least in my case it started at 17.48 and it’s 19.22 and it hasn’t finished yet for a 32GB SD card. I think that it check all the sectors of the card and copy them to the backup. EDIT: I got bored of the slowness of the process and I cancel it after a while and try to implement this suggestion about raw volumes. So the code would be like this now: 1$ sudo dd if=/dev/rdiskX of=users/YOURUSERNAME/Downloads/SDCardBackup.dmgRestoring To restore you first have to unmount your SD card. 1$ diskutil unmountDisk /dev/diskXTo following write the image in the SD card with this command. 1$ sudo dd if=~/SDCardBackup.dmg of=/dev/diskXAnd finally you eject the card with using this. Once it has finished writing the image to the SD card, you can remove it from your Mac using: 1$ sudo diskutil eject /dev/rdisk3So… you are ready now to mess up with your Raspberry Pi without worrying. ","categories": ["Personal","Professional","Technology"],
        "tags": ["linux","macOS","raspberry pi","raspbian"],
        "url": "https://luisspuerto.net/blog/2017/10/19/backing-up-your-pis-sd-card/",
        "teaser":"https://luisspuerto.net/assets/images/pages/teaser-default.jpg"},{
        "title": "Trash location in macOS vs Linux",
        "excerpt":"          White trash (oh wait!) on macOS  The other day, I explained that there is a way to send files and folders to the trash from the the shell. Now, I just found out that there are differences between where is located the trash (it’s a folder nonetheless) in macOS and Linux. In macOS, the trash is located in your user’s folder rmtrash   on macOS, since it’s a much nicer and neat command. And easily to understand. On another hand, in Linux, you can only use trash-cli (you can’t get rmtrash   AFAIK), and I recommend you to install from source, as explained in it’s GitHub site, because if you install using apt-get  you are going to get a some kind of an old version without all the commands (trash-restore  was missing). In Linux, you have two trashes when you are operating with trash-cli  on shell. One is your user’s trash and you can access to it on this path /home/$USER/.local/share/Trash . There, you can see two folders files and info. I guest that you already know where are the files and where are the info / metadata of the files. However, if you use the command sudo trash-put  you files are going to be moved to /root/.local/share/Trash (obviously, or not that obvious as we’ve seen in macOS). For the other sudo   before the command. Now, you are ready to trash whatever you want.                                                                                               ","categories": ["Professional","Technology"],
        "tags": ["linux","macOS","raspberry pi","raspbian","shell"],
        "url": "https://luisspuerto.net/blog/2017/10/26/trash-location-in-macos-vs-linux/",
        "teaser":"https://luisspuerto.net/assets/images/pages/teaser-default.jpg"},{
        "title": "Installing PGP signing for Git on macOS",
        "excerpt":"          Only some commits were “verified”  I’ve been committing on Git a lot lately and I’ve been uploading those commits to GitHub. At the same time, I’ve been doing some changes in the repository directly on GitHub and I noticed that the commits that I’ve done in GitHub itself were verified, but the ones that I was uploading from my computer were not. So, I decided to investigated how to “verify” the commits I upload from my computer. Turns out, that GitHub —and I suppose the rest of the online repositories— and Git are able to sign with a PGP key the commits you make to verify your identity against other people. It’s a way to be sure you, and only you, are the one that are committing, thus responsible for the things are doing. If you what to set up the PGP signing is pretty easy in principle, but could have some caveats. To be honest, I struggled with it on the beginning and every time I committed after I set if up in the beginning I got the following message: 12error: gpg failed to sign the datafatal: failed to write commit object          Verified Signature in GitHub  You can check the knowledge base that GitHub has about the topic here. However, I found that some of the topics are perhaps a little bit outdated and doesn’t give you clear directions about how you can really do it. I also checked this sources to get my solution post:   Github : Signing commits using GPG (Ubuntu/Mac)  Git error - gpg failed to sign data  Github GPG + Keybase PGP  Automatic Git commit signing with GPG on OSX  Git Tools - Signing Your WorkHow I’ve done it First of all, you need to install pinentry   for mac. I’ve installed all of them using homebrew. 1$ brew install gpg gpg-agent pinentry-mac Now, you need to created a PGP key runnnig the command: 1$ gpg --full-generate-keyYou can do it also with: 1$ gpg --gen-key However, if you do like the latter command is not going to give you the option to change the key size, as suggested by GitHub. Answer all the prompted questions and be specially careful with your email since GitHub is going to recognize you by your verify email. You can also create a comment to identify the key e.g. GitHut Key. Finally create a passphrase that you can remember, or note down in a password manager. Now, you can have to list all your keys with the command: 123456789$ gpg --list-secret-keys --keyid-format LONG/Users/lpuerto/.gnupg/pubring.kbx---------------------------------sec   rsa4096/&lt;YOUR_LONG_KEY_ID&gt; 2017-11-04 [SC]      349340ARAFKAJHFA93O8024O02JQ9304OQIRF0QUuid                 [ultimate] Your Name (GitHub Key) &lt;youremail@domine.com&gt;ssb   rsa4096/62E5B29EEA7145E 2017-11-04 [E]You have to copy to your clipboard &lt;YOUR_LONG_KEY_ID&gt; , with is your key id, and paste in the following commands to configure you Git with your key. 12$ git config --global user.signingKey &lt;YOUR_LONG_KEY_ID&gt;$ git config --global commit.gpgsign trueYou can certainly not pass the command 1$ git config --global commit.gpgsign truethat configures your Git to always sign your commits with your signature and sign just certain commits with adding the flag pinentry  . You also need to copy your long key id again to get your PGP key with the following command. 1$ gpg --armor --export &lt;YOUR_LONG_KEY&gt;Which print you full GPG key, beginning with ——BEGIN PGP PUBLIC KEY BLOCK——  and ending with ——END PGP PUBLIC KEY BLOCK—— . Copy it and now you can paste it on your GitHub following this instructions. Now, to make it work you need to config pinentry for mac as your dialog to enter your passphrase. To do that you have to use the following command to write pinentry-program /usr/local/bin/pinentry-mac in gpg agent config file. 1$ echo \"pinentry-program /usr/local/bin/pinentry-mac\" &gt;&gt; ~/.gnupg/gpg-agent.confYou can also do it manually. 1$ open ~/.gnupg/gpg-agent.confFinally, you need to restart the gpg agent  doing the following. This is really important and it’s was one of the reason because I took me so long to finally configure Git with the PGP. Since I haven’t restarted the gpg-agent it hasn’t pick up the configuration. 1$ gpgconf --kill gpg-agentIt’s done! I recommend you to test it doing a test commit. First time it should to prompt you with a dialog like this           pinentry prompt  Where, if you tick save in keychain , it isn’t going to prompt you again. Note that if you want to sign commits outside of the shell, not all the apps can sign commits. With my setup I’ve tried Tower and GitHub Desktop and they are able to sign without any problem. Keep  in mind that I’ve committed first in the shell and then I’ve clicked save in keychain  so I don’t know how is going to behave the first time you commit and you haven’t ticked that option or if it’s the first time you sign a commit. In case you had problems with Tower, there are a couple of tutorials out there including Tower:   Signing GitHub Commits  Signed git commits with TowerEnjoy your Git! Note: I’ve follow this setup in Mac OS X El Capitan 10.11.6 and with Git 2.15. ","categories": ["Professional","Technology"],
        "tags": ["coding","git","pgp"],
        "url": "https://luisspuerto.net/blog/2017/11/04/installing-pgp-signing-for-git-on-macos/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/11407107023_b52fa108f7_b.jpg"},{
        "title": "Set rStudio with Homebrew's Git",
        "excerpt":"As I’ll try to explain in the future, I have a full Homebrew R install. I also try to use Homebrew to install as much applications and utilities I can because I think it’s really handy to be able to install or update just with a simple command in the shell. Although sometimes it give you a little bit of a headache, as this time.           Apple vs Homebrew’s Git version  Apple ships with their systems a really to use version of Git, but it’s usually a bit outdated and you can’t update that version —I don’t really know what version they have shipped with High Sierra1. This is usually not a really big deal, since, as you seen in the left picture, the versions aren’t really far away and most of the people don’t use Git in their everyday lives, but if you really need, or want to be, up to-day you are going to need to do some tweaks here and there. First of all, you need to install the last Git using Homebrew: 1$ brew install gitYou are probably going to need to relink by force -f your new Git to make the system to use it. 1$ brew link -f gitKnow if you ask the system, your version of Git have to be different —superior—  to the one Apple provides. In my case and under El Capitan is like this: 123456$ usr/bin/git --versiongit version 2.10.1 (Apple Git-78) # Apple's version$ /usr/local/Cellar/git/2.15.0/bin/git --versiongit version 2.15.0 # Homebrew's version$ git --versiongit version 2.15.0 # System's version, now linked to Homebrew's one.If you are user of rStudio, you’ll probably know that you can use Git in your rStudio projects, as you should, as in any coding project. rStudio developers, to save us with the fuss of installing and configuring Git —and to save them to explain us how, set up rStudio to use the Apple’s Git by default, pointing to /usr/bin/git  in the user settings           rStudio’s version control options  If you want to use your own downloaded Git you just have to change that value in the settings and that’s it. However, it’s a little bit more complicated than that in practice. Since we’re using Homebrew to manage our apps the directory of the app changes every time you update it to show the version it’s storing, just in case you wanted to have more than one version. The path to the directory of Homebrew’s Git looks something like this, as you saw before in a code chuck: 1/usr/local/Cellar/git/2.15.0/bin/gitIf you updated Git using Homebrew, the new path would look something like this. 1/usr/local/Cellar/git/2.XX.X/bin/gitWhere the X are the new version numbers. To make things easier, Homebrew just create symbolic links to the directory /usr/local/bin/  to make the system find the app files. That is what you did when you used the command brew link  and you had to use the flag -f  —force— to overwrite the already existent links to Apple’s Git in usr/bin/git . So, you’re probably thinking that you just have to set the path to Git executable in rStudio to /usr/local/bin/git  and problem fixed. Yes and not. Yes because that is the path you need to end up in settings, but is something you can’t make to happen using rStudio interface. Every time you change the path to /usr/local/bin/git  using the browse button in the settings you are going to end up with /usr/local/Cellar/git/2.XX.X/bin/git  and in consequence when you update Git using Homebrew rStudio isn’t going to be able to find the Git executable. In consequence, you will end up without Git support in rStudio. This happens because rStudio interface follows the symbolic link instead of stuck with the route you set with the browse button. Then… What we should do? You need to open the user setting’s file of rStudio located in a hidden directory in your user folder ~/.rstudio/monitored/user-settings/user-settings  with the following command. 1$ open ~/.rstudio/monitored/user-settings/user-settings          rStudio user setting’s file.  Towards the end of the file, there is a variable called vcsGitExePath  that set your personalized options for the path of Git executable. With your rStudio closed, you can change it in the file to this: 1vcsGitExePath=“/usr/local/bin/git\"and save the file. If you open again rStudio and go to your user settings, the version control settings have to look like this:           Version Control Settings on rStudio.  Now you can update without any problem your Git using Homebrew and it will keep working.           Git’s version in High Sierra              I just updated to High Sierra, and I can confirm that the Git’s version is a little bit more up to to day, but it isn’t the latest. &#8617;       ","categories": ["Professional","RStats","Technology"],
        "tags": ["git","homebrew","how to","RSoft","RStudio"],
        "url": "https://luisspuerto.net/blog/2017/11/05/set-rstudio-with-homebrews-git/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/rstudiobrewgit-1.jpg"},{
        "title": "Updated to High Sierra",
        "excerpt":"          High Sierra update on my machine.  Yesterday, after a hard drive update, I updated my machine to macOS High Sierra. When I tried El Capitan, like almost two years ago, I thought that it was going to be the last OS my Mac was going to run. El Cap, as the Apple employees call it, was a really stable and reliable OS. I loved it, and it really run smoothly in my machine, where I had at that moment a custom Fusion Drive —120 GB SSD + 700 GB HDD, latter I upgrade to 1 GB due to a failure of the original hard drive (after 5 years) . At that moment I thought that any further update would create slowness and lagginess in my machine and after I’ve tried how smooth is a computer with an SSD on it,  I really feel aversion to a slow machine. When Sierra went out I tried it, since I have to install the OS again, but didn’t feel right so I stick with El Cap. Now is the day after I finished the install of High Sierra and the feeling is really nice in general. I think a lot of things are still to settle down —I still have a couple or more mdworkers   hanging around from time to time— so the fans fire up from time to time, but I would say that the felling is even a little bit better than El Cap in some aspects —perhaps I’m subjective and in inside of the new OS hype. It’s true that I am not longer under a custom fusion drive and now I have a full SSD hard drive, and probably that helps, but you have to bear in mind that my machine is a Late 2011 one, 6 years old, and it’s running really really smooth. It’s also true that no longer has the original RAM, but all the rest are the original pieces and still work really well. It seems that even the battery life has improve a little bit after the update. However, I don’t have any stats to prove it. After I updated, I faced a couple of problems, like is normal in what I would say it a quite customized environment. I have to retouch a little bit my custom keyboard layout to work perfectly with high sierra, and I have some problem with a PDF that I don’t know why preview couldn’t visualize. This latter problem caused the QuickLookUIService   to run wild —even at 400%— when spotlight tried to preview that pdf. So I deleted the pdf —I wasn’t interested— and problem solved. So far so good! Good job Apple. PS1/ There were some mdworkers   hanging around consistently even after two days after I’ve installed the new OS —seems that they are not around any more. mediaanalysis   that look what is in your photos to be able to search about them lately. Those processes only work when your computer is idle or you are almost not using it. Interesting. ","categories": ["Professional","Technology"],
        "tags": ["macOS"],
        "url": "https://luisspuerto.net/blog/2017/11/08/updated-to-high-sierra/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/macos_high_sierra_alternative_wallpaper_by_kakoten-dbfgc6m.png"},{
        "title": "Media Buttons Behavior Has Changed In macOS High Sierra",
        "excerpt":"macOS High Sierra has changed the behavior of the media buttons on macOS —AKA those buttons you use to play/stop music or go forwards or backwards. Before, they were reserved to manage music, whether you where playing in iTunes or Spotify, with iTunes having preference (usually). They also worked with some video player. Now, Safari has stolen that preference, and if a video or some kind of media is played in Safari —whether in background or foreground, those buttons are going to control it. In other words, you are playing music in iTunes, you find a video in YouTube that you want to watch, so you hit play and push the play/stop key in your keyboard to stop the iTunes music and be able to listen the video audio, but now that is not he behavior. You are going to stop the video, while the music is still playing. And this is not the worse behavior, some people have reported that they are listening to music, receive a call in the iPhone, ringing in macOS —as expected in the last versions of macOS— and when you press play/stop button to stop the music, you answer the call, while the music is still playing. People isn’t happy.           High Sierra Media Key Enabler for iTunes  Some users have reported that you can fix the issue —or the feature— if you log in your Mac on Safe Mode —pressing shift key when the Mac starts— and use the keys with iTunes and then you return to the normal logging. However, that hasn’t worked for me and I have to say that in my experience iTunes doesn’t behave as they describe. I’m perfectly able to play music on iTunes in safe mode and if I open Safari with a video, the play/stop key behaves in the same way and in normal mode. What I’ve found helpful is this little app called Media Key Enable that someone recommended in Ask Different. It just turn back the behavior as in earlier releases. You can check the project in GitHub if you want. If you’re a Homebrew user you can install it with Homebrew cask: 1$ brew cask install highsierramediakeyenablerIf you are as annoyed as the rest of us for the change in behavior, I recommend you to complain to Apple using  Apple Feedback. ","categories": ["Professional","Technology"],
        "tags": ["high sierra","how to","macOS","tweaks"],
        "url": "https://luisspuerto.net/blog/2017/11/10/media-buttons-behavior-changed-high-sierra/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/File-Oct-17-10-34-21.jpeg"},{
        "title": "The bread story",
        "excerpt":"Anyone close to me, or that’s been hanging out with me for a while, knows that I’m a bakery enthusiast. Ok, perhaps I’m not an enthusiast, but let’s say just an aficionado that like to bake bread and pizza from time to time. This hobby started basically when we arrived to Finland and we brought with us a bread machine that a friend gifted to us. When I was in Spain, and some of my friends and acquaintances were really enthusiastic about bread making and learning about how to make bread, I never understood the point. In general, or at least in my hometown, the bread is really good and quite cheap. I know, really depends where you live and buy your bread and myself have had a really mixed experience related to bread quality in Spain. For me has been quite surprising that in some small villages the bread nowadays is quite industrial and tasteless, where supposedly it has to be more traditional and flavory. I would say that in Ponferrada you can buy a really quite high quality bread almost anywhere, in supermarkets or in bakeries. It’s true that some supermarkets chains prepare themselves the bread using a precooked bread, which give a really fine result few hours after baking it —usually it’s still hot and appealing when people buy is— but after few hours it becomes soggy and unappetizing.           Lild’s bread machine, quite similar to the one we inherited. Source: Wikimedia.  Anyhow, when we arrived to Finland was really hard for us to find bread with similar standards as the Spanish or South Europeans ones —mainly hard and crunchy crust, and fluffy, full of holes (or eyes as we call them in Spain) and spongy interior although firm. Don’t get me wrong, I don’t think the Finnish, or Nordic, bread is bad, but it lacks of certain characteristics that for me make it soulless —it’s almost impossible to dip with it and the olive oil isn’t as tasty. The bread machine, yet it’s a good beginning to begin to bake, it wasn’t any help to reach the desired standard, since the style you usually get with those machines is similar to the common sliced bread —soft crust and interior, and with no eyes or fluffiness at all. In other words, a soft brick. It’s true that you can do a lot of variants with those machines, and add mix different flours or ingredients, but it can’t deliver what we wanted.           Ken’s Book. Source: Amazon.  Therefore, I begin a search to mimic the style my baker deliver to me in Spain. In that journey I came across the Ken Forkish’s book, “Flour Water Salt Yeast: The Fundamentals of Artisan Bread and Pizza”, which I liked from the very beginning, because even the title sounded pretty basic and I wasn’t looking for something really fancy. I just wanted to make simple but tasty bread. Through that book, I learned the basic bread making technique, the basic instruments I needed and from there on I developed my own technique and recipe, more simpler than the one he teaches in the book. Ken uses mainly a dutch oven to bake the bread at home and to mimic the moist created in an industrial oven that provide the bread its hard crust characteristics of the South European breads. Although I really liked the result with the dutch oven —you are going to get a really a perfect boule that cracks from the top, which is really nice— it’s really more complicated than what I wanted. You have to warm up the dutch oven in the oven for around an hour before you want to start baking the bread in it. Then, manage the really hot dutch oven to put the dough in it and reintroduce the whole thing in the oven again. You can burn your hand if you aren’t careful and adds quite a complication to the process. Anyway, I really recommend Ken’s book to begin to bake and learn about the process of making bread. It’s really simple and enjoyable to read, and with tons of diagrams and images to explain to you how to do things. With him, I learned about the different kinds of flours, how to mix the dough with one hand, about the autolyse, the stretch and the folding of the dough to improve the formation of gluten networks, the pincer method of mixing, to measure everything always in weight and in percentages of the whole amount of flour, and or course about my beloved Maillard reaction that is in almost all the things I bake and cook. Because if your bread isn’t brow, I would say dark brown, in other words well baked, you are doing it WRONG. And I can’t stress it more. If your loaf doesn’t have the Maillard reaction isn’t bread, is other thing, probably just harden dough. It isn’t a mater of your taste, but a matter of correct taste. Bread should have a hard and crunchy dark brown crust to give to it the different levels of complex flavor that a perfect bread must possess. I’m not kidding and it’s probably a matter of education to learn how appreciate bread like that.           Ken’s sandwiches. D E L I C I O U S !  When I started to use Ken’s book, four years ago, I couldn’t imagine that at some point I would be enjoying Ken’s products in his bakery in Portland’s Alphabet Historic District.  I never thought that in the future I would be living for a while in the States, and even less in the West Coast, and more specifically in Oregon. I even didn’t realize that his bakery was there until we arrived to Oregon, and thought… “wait a minute, isn’t here were this guy from the book has his bakery?” Besides, and as I said, I’ve never been a crazy guy about baking, and I bake more for necessity than for the pleasure of baking. However, I really like to do something right when I do it, and I can become really obsess with it at some point. Taste matters. When I visited Ken’s place I realized what is perfection. I would say it’s the best bread I’ve ever tried, and it’s well over the average loaf you can find in Spain, and probably in France and Italy. Really high quality and for a really good price, tacking into account you are in the United States.           Me at Ken’s. On the left after we bought a couple of loaves and in the right at the door of the venue.  Sometimes one just can’t be but really surprised of the turns that life takes and you never know where you are going to buy your next loaf of bread, eat you next sandwich or drink you next beer. I’m really proud of my bakery abilities. My grandpa was as professional baker and, although I never baked with him, I think about him almost every time I bake.   You always have to bake very well the bread (get a really good Maillard effect) and the bottom of the loaves and boules have to be also really well-baked. Move them to bake the bottom because the oven get cold under them. In the following days I will try to post my recipes for bread and pizza. I’ll try to be as detailed as possible, but as I said, they are just simplified versions from Ken’s book ones. I really recommend to get Ken’s book to get the full technique and recipes, you are going to learn a lot. Ken has a YouTube channel where he explain different techniques also. See you by the heat of the oven. ","categories": ["Personal","Trips"],
        "tags": ["bread","eating","Oregon","Portland","trips","USA"],
        "url": "https://luisspuerto.net/blog/2017/11/12/the-bread-story/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/IMG_0631.jpg"},{
        "title": "The preliminaries for bread and pizza making",
        "excerpt":"When I started to write this post, it was going to be just my bread recipe, as promised in my previous post. However, as I dug down little my little explaining the basics of bread making, I realize that I’d be better to make a post just explaining the basic of bread and pizza making and then in two other different post explain the recipes. Again, I can’t stress more that if you really want to learn how to bake, you should take a look to Ken’s book, where you are going to be able to learn the bread method as a whole and read the complete recipes. Ingredients &amp; tools What are we going to need to bake bread? Ok, let’s start with the basic tools and ingredients you are going to need.           Tools for baking  Essential tools   An oven —:grimacing: just in case isn’t something obvious or you don’t live in Iceland— and an oven tray. It’s better to use a swallow one.  Oven mittens or something to pick up hot things. You aren’t probably superman or a replicant, so you are going to get your hands burn without them.  A kitchen scale. All the measurements are in grams. No volumes. I’ll explain later.  A big bowl. Thing that the dough usually rises like the double or the triple of the original volume. Better transparent, so you can see what is going on inside. I use a big salad bowl from Ikea when I bake a 500 gr loaf, and a really big kitchen pot when I’m making a kilo.  A container to put water inside the oven. I use a small pyres tray but something made of metal or ceramic also works. You need this to create a sauna in the oven.  A timer or a clock… you need to measure times quite precisely.Recommended tools   A precision scale. This isn’t an essential, but I would say it’s highly recommended. At some point you are going to need to measure quite tiny amounts of salt, and even tinier of yeast. Something in the range from 0.10 gr. to 5 gr. Kitchen scales usually don’t go down to less than 5 gr, and sometimes they lose precision under 100 gr. You don’t need anything fancy, just something than can go under 1 g. —with a readability of around 0.01 gr.— is going to be fine. I have this one now, but you can find tons of then in Amazon or eBay for less money. If you don’t want to have more than one scale, or you want to buy just one  —something understandable— you can just buy the precision scale. Yet, precision scales can’t measure more than 500 gr. —or at least I haven’t found any— which can be fine if you use a container really light to measure the flour. You can also take more than one measure. In other words, if you need to measure 600 gr of flour, you can measure 300 + 300 gr. Anyway, I have two scales, kitchen and precision one because it’s handy.  Parchment paper or what some of us know as oven paper —it is’t the first time I buy paper to wrap sandwiches thinking that it’s oven paper, so be careful, they are pretty similar, but sandwich paper get stuck to the bread and create a mess. It’s not an essential because you can sprinkle some flour over the tray to try to avoid bread to stick to it. However, it’s easier with the paper and It’s easy to find it in any grocery store —in USA was pretty difficult and I ended ordering it on Amazon. If you are thinking to use a baking mat I wouldn’t recommend since the maximum temperature those mats can bear is around 250 ºC, which is the basic temperature you are going use to bake your bread.  A scraper to cut and handle dough and which is really cheap. With it is usually easier to take out the dough from the container where it’s fermenting and if you want to cut the dough to make different loaves or boules it’s going to do the job better than anything.  A kitchen thermometer. The Ikea one is just fine. In the beginning is good to understand about the temperatures, but it isn’t essential. You can use your hand, but not in the oven.  Proofing baskets or bannetons. These are the baskets where you leave the dough when it’s already shaped and undergo its final rise, or proofing.  In general, it is good to have some container where you can leave the dough resting during the proofing, mainly to keep the dough safe —you don’t move or pick up the dough like slime— to save space in your kitchen and help them to reach the desired shape. You can leave your dough resting on the counter over some sprinkled flour or use some container you already have where you’ve sprinkled some flour, if you don’t want to invest in these baskets. However, the final result it’s usually a little bit better if you use a banneton. You can find them on eBay or Amazon. I got mines in eBay and they are just fine.  A rolling-pin or something to flat the dough when you are making pizza. I have a nice wooden rolling-pin in Finland, but if you don’t have one and you don’t want to buy it, it’s fine. You can use your hands to flat the pizza, if you are brave enough twirl it in the air like a real pizzaiolo, or use a bottle of wine or a big bottle of beer. While I was in the USA, I was using a long and straight bottle of beer I thoroughly cleaned and removed the label. It isn’t as perfect as the rolling-pin, but it’ll do the job.  A couple of small or middle size —a liter is enough— jugs to measure water. You can use whatever you want, but I recommend you to use something with a handler and a mouth made to pour liquids if you don’t wan to create a mess. You are going to measure water in gr. over a scale, so you need a container in scale, and a container to pour the water over the container in the scale and  measure the amount. Then you are going to need to pour that water over the flour.Ingredients   Flour — The basic ingredient.  Water — The basic matter of life and the universal dissolvent.  Salt — To make the bread savory and tasty.  Yeast — I normally use natural yeast, but you can use dry instant yeast if it’s easier for you to find it.  Olive oil — Just to make pizza dough. I use Spanish 🇪🇸 extra-virgin olive-oil for almost all my cooking —this isn’t an exception.Ok, as you see the ingredients aren’t really complicated and they are basic things that almost anyone has in their kitchens. Perhaps the most complex thing is the yeast, but you’ll see it isn’t that complicated. Measurements in weigh           Measuring for a pizza  As Ken explains in his book, everything in bakery is measured in mass or weight, and grams are usually the most handy unit. You don’t use volumes because usually are a tricky business even more when you are dealing with something like flour, salt or yeast. Flour can be compress and have less volume for the same amount of matter or mass, in other words more dense. Water can vary its volume depending on the temperature also, and, although the variation usually is really small, you are already using a scale for the flour. You are going to be really precise if use the scale instead of the marks in the water container —if it has any. Salt and yeast, are also tricky things to measure in volume, even more if you use natural yeast, which is like plastic. When I’ve been baking with some people, they usually are really surprised that I try to be as precise as possible working with the scale. So if the recipe call for 500 gr. of flour, I go for 500.00 gr., or if the recipe says 345 gr. of water I measure 345.00 gr. I don’t go a gram up or down and I try to be as precise as possible. The kitchen is a lab, and you should treat your ingredients as chemistry reactives. Baker’s Percentages Everything is also stated in percentages, or as they are called, baker’s percentages. This has more sense that you think and it’s going to be really useful. However, it’s also going to be really confusing at the beginning because often most recipes on internet aren’t stated like that. The reason for that is the amounts of some ingredients, like salt and yeast, are normally so tinny that is handier to use volumes unless you have a precision scale. In spite of that, I recommend you to stick with weights since in the long run the results are going to be better. You have to think that the main ingredient here is flour, whether it is just one kind or a mix of flours. For that reason, all the rest of the ingredients are just expressed as a proportion of that main ingredient, so the mix of the dough is going to reach always the same exact result. OK, this is not always true, and the kind or flour or mixture of flours you are using has a lot to do with your final result. Let’s try to keep things simple for now, and I’ll try to explain a little bit about that later. So, let’s say in our recipe we are using 500 gr. of flour that is our 100%. The rest of the ingredients are just a proportion:   100% of flour: 500 gr. x 100% = 500 gr.  72% of water: 500 gr. x 72% = 360 gr.  10% of salt: 500 gr. x 10% = 10 gr.  0.72% of yeast: 500 gr. x 0.72% = 3.6 gr.Now imagine that for any reason you wanted to make a loaf of 700 gr. instead of 500 gr. Easy peasy:   100% of flour: 700 gr. x 100% = 700 gr.  72% of water: 700 gr. x 72% = 504 gr.  10% of salt: 700 gr. x 10% = 14 gr.  0.72% of yeast: 700 gr. x 0.72% = 5.04 gr.As you see percentages makes your life a little bit easier, and gives you flexibility. Sometimes you are going to want to mix flours to give different flavors and consistency to your bread. Usually those recipes state the amount of flour of each type also in percentages For example. 60% white flour and 40% whole wheat. Then, if you want a 700 gr. loaf you have to proceed as following:   100% of flour: 700 gr. x 100% = 700 gr.          60% white flour: 700 gr. x 60% = 420 gr.      40% whole wheat flour: 700 gr. x 40% = 280 gr.        72% of water: 700 gr. x 72% = 504 gr.  10% of salt: 700 gr. x 10% = 14 gr.  0.72% of yeast: 700 gr. x 0.72% = 5.04 gr.Easy, isn’t it? Anyhow, if you want to learn a little bit more about the baker’s percentage, check Ken’s book or the wikipedia article about the topic. Flour           Finnish flour  I think you have to take into account when you are mixing flour and water is you are going to get different dough consistency —thus different results— depending on the amount of water you are  adding and the kind of flour —or the mix— you are using. It’s not the same to use white fine flour than whole wheat or rye flour. Usually, white fine flours need less water than whole wheat or rye flours, mainly because they absorb less water. Of course, if you mix flours you are going to need something in between depending on the percentage of each flour. I normally use wheat-white-fine-unbleached flour for my baking, which in Finland is called puolikarkea vehnäjauho. I use this kind, perhaps, because in Spain the most widely used flour is the wheat-white-fine-bleached one since most of the people consume white bread, although things are changing. I decided to go with non-bleached because I prefer the taste —less industrial— and the color of the final product —close to the real color of the wheat, white creamy —almost nothing is pure white in the nature. You can go with whatever flour, or mix of flours you want, but keep in mind that if you decided to mix or use other flour than the one stated in the recipe you are going probably to need a little bit of adjustments. In any case, the adjustment could be unavoidable along the road, since even if you are using the same kind of flour, but different brand —or  even vintage, the flour could be different and have slightly different properties. In the past, I used and mixed different kinds of flours, like rye or whole wheat with really good results, but nowadays I mostly use just white non-bleached for bread and pizza. If you want to learn more about flour, I again, recommend Ken’s book. If you live in the Nordic Countries, specifically in Finland, I recommend you this guide that will help you a little bit in your trip to the supermarket. Please, keep in mind that the more gluten content of the flour, the better, since it make the dough more elastic, it can rise better and keep the bread structure more firmly. The problem is that usually the gluten content isn’t stated in the package. I think you can also read the wikipedia article about wheat flour, which is quite informative. Learn as much as possible about the flour you can find where you live; it’s the basic element for baking and that information it’s going to be helpful. Water and temperature Almost any water good for drinking is going to be good for baking. However, take into account that if you use water that has flavor, it’s going to be added to the bread. In Spain, for instance, there are a lot of places where the water is hard —high content in minerals, specially calcium— and they give to the water sometimes unpleasant flavor. Another variable you have to take into account is temperature. Mainly the temperature of the water and the room where the dough is fermenting / raising. For best results during fermentation you usually needs to have everything a little bit over room temperature (21 ºC), about 26 ºC. This means that you have to use a little bit of warm water, like 35 ºC to warm things up when the reaction starts. Here is where you use the the kitchen thermometer, if you have one, but if you don’t, you can use your hand. Remember that your body is around 36 ºC, so if you dip your hand in the water and it feels comfortable for a bath, that means temperature is more or less right. Since I use fresh yeast, I dissolve it in the water although you can mix the yeast and the salt with the dough after you do the autolyse, as Ken’s explain in his book. Keep in mind that as higher the temperature, the yeast reaction is going to be faster, as temperature activate the yeast. So, if you use warmer water, the temperature of the dough is going to be higher, the yeast if going react faster and the total time of fermentation be reduced. However, keep in mind that around ~43 ºC the yeast starts dying. For that reason if the water is too hot for you, it’s going to be probably too hot for the yeast. Yeast           Finnish fresh yeast. Source Wikimedia.  Yeast is the most complex ingredient after flour —or even more complex than flour in some aspects— and one that is quite mystical, since it provide the magic of rising the bread. I don’t going to tell you too much about yeast in the technical side —I’m not an expert— and you can know more, as always, in wikipedia. I think that what you just need to know is that basically yeast is something alive —even when you use dry yeast, when you hydrate it comes to life— and they are from the kingdom of fungi —the same as mushrooms. They usually eat sugars and transform them into other things. In our case mostly gas —carbon dioxide, but if you leave them enough time yeast can also produce alcohol. I normally use** natural fresh yeast** for my baking here in Finland, but perhaps where you live is more difficult to find. Where I was living in USA, I used instant dry yeast since I could find it in almost any grocery store. Later, I found out where was the fresh yeast my grocery store, but was more expensive and less convenient than the instant dry yeast. It’s up to you what yeast you use. Whether you uses fresh yeast, or instant dry, you have to know that: 3 gr. of fresh yeast ≈ 1 gr. of instant dried yeast So, you can convert one kind of yeast into another easily and use the one you have at hand regardless of the kind is mentioned in your recipe. When you increase or decrease the percentage of yeast in the mixture, you usually increase or decrease the fermentation time, in other words, the time you have to wait until the dough fully rises. To calculate this time, you have to take into account also the temperature or the room and temperature of the water you uses for mixing the dough. However, let’s suppose that we work always in standard conditions (21 ºC of room temperature and 36 ºC for the water). In consequence, you can use the amount of yeast you use to adjust the time of fermentation to your necessities. However, you have to be careful and don’t add an incredible amount of yeast to produce a fast or instant bread because your bread could end with too much yeast flavor. The Tables of Bread &amp; Pizza “The Lord Jehovah has given unto you these tables of bread and pizza commandments! For all to obey!” Ok… perhaps not Jehovah. Ken uses 5 hours of fermentation for straight doughs bread which it’s a nice beginning point. However, there are moments when you don’t have the time to wait for a 5 hours fermentation, or that it would suit you better if you can extend the fermentation a little more. For instance, if you want to mix the dough just before you go to bed and bake in the morning. For that reason I developed the below tables. Bear in mind that they are really far from being truly  accurate and they are just a rough extrapolation, but they help me to create an idea of how much yeast I need for the time I want to rise my dough. You can use then, and perhaps you can even develop yours. You can download in pdf in the link above or here. I created them in Numbers App on Mac, you can download the original here. If you want an Excel version you can download it here, but take into account that I just converted them using Numbers so bugs galore. Perhaps, at some point I should try to create a regression equation or something. The technique The technique I use is a little bit different than the one Ken uses; I tried to simplify because I usually shot of time. However, and as previously, I recommend you check his book to a full explanation of the technique. I’m going to try to explain here, and with words, some parts of the technique that I use and some others that I find interesting but I don’t normally use. The autolyse The autolyse it’s just to mix the water and the flour alone and leave like that for about 20 or 30 minutes. The reason to do it is to increase the absorption of water by the flour, making it easier to shape and work with it and prevent the bread from bleach from the action of atmospheric oxygen. I usually don’t autolyse, unless I really have the time. For example, if I going to make an overnight fermentation I sometimes mix the water and the flour a little bit before going to bed. Then, just before going to bed I add the salt and the yeast for a 8 hours fermentation. Another reason because I don’t autolyse is I don’t use dry yeast that it’s easier to add after, since you just sprinkle over the dough. Natural yeast need to be dissolved. The pincer method It’s a way of mixing the dough using your thumb and index fingers to cut the dough several times and then remix it again. You usually do that a couple of times. You can see how Ken do himself in this video. The folding After you have divided the dough with the pincer and mixed it again, you use the folding after the dough has rested a little bit. The folding is basically stretch the dough, without tearing it, to fold it over itself. You usually do that several times and then leave the dough rest for 15 minutes to repeat it again. You do this like 3 or 4 times during the first hour of fermentation. It helps to build up the gluten to provide the necessary strength to support the bread structure. In other words, it helps to make a bread with volume. Again you can see Ken do it himself in this video. I usually don’t do it as thorough and I just do the folding at the end of my dough mixing. It’s up to you if you want to do it or not during the first hour. The rising There isn’t a lot to say here, but just that in the time when the yeast is reacting, and producing the fermentation, so the dough rises. Try to keep the dough at room temperature (21 ºC) for the whole time and remember to cover the dough to avoid the development of a dried crust in the top of the dough. If you aren’t using a container for rising with a lid, like me, you can use a dish to cover because it’s easy to clean in case the dough rises enough to touch the covering —I use a big dish from Ikea and perfectly fits on the opening of the bowl. There are multiple options for covering, from the traditional kitchen towel to the even better with plastic wrap. I think plastic wrap is better because you are trying to avoid losing as humidity as possible from the dough during the rising period, so plastic is a better sealant than a piece of cloth. However, I understand that plastic is not the best for the environment and for that reason I suggest a dish. Shaping and proofing                                                                                                     After the dough has risen —it’s fully fermented— you can remove it form the container where it has been rising and put it on the counter over some sprinkled flour, where you are going to shape it.  Just remember to cover your hands with four to avoid the dough stick to your hands when you are handling it. It’s usually really handy to sprinkle some flour in the the border of the dough to remove the it from the container, where you are going to introduce your hand or the scraper to detach it from the container. With the scraper it’s usually a lot of cleaner and easier than with your hands. The process of shaping the dough isn’t really complicated. I usually pick up each of the corners, after I’ve cleaned any residual flour on the dough, and fold them to the center of the blob. Next, I turn it over and create a ball with the seam on the bottom using my hands to push the edges of the ball under it and stretch the surface of the ball. If I’m going to bake a boule I leave like that, but if I’m baking a loaf I squeeze and stretch the ball to make it cylindrical, but keeping the seam at the bottom. You can see how Ken shape the dough here. After than, I leave it resting in the banneton to undergo the final rise for proofing. The proofing is the way your loaves are going to get their full potential and volume. However, you have to be careful, if you overproof, your loaves are going to collapse over themselves, and if you underproof they aren’t going to develop their full volume.  You can see Ken here checking his proofed loaves. I usually don’t proof the bread too much and perhaps it’s something I should do during more time. Normally I get impatient and I don’t proof more than 20 or 30 minutes —the time the oven gets warm. However, for straight doughs it’s recommended to proof for around an hour. This is really up to you and how much time you have or want to invest in this. You have to mind too, that if you are going to leave your loaf proofing for about an hour, you should keep it inside of plastic bag or cover it in some way, to avoid it to dry and create a hard crust.           Proofing in the banneton.  Almost every good baked —and happy— bread has to have what we call in Spain a smile,_ _or in other words a crack or split. To make that happen, usually you use a razor —or a really well sharpened knife— just before you are going to introduce your loaf in the over to make one or more cuts in the upper part of the loaf. This way, the the loaf rises in the oven it create beautiful splits and cracks. However, I usually don’t score then and I try to leave the seam —the one I made when I shaped the loaf and I left under the loaf while proofing— in the upper part when I put the loaf in the oven. This way, usually —and I say usually because it doesn’t happen always— the loaf creates a natural crack where the seam is when it rises in the oven. It’s up to you so score or not your bread before you bake it. The sauna oven :finland:           Water in a container inside the oven.  If you want to have a crispy, toothy and hard crush in your bread you need to put it on a sauna for the at least the first 20 minutes. OK, wait a minute, bright back that loaf to the kitchen because I didn’t mean literally in the sauna. What I mean is you have to create a lot of humidity inside of the oven. To make that happen I usually introduce in oven, while it’s warming, a heat resistant container with water. This way the oven is really humid when you introduce the bread. There are other several techniques and some of then have been tested here. You can do whatever you want, but the point is to bring humidity inside. I usually remove the container from the oven after 20 minutes if there is any water left on it, so the environment is totally dry towards the end of the baking and you extract all the excess of humidity from inside of your loaves. You don’t want the crumb of your bread soggy. When I started to bake bread I used Ken’s method with the dutch-oven, which doesn’t need to add any water to the oven since you use the own humidity of the dough —the dutch oven is really a small place and with the humidity from the loaf is enough. However, as I’ve explained, in my opinion it’s too complex for a regular baking, and has another drawbacks . So I tried to mimic a professional oven and started to spray water inside with a manual spray from Ikea. The results where really good. However, I felt that if you put too much water over your loaf it loses the capacity to rise. Besides, you have to open the door almost every 3-5 minutes to re-spray and keep the oven humid, in consequence you lose heat every time you open the oven door. However, I think that the optimal approach has to be something closer to what you have in the Finnish 🇫🇮 stove in sauna.  In other words, a container filled with rocks of other similar elements that has a lot of edges, jagged sides and crevices that increase the hot surface exponentially —Iban Yarza says that a deep metallic oven tray filled with screws and nuts could do the job too. Nevertheless, I would also have a container filled with water from the very beginning, to introduce the bread in an already humid environment. Maillard reaction           Maillard reaction in my bread  As I mentioned in my previous post, you have to bake your bread until it’s dark brown because if you don’t, you are doing something wrong. You have to get in your bread what is know as Maillard reaction. Maillard reaction is a well known reaction that doesn’t only take place in your bread, but in almost everything you eat and enjoy, or at least you should, and has been cook. When you create a Maillard reaction what you are doing is adding flavors to your bread due to the degradation of proteins in the outside of the loaf. Besides of adding flavor, you are also adding a different texture to your bread, which your taste is probably going to appreciate. I know that there are people out there that _don’t like dark brown bread _and they prefer to eat white blunt one. As anything in taste, dark brown bread if something you will end up learning how to enjoy, in the same way you learn to enjoy a good wine or beer, or a well made piece of meat. It’s just a matter of education to learn to enjoy and appreciate those new flavors and textures. Remember, if you don’t bake your bread until dark brown, you aren’t baking bread, you are baking other thing. Perhaps, just dried dough. Post baking As you probably know, you don’t try to eat or cut the bread directly after you bake it. You have to leave the loaf resting in racket for at least 30 minutes and I even recommend a little bit more. If you open up your bread too soon you are going to mess up with the last part of the baking and probably the crumb is going to get ruined. You have to think that when you cut the bread and it’s still hot you are exposing the hottest and most humid part of your bread to the outside environment without the protection of the crush. In consequence, it’s going to lose it’s water content quickly and going to get dry and deformed. Don’t open out your bread too soon and be patient. While you wait, you can listen the sound of the cracking crust. Pure music, your bread is singing for you. Final comments This post has been finally much more longer than I wanted and I’m sorry for it, but it’s really difficult to summarize all you have to know in a more brief way. Perhaps you are thinking that you just want a recipe and you don’t need to know how it works. I understand, but as everything in life if you really what to do it right you have to at least have an idea of what is going on. With this post, I’ve tried to do that. You also have to keep in mind that this directions and explanations, are mainly valid for the straight dough kind of baking. If you want to explore other styles like biga or poolish, things are going to be quite different. Finally I can’t but again recommend you to check Ken’s book, which I think it’s perfect to start baking, have a deeper understanding of all the processes, learn about another styles of doughs and to have a really simple recipes from where you can create your own. As Ken recommend in the book, I also encourage you to experiment and try to change little by little the proportions and add different flours. If you speak Spanish, and you are interested in the Spanish style bread, I recommend you Iban Yarza’s book, which is a classic among the baking enthusiast in Spain. Almost anyone that makes his own bread in Spain has this book in their bookshelf. I promise that my next post is going to be the recipe, and shorter. ","categories": ["Personal","Recipes"],
        "tags": ["bread","how to"],
        "url": "https://luisspuerto.net/blog/2017/11/16/the-preliminaries-for-bread-and-pizza-making/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/IMG_4380.jpg"},{
        "title": "My bread recipe",
        "excerpt":"Ok… as I promised in my previous post, here it’s my bread recipe for straight dough. I’m not going to fully explain the techniques, since they are already explained in the earlier post. There, you can also find what tools you need and, in case you want to change the ingredients quantities, the tables for bread and pizza. For this recipe, I’m going to make a 4 hours rise / fermentation bread, but as you know, you can change the proportion of yeast in your dough to change the rise time. The proofing time is around 40 minutes and the total baking time is around 40 minutes. This gives us around 6 hours in total of preparation, if we take into account the mixing and handling of the dough. The temperature of baking is 250-270 ºC —depending on the oven and how brown you want to your bread. Ingredients   Flour: 500 gr. 100% of wheat-white-fine-unbleached flour or puolikarkea vehnäjauho in Finland.  Water: 360 gr. 72%  Salt: 10 gr. 2%  Yeast: 6.00 gr. 1.20% of natural fresh yeast for 4 hours fermentation. Directions   Measure 500 gr. of flour and put them in your mixing bowl with the 10 gr. of salt.  Measure the 360 gr. of warm water (~36ºC) and dissolve on it the 6 gr. of fresh yeast with a spoon.  When the yeast is fully dissolved, you can pour the water on the flour.  You can start mixing, using the pincer method and when the ingredients are fully mixed you can proceed with the folding.  Leave the dough fully rise for 4 hours in a covered container.  When the dough is fully risen, you can use the scraper to remove it from the container and drop it over the counter where you previously have sprinkled some flour.  Shape the dough as explained in the previous post.  Leave for proofing for at least 20 — 30 minutes, but remember that the recommended time is about an hour. Don’t forget to put into a plastic bag or cover it if you are going to leave it for an hour.  Remember to preheat the oven with the water container inside it before your loaf if fully proofed.      When the dough has finally proofed you can drop the loaf over the oven tray with the parchment paper and introduce it in the oven.      Keep the water container inside of the oven the next 20 minutes.  After 20 minutes, remove the water container if there is any water left in it and bake for another 10 min.  I usually at this point take the loaf out of the oven and flip it over quickly down side up and reintroduce it in the over for at least another 20 min. I want the bottom my loaves really well-baked. This way to get a really uniform dark brown color across all the loaf. Remember to pick up your loaf with the kitchen mittens if you don’t want to burn your hands. The loaf is really hot.  After 10 min. —or when you have reached the desired dark brown color— take out of the oven and put over a rack, if you have one, or something that allow the heat and the humidity to disperse. If you haven’t bake the loaf with the rack of the oven inside, that rack is usually fine.  After 30-40 min you can enjoy your bread.          Final result  ","categories": ["Personal","Recipes"],
        "tags": ["bread","how to"],
        "url": "https://luisspuerto.net/blog/2017/11/17/my-bread-recipe/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/IMG_4384.jpg"},{
        "title": "Pizza recipe",
        "excerpt":"Since it’s Sunday let’s have some pizza for dinner. Here is the pizza recipe I usually make at home, and what I would call our standard pizza. It’s really rare that we don’t bake one once per week or at least two weeks. In the same way as with the bread, you can read about the basics of the bread technique and find out a little bit more about how to bake in this post. Just remember that in addition to the normal baking tools and ingredientes you are going to need olive oil and a rolling ping to flatten and stretch the dough. The latter isn’t really necessary, but if you like really thin pizza you are going to need something —anything— to flatten the dough. Besides that, you are going to need whatever you want to put as toppings. However, you have to keep in mind that you shouldn’t put a lot of topping over the dough for two reasons. First, because the principal ingredient here should be the dough. The final flavor has to be a combination of everything you put over the dough plus the dough, not just the toppings. If you can’t taste the dough you are doing something wrong and you’ve put too much toppings. Second, because if you load the dough with too much toppings you aren’t going to be able to bake the dough. Anything that you put in the oven is going release water, in the case of vegetables, or fat, in the case of meats. All of that released water is going to end up in the dough and it’s going to slow down the baking and if you increase the time of baking you can end up burning everything. It isn’t the first time I get too excited about to put my favorite ingredients with the result of cooked ingredients but a half backed dough. You also have to know that pizza shouldn’t be baked too much —just a little bit of Maillard reaction in the crust and that’s it, the rest of the pipe has to be soft. Pizza isn’t supposed to be hard like a cookie.           Pizza in a traditional oven. Source Wikimedia  Pizza usually is traditionally baked a really high temperature (~500 ºC), much higher that the bread, and in short time (90 seconds) —at least the Neapolitan pizza. The key is to get baked the base, but not cook to much the toppings, to keep the moist on them and in the base. Yet, usually commercial home ovens aren’t able to reach that high temperature. I usually set the over for around 275 ºC that it’s more or less the maximum. In my oven the maximum is 300 ºC but I’ve put an oven thermometer inside once and it wasn’t able to reach that temperature and it stabilize around 275 ºC. So with that temperature we are going to need to bake our pizza for around at least 9-10 min. It really depends in the amount of toppings you put and what kind. I usually bake it for around 12 minutes. The key is to have a crispy and brown crust and a melted and a little bit brown in some spots mozzarella. Also, is good to have a fully baked base with some brown spots on it. Anyhow, use your judgement to get the result you really want. Some people like to bake their pizzas at home in a pizza stone or similar. They also bake bread there. I plan to make a small note in the future about my experience baking in a stone, but to sum it  up a little bit, it makes things a lot of more complicated and the final results aren’t as better than when you bake your pizza of bread in a regular metal tray. I wouldn’t recommend it, and even less in the beginning. So, to wrap it up. We are going to mix pizza dough and we are going to leave it rise for around 4 hours. Then, we are going to proof it for around 20 minutes and we are going to bake it for around 10-12 minutes at 275 ºC. This gives around a total of 5 hours if we take into account the mixing, the flattening of the dough and the topping. Ingredients Dough for the base   Flour: 160 gr. 100% of wheat-white-fine-unbleached flour or puolikarkea vehnäjauho in Finland. In the case of the four for pizza the general rule is as finer the better and it’s commonly said that you have to use double cero “00” flour. Anyhow, and again, is a mater of taste and where you live. I’ve tried the pizza flours you can buy here in Finland, or at last in my local grocery store, and I have to say they aren’t anything fancy, more the contrary. As a rule of thumb, I would say that any really fine and white flour is going to do the job for you.  Water: 112 gr. 70%  Salt: 3.2 gr. 2%  Yeast: 1.44 gr. 0.9% of natural fresh yeast for 4 hours of fermentation.  Olive oil:  A dash… I don’t have a defined amount and I just eyeball the thing.Toppings   Tomato sauce: I use normal tomato sauce to which I add oregano and basil, but you can use whatever you want.  Oregano and basil: to add to the tomato sauce.      Fresh mozzarella cheese:  ~100 gr. I usually pick up a block of fresh mozzarella for pizza  of around 400gr. and I cut in four. I use one of the pieces and I freeze the rest of the pieces wrapped in aluminium foil, since mozzarella is something that easily get spoil. To use the frozen pieces I usually thaw them slowly, or if I’m in a hurry I put them in warm water. They are usually ready in an hour. You can use the already cut one if you prefer, I sometimes use that because it’s handy. Also keep in mind that although you can use fresh mozzarella for salad, the results aren’t going to be as good as if you use the special for pizza’s one.     White mushrooms: ~250 gr. Perhaps a little bit less. Keep in mind that if you put too much they are are going to release a lot of water. Be cautious.  Bacon: 4 slices, it’s more than enough. Think in the same way as with mushrooms, if you put too much, there is going to be a lot of fat and the dough isn’t going to get cooked.  Olives: I love olives so I put some if I have them at hand.  Big capers: The same with caper, I really like them, but I usually prefer the big ones instead of the small. Somehow they taste different to me.          Big and small capers.  Directions   As in the same with the bread, we measure the flour (160 gr.) with scale and put in on the container where the rising in going to happen.  Measure the salt (3.2 gr.) and put with the flour.  Measure the water warm water (112 gr. at ~36 ºC) and dissolve the yeast on it (1.44 gr.).  Pour the water with the yeas with on the flour with the salt and add a dash of olive oil.        Mix everything thoroughly and leave it rising for 4 hours at room temperature (21 ºC). If you have your mozzarella frozen, it’s a good moment to take it from the freezer and thaw it. Remember to cover the dough while is rising.           When the dough is fully risen, you take it from the container and drop it over the counter where you have sprinkle some flour. There, in the same way as with the bread, you shape a ball and leave it proofing over the counter for around 20 min. You don’t need to cover them since it’s going to be just 20 minutes. However, if you are going to make more than one pizza, perhaps is going to be worth to take the third and the fourth ball to the fridge to slow a little bit the proofing and to keep the moisture. The best is to put them in a container, cover them and put in the fridge.       While the ball is proofing is the moment to prepare your toppings and warm up the oven. Slide your mushrooms as fine as possible and take your mozzarella and slide then too, if you are using fresh mozzarella in a block. I usually cut the bacon in four pieces and cut the big capers in four pieces too.  When your ball is fully proofed you take it and turn around and push it with your fist on the seam. Now you take your rolling pin, over which you have also sprinkled some flour, and begin to flatten the dough. I usually try to make it square, since my tray is square and I want to use the full tray, but you can shape it round if you prefer something classic. Use as much flour you need to avoid your dough to get stick to the rolling pin and to the counter. I usually apply the rolling ping a couple of times and then put more flour on the dough to turn it around apply more flour and the other side and then use the rolling pin in that side. I do that until the dough has been stretched and flatten enough that it’s slightly bigger than my tray.      When the dough is stretched enough I pick it up with my hands and put in on the tray with the parchment paper. There, I extend to the full size of my tray and with the scrapper I cut the parts that overflow the edges of the tray. You can use a scissors if you prefer, but I think with the scrapper is easier.         Now, you can begin you apply your toppings. First, a really thin, but really thin, layer of tomato sauce. Then, I apply the oregano and the basil. Next, the mozzarella slices, and after that the mushrooms. Finally, I put the bacon over the layer of mushrooms and I add the olives and the capers.         When you are happy with your toppings, you introduce your pizza in the oven for about 10-12 minutes. Towards the end, you should assess if you want to take it earlier from the oven or if you want to leave it a couple of minutes more. But, be really careful. At 270 ºC things go really fast and in a matter of a couple of minutes things can get scorched easily. If there is a lot of moist over the dough, you are right, you put too much toppings.         When you are happy how your pizza look, take it out and place it over a wooden cutting table, or somethings like that to proceed to cut it. Don’t leave on the tray because you want it to stop baking and don’t cut it in the tray because you don’t want to scratch your tray.        Enjoy your pizza!           Pizza ready to be eaten  This is just an idea for a basic pizza with a basic toppings, but you can be as creative your want. I sometimes make a smoked salmon one with pesto and my mom likes a lot to put seafood like mussels, claps and shrimps. The only forbidden ingredient is pineapple. ","categories": ["Personal","Recipes"],
        "tags": ["bread","how to","pizza"],
        "url": "https://luisspuerto.net/blog/2017/11/19/pizza-recipe/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/IMG_4377.jpg"},{
        "title": "About baking stones",
        "excerpt":"As I promised, here is a small note about my experience using baking stones and some things I think you should take into account if you decide to use one. First of all, I think, if my memory doesn’t fail me, that I have used just one baking stone and it broke as a cause of the heat —while we were baking a pizza some pieces of the stone started to fall from the rack, creating a interesting scorched mess in the bottom of the oven composed of stone pieces, pizza dough, tomato and mozzarella. Until it broke, I use it extensively to bake pizza and bread. Now, what do you have to take into account when you are baking over a stone, and what are the pros and the cons? Pros   I think that the only pro you have when you are baking in a stone is the final result. Usually the stone is somehow porous and it pulls the moist of your dough which allow you to have a crispier results in your bread and pizza. Even more, in a place quite complicated as the bottom of the pizza or the loaf that it isn’t in direct contact with the hot air of the oven. Probably the results are going to be closer to a professional oven .Cons   Warm up the stone is going to take more time that just warm up your oven. A minimum of 30 minutes, ranging as a normal time almost 1 hour. By no means you should put your dough over a not-enough-hot stone because you’re going to get the opposite effect. The bottom of your pizza or loaf if going to be under-baked.  You no longer going to be able to work on tray and you need to work on your pizza over a pizza / baking peel. Perhaps it’s something appealing for you, since you are going to look like a real baker, oh yeah! But it’s something that takes practice to master. Besides, it really limits the size fo your pipes and loaves. Usually the peels you are going to find aren’t going to be as big as your tray. The size of your pizzas is going to be reduced.  In the same way that you need to warm up your stone, you need to cool it down. If you take your stone from the oven too soon if can break due to thermal shock. Even when you are careful, your stone can break, like it happened to me. This cripples a little bit the capacity operation of your oven, extending even in two hours your normal baking time.  The results are good, but they aren’t, at least in my opinion, incredible good that justify all the fuss and the price. I get really good results with my regular metal tray, and in some cases, I would say that even better than with the stone, since I have more experience that before. Before you decided if you want to give a try to the stone, I would recommend to master your technique.  Although the purpose of the stone is to get more crispier result, since the stone pulls the moist of the dough, it going to get colder than the rest of the oven by the effect of the dough. In other words, where you put the loaf to get baked, it’s going to get colder. to avoid that, my grandpa —who was a professional baker— always told me that you have to move your loaves towards the end of the baking to a spot where there wasn’t a loaf previously. I guess that in the modern industrial ovens it’s less of problem since those are more powerful —and electric— than the previous and lumber heated ones that my grandpa was using. Anyhow, you are going to probably find this problem too in your home oven, and this is the reason because I take out the loaf and turn it over bottom up for the last 10 minutes of baking. I doubt you have a stone and oven so big that you are able to move your loaf around in the oven, so you are going to probably do as me. The stone is going to make this process slightly more difficult.  It’s somehow dirtier. You aren’t going to be able to use parchment paper anymore. I’ve seen some setups that use it in combination with the stone, but in my opinion you can’t use both. The parchment paper will stop the stone to take the moist of your dough while baking. If you bake just bread probably it’s going to be ok, but it’s quite often that you some ingredients fall over the stone when you are baking it. Even more if you need to use the peel to take it in and out.Considerations As you see… I’m not a big fan of baking stones although I recognize its appealing since they make things closer to the real thing. They aren’t cheap either and good ones could be really expensive, around 50 to 100 €. Besides, they are really heavy and delicate. In my opinion they are something that if you decide to use better to be a good on, thus you are going to expend money on it. I recommend you to think it over really carefully. If you really want to give it a try, I think that the stone as thicker the better —it takes also more time to warm up and cool down— and that the tiles are a better solution than a really big stone since they more adaptable, easy to keep and probably as a result of their size some less dilatation and contraction, thus they be less prone to break. However, take into account that I never ever I’ve used them, so it’s just a guessing. That’s my two cents about baking stones. ","categories": ["Personal","Recipes"],
        "tags": ["bread","opinion"],
        "url": "https://luisspuerto.net/blog/2017/11/19/about-baking-stones/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/Pizza_on_stone.jpg"},{
        "title": "Homebrew",
        "excerpt":"In some of my previous post [e.g. 1, 2, 3 or 4 ] I’ve been using Homebrew to install some pieces of software in my Mac using the terminal, or shell. But, perhaps you’ve been wondering what is exactly Homebrew? It defines itself as “the missing package manager for macOS”. Yet… what is a package manager? A package manager is a small piece of software that helps you to manage other software —packages— in your computer, or in other words, to install, update, setup and uninstall software. Package managers have been a classic in most linux distributions and most linux users are accustomed to the idea to install software through them, whether on a GUI (graphical user interface) or just on a CLI (command line interface). You as a macOS user probably are also used to a GUI package manager, the Mac App Store, that allow you to install Apps easily and keep it updated. It doesn’t uninstall it for you, or clean the config files, though. However, you usually need more software that the one you can find in the Mac App Store, and even more if you are a bit of an advance user. For example, you probably need to install Java, Flash, Git, R (the stats software) or other apps that aren’t available on the Mac App Store for different reasons. To manage that software and apps Homebrew was created.           List of all my installed formulas  Homebrew is a really simple thing, it’s just a Git repository full of Ruby scripts that you download to your machine and they install, update or uninstall the software with a given set of parameters or options that user can set. Those scripts are called formulas in the Homebrew terminology —as you soon will discover, Homebrew terminology is everything about beer. You can easily install Homebrew using your terminal with the following command. 1$ /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"From there on, you can start to use Homebrew in the same way as any other command on terminal. To use Homebrew you just have to type info if you want more info about it. Homebrew install itself on the folder /usr/local/Homebrew and it’s going to install your software in the folder /usr/local/Cellar.           The Cellar of Homebrew  When you install a formula with Homebrew, it usually creates symbolic links to the folder /usr/local —usually to the /usr/local/bin. but it could create more links to other folders there— to make that software available to the whole system. However, there are some formulas that aren’t linked to /usr/local and they are considered keg-only, or in other words, they are there just to be used for other formulas as dependencies. You can change that, though, and link it manually with brew link. Sometimes when you install a formula with Homebrew, you need to link it manually and/or force the linking, just because your system has already a symbolic link on /usr/local/bin for that same software but not manage by Homebrew. Like with the Git case. 1$ brew link -f formula-name # -f is a flag to force the linking in case there were already a symbolic link on /usr/local/binWhat are the advantages of using Homebrew? Mainly that you can forget about download any software yourself and keep it updated manually. Now, you just can download and install your software with a simple command on your terminal, and update or uninstall it. After you install Homebrew you just need to type this in your shell to install a formula: 1$ brew install formula-nameBut you probably are wondering… How can I know the name of the formula I want to install? It’s quite easy, most of them are really intuitive, like for example Git one. 1$ brew install gitSome other aren’t that easy, but Homebrew has a search engine included. 1$ brew search formula-nameAnd of course, you can look on internet for them. There are even some websites that are specialized on formulas, like http://brewformulas.org. One of the advantages of Homebrew is you can install more than one formula at once, and you can even create shell scripts to install, uninstall or configure several formulas. If you want to install more than one formula, it’s pretty easy. 1$ brew install formula-name-1 formula-name-2 formula-name-n ...Another advantage of Homebrew is you can also choose how to install your software and you can even compile yourself from source code. If possible, Homebrew is going to install in your system a bottle by default, the binaries of the already compiled software. Yet, you can ask Homebrew to download the source code and compile it in your computer. Compiling has advantages and disadvantages. The main disadvantage is that it takes time, for some packages up to half an hour or more to compile, really depends on your machine. Also takes resources. On the other hand you can really personalize your install and the software, giving you fully control of the software you install in your computer, giving extras from the original or standard install. Even you can install software that is under development or it isn’t available for Mac yet. For example, I have a full Homebrew R install that allow me to have the last version of R before is available for Mac in CRAN. Since I’ve compiled it myself, I’ve compiled with OpenBLAS which make R a little bit faster. I’ll try to make a post soon about my installation of R and how to do yourself one. Finally one of the best things about Homebrew is you can update all the software installed with it just with one command. Ok, the true is you need two, but you can chain them on just one. 1$ brew update &amp;&amp; brew upgradeThe first command is to update the list of formulas you have available in the Homebrew repository and download to your computer. It’s basically a upgrade, what you are doing is comparing the formulas you have installed with the Homebrew repository ones. If there is new versions of the formulas you have, Homebrew will installed them for you. Besides of formulas, kegs and bottles, Homebrew has also taps. Taps are third-party repositories additional to the core Homebrew. I think that the most famous one is Homebrew-Cask caskroom/cask. Cask allows you to install GUI apps that are installed in /Applications folder of your Mac. To install Apps with cask is very simple. 1$ brew cask install cask-nameThere are several other taps you can add and most of them are to add functionalities or are thematic, like for example homebrew/science for formulas related to science packages or osgeo/osgeo4mac for formulas related to geography and GIS. As you’ve noticed the name of the taps are somethings like this: some-name/some-name. The reason for that is because taps are GitHub repositories by default although you can tap any git repository, even local ones, so the tap names correspond to github-username/repository. Therefore, and through this simple mechanism, you can create your own taps and share them with anyone, and, conversely, add anyone taps. For example I’ve installed a tap that adds functionalities to Homebrew-Cask, since the update capabilities aren’t as great as with homebrew/core. The name of this tap is buo/cask-upgrade and you can check the repository here. With the original Cask functionalities you can only know which casks are outdated using brew cask outdate and force brew to “update” each of them with: 1$ brew cask install -f cask-formula-name # -f to force to force the install of the new versionHowever if you use buo’s tap you just need to type: 1$ brew cuand that’s it. You can even add the flags -a and -y to autoupdate and to not ask questions. Yet, you have to be aware that some people on the team of homebrew cask doesn’t like buo’s tap or at the very least they think it has some caveats. So be careful when you implement it.           brew cu on my machine  There are more commands you can use inside of Homebrew and Hombre-Cask. You can find more documentation about Homebrew here, and about Hombrew-Cask here. I don’t want to finalize without sharing with you the line I use to update and upgrade my Homebrew. 1$ brew update &amp;&amp; brew upgrade &amp;&amp; brew cleanup &amp;&amp; brew prune &amp;&amp; brew cu -ay &amp;&amp; brew cask cleanupYou already know the purpose of prune deletes the unnecessary symbolic links. Happy brewing :beers:! ","categories": ["Professional","Technology"],
        "tags": ["homebrew","how to","macOS"],
        "url": "https://luisspuerto.net/blog/2017/11/21/homebrew/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/homebrew.jpg"},{
        "title": "First Heavy Snowfall",
        "excerpt":"Last Sunday we had the first heavy snowfall of this winter season in Joensuu. As you can see in the photos in flickr gallery below, the landscape was really wonderful… quite like a postcard. Olalla and I decided to go outside after our late brunch and take a walk over the fresh snow to shoot some photos. It was a quite nice walk, also rather cold. The temperature was around zero, nothing compare with what we have ahead of us (probably -30 ºC). We welcomed the snow, not only because it’s beautiful, but because in November it’s quite a blessing. It makes everything brighter in the darkness. Bear in mind that we are in the middle of Kaamos, or Polar Night, and not until 9 a.m. there is some light to begin to fade away around 3 p.m. —or even earlier. We still have three weeks ahead until the trend is reversed and the light increases again. I’ll try to write about Kaamos in a future post.           First heavy snowfall  Although we welcomed and enjoyed the snow on Sunday, the problem came on Monday.  Since the temperature is all the time around zero, snow is in quasi-liquid state, or in other words it’s really humid since it’s almost thawing and freezing all the time. This makes the floor really slippery and dangerous. It’s really madness to drive, even with studded tires, since it makes the car behave more like a boat than really a car. The car is skidding almost all the time, and you have to be really carefully shifting lanes or turning on the streets. Even more keeping a safe distance from the car in front of you because the braking distance doubles or triples. The problem is that snow and ice doesn’t stick to the tarmac until it’s around -6 or -10 ºC. Then the ice stinks to the road and the sudden tires are able to get grip on the ice, not as good as in dry conditions, but I would say that surprisingly good. Anyhow, I’m not going to deny that sometimes I enjoy a little bit the skid the situation, but most of the times one have to be really careful.       As you can see in the pictures above, the parking lot of the university wasn’t that fancy on Monday as our Sunday photos. Let’s hope that the temperatures decrease a little bit and stabilize around -6 ºC, which becomes to be a really great temperature to enjoy the snow and drive safely.           Joensuu’s weather forecast for the following days. Source FMI  PS/ Meanwhile we’ll try to enjoy the views.           View from my window… only on the light hours, of course. Then is like this  ","categories": ["Personal"],
        "tags": ["Finland","Finnish life","Joensuu","snow"],
        "url": "https://luisspuerto.net/blog/2017/11/29/first-heavy-snowfall/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/DSC8753.jpg"},{
        "title": "My MacBook Pro late 2011's discrete graphics card said \"ciao\" 👋🏻 —again",
        "excerpt":"Last Sunday wasn’t really a pleasant day. On Saturday late night, or rather around Sunday 00.30 am, my MacBook Pro late 2011’s discrete graphic card begin to fail to in the end not being able to boot it properly. The computer was working just fine, it wasn’t even using the discrete card, connected to the external screen as I’ve been doing lately, or any doing any other intensive task. I just rebooted it and 5’ after loading the desktop a solid gray screen appear that allowed to do nothing. After I forced reboot pushing the on/off button, the normal loading gray screen had glitches as thin-horizontal-weird lines. After 3 or 4 boots into the desktop and then the gray screen of dead the computer begin to load directly just to the gray screen of death. Nothing could be done to load the computer normally. I tried safe mode, pressing shift key on boot, and nothing, just the same gray screen of death. Restore mode, alt + R on boot, also the gray screen of death. So, I decided to left the issue to sleep —it was around 1.30 am in the morning, and led the computer to make a hardware test, pressing D key on startup. It’s not the first time that the discrete graphic card fails in my laptop. It’s a malaise that occurs to almost any 2011 Macbook Pro’s computer. I think there is two kind of machines out there, the ones where the issue already happened and the ones where it’s going to happen. My entire logic board was changed on July 2014 and 3 years and a half down the road it failed again last Sunday. Again, the same faulty chip. This is not proper quality Apple (AMD / Nvidia are also culprits here), and I don’t know whose idea was to mount those logic board / chips on this Mac model, but I think it wasn’t the brightest idea ever. So, in Sunday morning, after I slept on the issue and I had a proper coffee and breakfast, I got my hands on to try to fix the problem. I begun with searching on internet about the problem and some people suggested that it was a RAM problem. Well, it could have been. The last time I did a hardware test, when I changed my hard drive in the US, it yielded a RAM problem, and this time threw me the same error.           Error 4MEM/66/40000000: 0x846b3798  So I decided to give it a try to this guy’s suggestion and I even switched the RAM for the original ones, since I upgraded 4 years ago to two 8 GB modules. However, the result was always the very exact one. So I decided to ditch the idea that the RAM was the cause of the grey screen of death, reinstalled the RAM and looked for another solution. Finally, I found these solutions (1, 2, 3 and 4), which were quite recent. It seems that a lot of boards are dying all over again. The solution is quite simple, since what is failing is the discrete graphic card and you usually don’t use it in your daily life, you just have to stop using that card at all, and use all the time the integrated one. Problem solved. But, how do you make that happen when the only thing you are able to see is the grey screen of death? Basically you make the computer to not boot using the drivers for the discrete graphic car. The solution works, but there is some caveats, under High Sierra. One is that your Mac is not longer going to sleep properly, but it can be fixed just changing the sleep mode to hibernation. And that the bright control is not longer going to work, at least at the moment. I can live with that. I’m going to summarize here what I’ve done to fix it under High Sierra macOS 10.13.1 on my Late 2011 MacBook Pro. The solution First of all, I have to say that I begun with the solution number 1 and then I switch to the 2, 3 and 4 ones. Probably, you are fine to proceded from the solution number 2 onwards. To make make those solutions work in the long run, you are going to need a USB stick in order to have a way of booting your Mac, from the very beginning, or when you update your system and the fix stop working as a consequence of the update. You don’t need a very big USB stick. What you are going to store on it it’s not going to more than 10 mb. Moving the kexts This step isn’t really necessary, and you can jump to the next step. However, this is the exactly how I did things, since first I found one solution and then the others. Also, if you have trouble booting with the other solutions, perhaps this part is going to help you. You need to boot on single user mode (press and hold `Cmd + S + R ) and run the following commands. 123456789$ fsck -fy # to check a disk$ mount -uw / # mount a root filesystem with read/write permissions$ sudo mkdir /AMD_Kexts/ # make a directory to store the AMD drivers in case you'll need them in future$ sudo mv /System/Library/Extensions/AMD*.* /AMD_Kexts/ # move the AMD drivers$ sudo rm -rf /System/Library/Caches/com.apple.kext.caches/ # remove the AMD drivers cache$ sudo mkdir /System/Library/Caches/com.apple.kext.caches/ # just in case OS X will be dumb and will not recreate this directory, I am creating it for OS X$ sudo touch /System/Library/Extensions/ # to update the timestamps so that new driver caches - without AMD drivers - will be definitely rebuilt$ sudo umount / # umount a partition to guarantee that your changes are flushed to it$ sudo rebootHowever, in the same way as the solution’s poster, when I tried to delete the kext the Mac was throwing me the error operation not allowed or something similar. Probably because in the same way as s/he, I have my disk locked as “read-only” after too many attempt of booting. Lucky, I didn’t need to mount my disk on Linux, as s/he did. I just took my disk out of my Mac and put it in a USB enclosure that I connected to another Mac with High Sierra. I have High Sierra installed in my machine with the new APFS, so that means that my disk in only readable by other Macs with High Sierra installed. Dangerous, yes, but I wanted to take advantage of the new features. Backups were invented for some reason. From there, I just needed to performed the same commands but a little bit different. You have to take into account that in macOS your hard drive is going to mount automatically, so it wasn’t necessary to mount it like before, and you just have to run the rest of the commands with the proper path and the name of your drive. In my case my hard drive name is Macintosh SSD, and in this Mac there is also a Macintosh SSD, so when it mounted my hard drive macOS renamed it to to Macintosh SSD 1, In the shell you have to proper indecate the blank spaces on name and paths using the backslash symbol \\, therefore I could access to my hard drive using the name Macintosh\\ SSD\\ 1. Mind the name of your hard drive (usually Macintosh HD) and change the path in the commands in consequence. 123456$ sudo mkdir /Volumes/Macintosh\\ SSD\\ 1/AMD_Kexts/ # make a directory to store the AMD drivers in case you'll need them in future$ sudo mv /Volumes/Macintosh\\ SSD\\ 1/System/Library/Extensions/AMD*.* /AMD_Kexts/ # move the AMD drivers$ sudo rm -rf /Volumes/Macintosh\\ SSD\\ 1/System/Library/Caches/com.apple.kext.caches/ # remove the AMD drivers cache$ sudo mkdir /Volumes/Macintosh\\ SSD\\ 1/System/Library/Caches/com.apple.kext.caches/ # just in case OS X will be dumb and will not recreate this directory, I am creating it for OS X$ sudo touch /Volumes/Macintosh\\ SSD\\ 1/System/Library/Extensions/ # to update the timestamps so that new driver caches - without AMD drivers - will be definitely rebuilt$ sudo umount /Volumes/Macintosh\\ SSD\\ 1/ # umount a partition to guarantee that your changes are flushed to it&lt;br&gt;Now, you can take your disk, reinstall it in your Mac and begin from there. I booted to something like this1:           Booting without kexts.  Using solutions 2, 3 and 4 That’s beginning… at least now I knew that my computer can be booted. Then, I decided to switch solutions and continue with the fix explained in 2, which is fully explained in 3. The reason… because seemed more recent and better explained, and more stable in the long term. So, as it’s detailed in that solutions, first reset the SMC and the NVRAM. Then, boot your Mac on recovery single user mode (pressing and holding Cmd + S + R) and run the following commands. 123$ nvram fa4ce28d-b62f-4c99-9cc3-6815686e30f9:gpu-power-prefs=%01%00%00%00$ csrutil disable$ rebootNow, and since you moved the GPU kext from their original location you are going to boot to something like this.           Booting normally  Hey!! you probably are thinking… I’ve done it, I’ve fixed. it. Yes &amp; not. Since you’ve moved the kexts from their original place things are working more or less correctly, however, if you updated the system, you are going to probably have to move your kext and apply the solution again. For that reason, they decided to created a nicer solution implementing GRUB on your start up disk and blocking the loading of those kexts on booting. GRUB is the same system you put in place when you are installing Linux in a computer and you want to have more than one OS in the machine. This solution allow us to keep the kexts in place and boot without loading them. The solution isn’t perfect, but at least is easy to implement and in case you install a system update you can easily reimplement. At this point, I recommend to move the kexts to the original location /System/Library/Extensions/.           Moved kexts  You can do it dragging and dropping those back to its original location (it’s going to ask for your password), or you just can move then with terminal: 1$ sudo mv /AMD_Kexts/*.* /System/Library/Extensions/Getting a GRUB Now, to implement the complete solution you have to download ubuntu to take the GRUB from there. I’ve downloaded Ubuntu 17.102, as it’s specified in the fix. When you’ve downloaded the .ISO, you have to attach and mount it, so assuming that you have the ISO in downloads: 1$ hdiutil attach -nomount ~/Downloads/ubuntu-17.10-desktop-amd64.isoWhich probably turns something like this: 123/dev/disk2              Apple_partition_scheme/dev/disk2s1            Apple_partition_map/dev/disk2s2            Apple_HFSThe disk number could be different, for example in my case the first time was disk3, but mounted a second time and was disk2. Depends on how many disks have you mounted before. Now you can finally mount the ISO with the following commands: 123$ mkdir /tmp/ubuntu$ mount -t cd9660 /dev/disk2 /tmp/ubuntu/$ open /tmp/ubuntu/shellPreparing the USB stick and editing GRUB file You have to format you USB stick to FAT32 and it’s recomendable to name it boot folders from the ISO to your USB stick root.           Folders you have to copy  When you have those folders on your USB stick, you have to edit the file /RESCUE/boot/grub/grub.cfg. I like Atom to edit, but perhaps you don’t have it installed so if you type: 1$ open /Volumes/RESCUE/boot/grub/grub.cfgYour default text editor will open. In case you want to be sure and open with Text Edit: 1$ open -a TextEdit /Volumes/RESCUE/boot/grub/grub.cfgThen you have to delete all the file content and paste the following. 1234567891011121314151617181920if loadfont /boot/grub/font.pf2 ; then    set gfxmode=auto    insmod efi_gop    insmod efi_uga    insmod gfxterm    terminal_output gfxtermfiset menu_color_normal=white/blackset menu_color_highlight=black/light-grayset timeout=0menuentry \"macOS\" {    outb 0x728 1    outb 0x710 2    outb 0x740 2    outb 0x750 0    outb 0x714 0xFF    exit}Take into account that is a specific GRUB configuration for High Sierra and with a single OS installed. If you have more that one OS or you are under other OS check this. Note that I’ve added a line to the original proposed GRUP file at almost at the end. This is because someone suggest that line on this thread. I’ve also set the timeout variable to zero, since I don’t want to push enter to continue or wait 10 seconds. I don’t have anything to chose from. Save the file and let’s copy now to you Mac. Or perhaps, you can test if this works properly rebooting using the USB stick. For that you have to reboot and then push alt after you hear the chime, introduce the USB stick and choose it on the menu. You should be able to reboot normally. Making it permanent Now you can make this permanent and without need the USB. You run on terminal the following commands with your USB still plugged and assuming that you named it RESCUE. 123456789$ cd /Volumes$ sudo mkdir efi$ sudo mount -t msdos /dev/disk0s1 /Volumes/efi$ sudo mkdir /Volumes/efi/boot$ sudo mkdir /Volumes/efi/EFI/grub$ sudo cp -R /Volumes/RESCUE/boot/ /Volumes/efi/boot$ sudo cp -R /Volumes/RESCUE/EFI/boot/ /Volumes/efi/EFI/grub$ sudo bless --folder=/Volumes/efi --file=/Volumes/efi/EFI/grub/grubx64.efi --setBoot$ sudo bless --mount=/Volumes/efi --file=/Volumes/efi/EFI/grub/grubx64.efi --setBootNow… you can unmount the USB and boot without it. Preventing GPU from waking up from sleep When you are under High Sierra, the next step doesn’t really work, and even installing this kext is going to return to a black screen when you return form sleep. To prevent this, you can just change the way your Mac sleep and make it hibernate. If you have a SSD in place, like I have, the difference on time between waking up from a normal sleep than from hibernation is going to be neglectable.  The only real difference is, your computer isn’t going to wake up when you lift the lid and you have to push the on/off button to wake your Mac up. To set this up you have to run on terminal: 1$ sudo pmset -a hibernatemode 25If you want to return to the normal sleep mode you set in the following way: 1$ sudo pmset -a hibernatemode 3Anyhow, I decided to apply the solution as it’s explained here and I even created a kext myself for High Sierra. Just in hopes that in a close future things improve I can normally sleep. If you download the kext you just have to unzip it and then copy to /Library/Extensions and run the following commands. 123$ sudo chmod -R 755 /Library/Extensions/AMDGPUWakeHandler.kext$ sudo chown -R root:wheel /Library/Extensions/AMDGPUWakeHandler.kext$ sudo touch /Library/ExtensionsAnd reboot. Now, you are done. Reimplementing the fix If you need to reimplement the solution because you updated the system you are going to need to just bless GRUB disk again —make it a bootable disk. You just boot from the rescue USB stick and run the following commands on terminal3 12345$ cd /Volumes$ sudo mkdir efi$ sudo mount -t msdos /dev/disk0s1 /Volumes/efi$ sudo bless --folder=/Volumes/efi --file=/Volumes/efi/EFI/grub/grubx64.efi --setBoot$ sudo bless --mount=/Volumes/efi --file=/Volumes/efi/EFI/grub/grubx64.efi --setBootFinal note As I’ve mentioned earlier, there are only two caveats to this solution if you are under High Sierra. One is that you lose the ability to sleep you computer normally and you have to hibernate. Nothing really serious if you have an SSD. The other is more serious… or at least is going to affect you more in your daily basics. You are not going to be able to control the brightness of your computer anymore. It’s something that MacRumors community is trying to fix. Anyhow, the weir way that High Sierra manages the bright isn’t something new. And during the betas, some people commented about this on the developers forum as well, here and here. Why this happens? You’re probably wondering yourself why this is happening to your computer although if you have researched a little bit about the problem you probably already know what is the problem. Really bad quality graphic chips that due to heat in the computer finally fails. You can learn a little bit in this video.   To sum it up… AMD / Nvidia chips mounted in logic board of this model are really bad and I guess most of them are faulty. The lack of proper ventilation on Macs, specially in this models, doesn’t improve things and make then even more prone to this kind of issues. There is a technique called reballing, which basically consist repair the littles balls that the chip uses to connect to the logic board. However, this is just a temporal solution since the problem is in the chip itself. Reballing works just because when you heat up the chip to reball it you mess with some of the internal parts of the chip —I think they call this reflow— and that makes it to work properly again, but after a while the problem is going to return. I’ve read that some people just put the board in the oven at around 200ºc to fix the issue, but I guess doesn’t last a lot either. The only long working solution is just get another board, or just another chip, and pray that this time it isn’t faulty. Change the board isn’t complicated, at least not incredible. But invest 400€, or even more, in a 6 years old computer is something you really have to ponder. Anyway, the only ones here to blame is AMD / Nvidia and or course Apple, they knew the issue all this time and they’ve done nothing to fix it. And for that reason Apple is being sued. It’s time to think if it’s really worth to spend the money Apple tags their computers. I’m really willing pay, but I expect a top-notch silent computer and service.  Besides, it seems that Apple has forgotten that professional customers really need professional computers and the last batch seems that isn’t up to the mark and Apple has received a lot of backlash for it. So big has been the adverser reaction that Apple has to even make an statement addressing it. Related issues? While I was in the US we got a beautiful 24” cinema display that I connected to my machine and we enjoyed a lot. At that moment, I was concerned by the extensive use I was doing of the dGPU when connected to the external screen and I asked in the Apple communities about the issue. They replied that it was the intended way to use the computer and I shouldn’t worry. I don’t blame then, because what they told me, was true, it was/is the normal way to use the computer and how it was designed.  Perhaps bad designed, or at least not really thoroughly thought. When you connect the computer to a external screen you trigger the use of the dGPU, not because you really need it —you can perfectly work with the integrated as other models do, but because the thunderbolt connection where you connect the external screen leads directly to the graphic card there is no way to avoid it’s use. This cause an increase of temperature of more or less 20º from the normal operation, just for connecting a external display, and  in my humble opinion there is nothing of extensive use in connecting it to a external display. In the same way… An almost month ago I installed High Sierra and I noticed a weird error related to graphics on the console:           [ERROR] — Unknown CGXDisplayDevice: 0x41dcd00  The error is still there right now, and I told Apple about it when I noticed. They contacted me and collected some data. They never return to me about this issue. Now, I wondering if this two issues are connected and High Sierra accelerated the degradation process of the Nvidia / AMD chip.             To be entirely honest I don’t remember if after deleting the kexts I was able to boot directly to the striped desktop or I needed to run the commands in the beginning of solution 2. &#8617;               Previusly I downloaded a spefific release of Ubuntu. I’ve changed to the last one. &#8617;               Today, 8th of December 2017, I decided to install the update to 10.13.2. It worked really well, and even booted without needed to apply the fix again. In other words, the discrete GPU was working. However, after a while fail, and took me more than what I wanted to reestablish everything. So my recommendation is, if you update, apply the fix as soon as possible, but cause sooner or later things are going to go south and it’s going to take you even more time to fix it. In my case I needed to apply the solution almost from the very beginning and a NVRAM reset was necessary to be able to operate again the computer. Good luck! &#8617;       ","categories": ["Personal","Professional","Technology"],
        "tags": ["dGPU","graphic card","high sierra","how to","macOS"],
        "url": "https://luisspuerto.net/blog/2017/12/05/my-macbook-pro-late-2011s-discrete-graphics-card-said-ciao-again/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/grey_screen.jpg"},{
        "title": "Disconnecting the dGPU in a late 2011 MacBook Pro —another way",
        "excerpt":"As I’ve told in the previous post, the discrete graphic car of my MacBook Pro late 2011 is faulty and can be trusted any more. So I decided to disconnect it. Yesterday, I updated the system to 10.13.2 and although in the beginning everything was working fine without enforcing the dGPU disconnection, the graphic card later failed and I had to apply the fix again. For some reason the fix didn’t working as well as it was working before so after too much booting and trying I decided to take the middle way. Besides, the GRUB soliton was nice, but it made the booting much more slower. What I’ve done basically is move the kexts from the extensions folder to other place and apply the wake up handle. In other words this are the steps. Please keep in mind that I’m running High Sierra in my machine.       Reset the SMC and the NVRAM.         Boot your Mac on recovery single user mode (pressing and holding Cmd + S + R) and run the following commands.     123 $ nvram fa4ce28d-b62f-4c99-9cc3-6815686e30f9:gpu-power-prefs=%01%00%00%00 $ csrutil disable $ reboot        You are going to reboot to your normal desktop. Now you can move the GPU kexts to other place:    12345 $ sudo mkdir /AMD_Kexts/ # make a directory to store the AMD drivers in case you'll need them in future $ sudo mv /System/Library/Extensions/AMD*.* /AMD_Kexts/ # move the AMD drivers $ sudo rm -rf /System/Library/Caches/com.apple.kext.caches/ # remove the AMD drivers cache $ sudo mkdir /System/Library/Caches/com.apple.kext.caches/ # just in case OS X will be dumb and will not recreate this directory, I am creating it for OS X $ sudo touch /System/Library/Extensions/ # to update the timestamps so that new driver caches - without AMD drivers - will be definitely rebuilt            Take the AMDGPUWakeHandler.kext and copy it to &lt;span /Library/Extensions then run the following commands     123 $ sudo chmod -R 755 /Library/Extensions/AMDGPUWakeHandler.kext $ sudo chown -R root:wheel /Library/Extensions/AMDGPUWakeHandler.kext $ sudo touch /Library/Extensions            Make sure to have change the way the system sleeps:     1 $ sudo pmset -a hibernatemode 25        Now you can reboot.      Perhaps it’s recomendable to re-enable the SIP. To do that just boot your Mac on recovery single user mode (pressing and holding Cmd + S + R) and run:     12 $ csrutil enable $ reboot      This solution perhaps it’s a little bit easier, but has the disadvantage that you need to apply it all every time you update the system. Anyway, I recommend to read the previous post to understand fully what is going on. ","categories": ["Personal","Technology"],
        "tags": ["dGPU","graphic card","high sierra","how to","macOS"],
        "url": "https://luisspuerto.net/blog/2017/12/08/disconnecting-the-dgpu-in-a-late-2011-macbook-pro-another-way/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/grey_screen.jpg"},{
        "title": "Disconnecting the dGPU in a late 2011 MacBook Pro —third way",
        "excerpt":"Update 2017.12.12-14.20 EET: whether or not I use the AMDGPUWakeHandler and whether I sleep or hibernate I can’t wake up of the hibernation/sleep. Depending on if I have AMDGPUWakeHandler on or off I get different outputs, but none of those end in a successful wakeup. Update 2017.12.13-09.08 EET: After checking about the wake up problem after sleeping / hibernating with the people form MacRumors, I reached some conclusions.   You don’t use AMDGPUWakeHandler with this solution, since it could create a kernel panic… so for that reason doesn’t work.  pmset gpuswitch option can help, but it’s really undocumented officially, so we really don’t know what the values for 0, 1 and 2 stand for, and can vary from machine to machine I guess, or at least to macOS version to version.  gfxCardStatus can help since the problem after wake up is the dGPU activates and the computer freezes.I’ve updated steps 11 and 12 in consequence. Update 2017.12.18-14.42 EET: I’ve tried to wake up from hibernation without gxfCardStatus and it worked pretty well I didn’t have any issue, so if you don’t want to have it installed or at least running in the background I think it’s OK. Update 2018.01.09-21.35 EET: After install the security update to mitigate the effects of Spectre, I have to apply the fix again as explained here. Everything worked fine, but on wake up of hibernation I got a black screen a couple of times. Also the computer didn’t turn off and got stuck in a black screen. I really don’t know what is the reason, but seems it’s related to the gpuswitch parameter. I changed to 0 and then to 2 again, and seems that everything is normal again. But I don’t know if it’s really that or it’s other thing. Update 2018.01.21-09.20 EET: I just installed macOS update 10.13.3 and after testing a little bit I got to the conclusion that what work best for me is to set pmset -a gpuswitch 1 Ok!!!!!! There is a third, and I think final, solution to totally deactivate the dGPU. Till this moment this is my favorite solution and I even have the brightness back to my computer. Also it sleeps correctly. You can check my previous post also 1 &amp; 2. We all have to thank to MacRumors community that all of them have been working really hard to create a workable solution to all of us. This guide is almost a exact copy of the one posted by MikeyN here. I’ve just changed somethings and added the AMDGPUWakeHandler to manage the sleep. The fix Let’s explain how it’s done:   As always you have to reset SMC and PRAM/NVRAM before you do anything else.          SMC: shutdown, unplug everything except power, now hold leftShift + Ctrl + Opt/Alt + Power for about 10” and release at the same time.      PRAM/NVRAM: with the power cord on, power on and immediately later and before the chime hold cmd + Opt/Alt + P + R at the same time until you hear the chime for the second time. Try to do the following step just right after, so you don’t let the computer to load —and fail.            Now, boot into recovery single user mode by holding: cmd + R + S. When finish to load, you run:     1234$ csrutil disable # to disable SIP$ nvram fa4ce28d-b62f-4c99-9cc3-6815686e30f9:gpu-power-prefs=%01%00%00%00 # to disable the dGPU on boot.$ nvram boot-args=\"-v\" # Load in verbose mode$ reboot            Reboot in single user mode holding on boot cmd + S         Now we are going to mount the hard drive and move the driver of the dGPU AMDRadeonX3000.kext out of the drivers folder.     12345$ /sbin/mount -uw / # mount root partition writeable$ mkdir -p /System/Library/Extensions-off # make a kext-backup directory$ mv /System/Library/Extensions/AMDRadeonX3000.kext /System/Library/Extensions-off/ # only move ONE offending kext out of the way$ touch /System/Library/Extensions/ # let the system update its kextcache$ reboot            Now you’re going to be able to load your desktop normally, but with an accelerated iGPU display. However, the system doesn’t know how to power-management the failed AMD-chip, so you are going to need to load it manually.     1$ sudo kextload /System/Library/Extensions-off/AMDRadeonX3000.kext            You can automate the loading with the doing the following:     12$ sudo mkdir -p /Library/LoginHook # Creating a folder to store the script.$ sudo nano /Library/LoginHook/LoadX3000.sh # Creating the script.            On nano you type/paste:     1234#!/bin/bashkextload /System/Library/Extensions-off/AMDRadeonX3000.kext# pmset -a gpuswitch 0 # to prevent to switch to the dGPUexit 0        * I’ve decided to comment the line 3 since I’m not sure that 0 is the correct value. Besides, in the step 12 I set gpuswitch 2.         You make it executable active:     12$ sudo chmod a+x /Library/LoginHook/LoadX3000.sh$ sudo defaults write com.apple.loginwindow LoginHook /Library/LoginHook/LoadX3000.sh            This is what I like the most. You create a script in the root of your hard drive to automate the process in case of an update.     1$ sudo nano /force-iGPU-boot.sh # Creates the script in the root        With the following content.     1234#/bin/shsudo nvram boot-args=\"-v\"sudo nvram fa4ce28d-b62f-4c99-9cc3-6815686e30f9:gpu-power-prefs=%01%00%00%00exit 0            Now you make it executable and I hide to avoid delete it:     12$ sudo chmod a+x /force-iGPU-boot.sh # make ir executable$ sudo chflags hidden /force-iGPU-boot.sh # hide the file.        In the future if you reset SMC and PRAM/NVRAM you just have to load in single user mode holding cmd + S and run:     1$ sh /force-iGPU-boot.sh        Then, you can copy the AMDGPUWakeHandler, or the one I created AMDGPUWakeHandler.kext, to /Library/Extensions and run the following commands:    123$ # sudo chmod -R 755 /Library/Extensions/AMDGPUWakeHandler.kext$ # sudo chown -R root:wheel /Library/Extensions/AMDGPUWakeHandler.kext$ # sudo touch /Library/Extensions            This time you don’t need to change the way the machine sleeps. And you can reboot     I recommend you the way the machine sleeps to hibernate, but I haven’t tested if it can sleeps normally after we apply the following step     1$ sudo pmset -a hibernatemode 25        All the fuss about the wake up after sleep / hibernate is related to when the computer wake ups checks the GPUs and somehow it gets stuck to dGPU. For that reason some people has changed the variable gpuswitch in pmset. Nevertheless, this variable is really undocumented and you find explanations to what the values to that variable (0, 1 and 2) do on internet. At this moment I have it set as default 2 I’ve decided to change to 1.     1$ sudo pmset -a gpuswitch 1        Which I thing it’s the default value. The default value is 2.     You can try the different values, reboot and then close the lid and wake up and see the results.     What has worked for me is leave it in 1 and install gfxCardStatus, and every time I boot change to integrated only. But still testing. I’ve tried to wake up from hibernation without gfxCardStatus and it also worked, so I guess it’s optional. gfxCardStatus can help, but at least I’m not using it right now. I wake up from hibernation without it perfectly.         After you reboot and if everything goes smoothly, perhaps you wan to return to the normal boot mode. You can room in terminal:     1$ sudo nvram boot-args=\"\"      Now I just going to copy paste from MikeyN’s post   This setup has now one kext in a place Apple’s installers do not expect. That is why in this guide SIP has not been reenabled. If an update that contains changes to the AMD drivers is about to take place it is advisable to move back the AMDRadeonX3000.kext to its default location before the update process. Otherwise the updater writes at least another kext of a different version to its default location or at worst you end up with an undefined state of partially non-matching drivers.   After any system update the folder /System/Library/Extensions has to be checked for the offending kext. Its presence there will lead to e.g. a boot hang on Yosemite and Sierra, an overheating boot-loop in High Sierra.   Further: this laptop is overheating, no matter what you do. The cooling system is inadequate and the huge number of failing AMD chips are just proof of that. In case you have to update So, before you update the system, please remember to run: 1$ sudo cp -r /System/Library/Extensions-off/AMDRadeonX3000.kext /System/Library/Extensions/Then you update. If you can’t normally load your computer, you can hold cmd + S and run: 1$ sh /force-iGPU-boot.shThen you can reboot again on single user mode holding cmd + S and then run 1$ sudo mv /System/Library/Extensions/AMDRadeonX3000.kext /System/Library/Extensions-off/To move again the kext. Keep in mid that the other one still there do you are going to probably rename it in this fashion: 1$ sudo mv /System/Library/Extensions/AMDRadeonX3000.kext /System/Library/Extensions-off/AMDRadeonX3000-1.kextChecking that everything is OK If you run in terminal 1$ kextstat | grep AMDYou have to get something similar to this: 1234111    2 0xffffff7f82da8000 0x122000   0x122000   com.apple.kext.AMDLegacySupport (1.6.0) 3BE3756A-6D69-3CD0-B18A-BC844EE2A4DF &lt;105 12 11 7 5 4 3 1&gt;130    0 0xffffff7f83631000 0x12e000   0x12e000   com.apple.kext.AMD6000Controller (1.6.0) DC45A18B-6F81-38D5-85CB-06BFBD74B524 &lt;111 105 12 11 5 4 3 1&gt;146    0 0xffffff7f83126000 0x22000    0x22000    com.apple.kext.AMDLegacyFramebuffer (1.6.0) 5F948DD4-8D1E-31BD-A7EE-C44254CBA506 &lt;111 105 12 11 7 5 4 3 1&gt;174    0 0xffffff7f83ab3000 0x56c000   0x56c000   com.apple.kext.AMDRadeonX3000 (1.6.0) 7E721EBE-AD4B-3C53-A70A-1FFF3C231968 &lt;173 147 105 12 7 5 4 3 1&gt;In the beginning I wasn’t getting any of these and the system just loaded AMDRadeonX3000. That resulting in a little bit of overheating in the dGPU and I wasn’t able to sleep the computer. The reason for the system to not load the kext was I moved them that much that I changed the ownership of the files. If that is your case you can run in terminal: 12$ sudo chown -R root:wheel /System/Library/Extensions/AMD*.*$ sudo chown -R root:wheel /System/Library/Extensions-off/AMD*.*to return the ownership to the System / Root Let’s hope that everything goes smoothly from now on. You have to see the bright side of life, now you have a quite cold running Mac since the dGPU is totally deactivated. After a while your temps have to be something similar to this:           GPU diode and GPU proximity are the dGPU sensors. GPU PECI is the iGPU sensor.  ","categories": ["Personal","Technology"],
        "tags": ["dGPU","graphic card","high sierra","how to","macOS"],
        "url": "https://luisspuerto.net/blog/2017/12/11/disconnecting-the-dgpu-in-a-late-2011-macbook-pro-third-way/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/grey_screen.jpg"},{
        "title": "Happy New Year 12018 &#x1f389;",
        "excerpt":"I want to wish you all a Happy New Year   12018   🎉 And remember that: Then       And Now       The Sky Is The Limit   There Are Always Reasons To Be Optimistic   And That You Get “More Bonus Points If You Help To Build A Galactic Human Empire”. ","categories": ["Personal"],
        "tags": ["New Year"],
        "url": "https://luisspuerto.net/blog/2017/12/31/happy-new-year-12018/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/happy_2018.jpg"},{
        "title": "iTerm2 + Oh My Zsh + Powerlevel9k + Monaco Nerd Complete Font",
        "excerpt":"In general, I don’t use my Mac’s Terminal app. Instead, I use iTem2 with a special configuration, that doesn’t use Bash, but Oh My Zsh as a shell, that is a framework to manage Zsh configuration as your shell. This framework allows you to install plugins or configure your prompt, among other cool things. I’ve also configured iTerm2 to work with a patched Monaco1 font with the complete collection of nerd glyphs. The result is more of less what you can see in the featured image in this post, a beautiful and elegant shell that you can configure and enjoy use. How you can get something similar? Reach this configuration is quite easy. These are the directions: Install iTerm2 I would begin installing iTerm2. iTerm2 is just an app similar to Terminal, but with steroids. It has far more options and even have mouse support. To install iTerm we are going to use Homebrew: 1$ brew cask install iterm2Now that you have iTerm2 you have to install Oh My Zsh. Install Oh My Zsh To install Oh My Zsh you need to have installed in your system Git. Usually that is not a problem because Mac comes with its own Git, but remember that you can update to the last version easily using Homebrew. However, you can’t install Oh My Zsh itself using Homebrew, but you can use cURL or Wget, which probably you have already installed in your system. If you don’t have any of those, you can install them through Homebrew. To install Oh My Zsh you can run the following commands: 1$ sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"or 1$ sh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\"Oh My Zsh has a autoupdate feature, so don’t worry about update. From time to time, it’s going to ask you to check the repo where it’s stored for updates. Installing Powerlevel9K theme Powerlevel9K is a Oh My Zsh external theme that gives it that awesome look and the capacity to configure the prompt, yet keep it light. There are literally dozens of themes, whether included in the Oh My Zsh repo or external ones, and Powerlevel9K is one of the external ones, so you have to download (clone the repo) and store it on the custom part for the Oh My Zsh configuration folders. To do so, just run the following command in your terminal. 1$ git clone https://github.com/bhilburn/powerlevel9k.git ~/.oh-my-zsh/custom/themes/powerlevel9k  Configuring Oh My Zsh &amp; PowerLevel9K When you have Oh My Zsh installed you can begin to configure. In order to do that you have to open the configuration file, which is located in your user folder, with your favorite text editor. In my case I like to use Atom, so I run the following command in the terminal. 1$ atom ~/.zshrcBellow you can see my configuration file. The important lines are highlighted. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154# Setting language and localization variablesexport LC_ALL=en_US.UTF-8export LANG=en_US.UTF-8# Setting $JAVA_HOMEexport JAVA_HOME=\"$(/usr/libexec/java_home)\"# Setting $PATH## If you come from bash you might have to change your $PATH.export PATH=$HOME/bin:$PATHexport PATH=/usr/local/sbin:$PATH# export PATH=/usr/local/bin:$PATH## Path for LLVM installexport PATH=/usr/local/opt/llvm/bin:$PATH## Path for Golangexport GOPATH=$HOME/golangexport GOROOT=/usr/local/opt/go/libexecexport PATH=$PATH:$GOPATH/binexport PATH=$PATH:$GOROOT/bin# Setting R variablesexport R_LIBS_USER=$HOME/Library/R/3.x/library# Path to your oh-my-zsh installation.export ZSH=~/.oh-my-zsh# Set name of the theme to load. Optionally, if you set this to \"random\"# it'll load a random theme each time that oh-my-zsh is loaded.# See https://github.com/robbyrussell/oh-my-zsh/wiki/Themes# ZSH_THEME=\"agnoster\"ZSH_THEME=\"powerlevel9k/powerlevel9k\"# POWERLEVEL9K_MODE='nerdfont-complete'POWERLEVEL9K_MODE='awesome-fontconfig' # This is another way# POWERLEVEL9K_MODE='awesome-patched' # This isn't working# Disable dir/git iconsPOWERLEVEL9K_HOME_ICON=''POWERLEVEL9K_HOME_SUB_ICON=''POWERLEVEL9K_FOLDER_ICON=''# DISABLE_AUTO_TITLE=\"true\"POWERLEVEL9K_VCS_GIT_ICON=''POWERLEVEL9K_VCS_STAGED_ICON='\\u00b1'POWERLEVEL9K_VCS_UNTRACKED_ICON='\\u25CF'POWERLEVEL9K_VCS_UNSTAGED_ICON='\\u00b1'POWERLEVEL9K_VCS_INCOMING_CHANGES_ICON='\\u2193'POWERLEVEL9K_VCS_OUTGOING_CHANGES_ICON='\\u2191'POWERLEVEL9K_VCS_MODIFIED_BACKGROUND='yellow'POWERLEVEL9K_VCS_UNTRACKED_BACKGROUND='yellow'# POWERLEVEL9K_VCS_UNTRACKED_ICON='?'# POWERLEVEL9K_SHOW_CHANGESET='true'# Root indicator configPOWERLEVEL9K_ROOT_INDICATOR_BACKGROUND=\"red\"POWERLEVEL9K_ROOT_INDICATOR_FOREGROUND=\"white\"POWERLEVEL9K_ROOT_ICON='\\u26A1'# Prompt elementsPOWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(status os_icon root_indicator context dir vcs)POWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(background_jobs virtualenv rbenv rvm time)POWERLEVEL9K_SHORTEN_STRATEGY=\"truncate_middle\"POWERLEVEL9K_SHORTEN_DIR_LENGTH=4POWERLEVEL9K_TIME_FORMAT=\"%D{%H:%M:%S \\uf073 %d.%m.%y}\"POWERLEVEL9K_STATUS_VERBOSE=falseexport DEFAULT_USER=\"$USER\"# Uncomment the following line to use case-sensitive completion.# CASE_SENSITIVE=\"true\"# Uncomment the following line to use hyphen-insensitive completion. Case# sensitive completion must be off. _ and - will be interchangeable.# HYPHEN_INSENSITIVE=\"true\"# Uncomment the following line to disable bi-weekly auto-update checks.# DISABLE_AUTO_UPDATE=\"true\"# Uncooment the following line to autoupdate without promptDISABLE_UPDATE_PROMPT=\"true\"# Uncomment the following line to change how often to auto-update (in days).# export UPDATE_ZSH_DAYS=13# Uncomment the following line to disable colors in ls.# DISABLE_LS_COLORS=\"true\"# Uncomment the following line to disable auto-setting terminal title.# DISABLE_AUTO_TITLE=\"true\"# Uncomment the following line to enable command auto-correction.# ENABLE_CORRECTION=\"true\"# Uncomment the following line to display red dots whilst waiting for completion.# COMPLETION_WAITING_DOTS=\"true\"# Uncomment the following line if you want to disable marking untracked files# under VCS as dirty. This makes repository status check for large repositories# much, much faster.# DISABLE_UNTRACKED_FILES_DIRTY=\"true\"# Uncomment the following line if you want to change the command execution time# stamp shown in the history command output.# The optional three formats: \"mm/dd/yyyy\"|\"dd.mm.yyyy\"|\"yyyy-mm-dd\"# HIST_STAMPS=\"mm/dd/yyyy\"# Would you like to use another custom folder than $ZSH/custom?# ZSH_CUSTOM=/path/to/new-custom-folder# Which plugins would you like to load? (plugins can be found in ~/.oh-my-zsh/plugins/*)# Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/# Example format: plugins=(rails git textmate ruby lighthouse)# Add wisely, as too many plugins slow down shell startup.plugins=(git colored-man colorize github jira vagrant virtualenv pip          python brew osx zsh-syntax-highlighting)source $ZSH/oh-my-zsh.shsource /usr/local/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zshsource /usr/local/share/zsh-autosuggestions/zsh-autosuggestions.zsh# source ~/.fonts/*.sh# User configuration# export MANPATH=\"/usr/local/man:$MANPATH\"# You may need to manually set your language environment# export LANG=en_US.UTF-8# Preferred editor for local and remote sessions# if [[ -n $SSH_CONNECTION ]]; then#   export EDITOR='vim'# else#   export EDITOR='mvim'# fi# Compilation flags# export ARCHFLAGS=\"-arch x86_64\"# ssh# export SSH_KEY_PATH=\"~/.ssh/rsa_id\"# Set personal aliases, overriding those provided by oh-my-zsh libs,# plugins, and themes. Aliases can be placed here, though oh-my-zsh# users are encouraged to define aliases within the ZSH_CUSTOM folder.# For a full list of active aliases, run `alias`.## Example aliasesalias zshconfig=\"atom ~/.zshrc\"# alias ohmyzsh=\"mate ~/.oh-my-zsh\"As you can see I have a lot the lines commented with #, since I don’t want to use that config, but I didn’t lose them. From line 28 to 73, it’s basically the configuration of the prompt. There are literally dozens of ways to configure the prompt, and you can see some of them here. Mine is quite similar to Falkor’s one, but I’ve edited it a little bit. You can find out more about how to stylizing your prompt and how the configuration variables work here and here. Don’t forget to set your theme as Powerlevel9k —line 33 ZSH_THEME=\"powerlevel9k/powerlevel9k\"— and also the Powerlevel mode —line 35. The Powerlevel Mode define the type —or the style— of glyphs than are shown. You can see also that in the lines 118 — 122 are the plugins I’m using and that in the the line 151 I establish a shortcut to access to the configuration through atom just typing zshconfig. Configuring iTerm2 Finally, you have to configure iTerm2 to use your patched font if you want the glyphs to shown in your prompt           iTerm2 font configuration.  If you don’t want to patch any font, you can download any of the prepatched fonts, and I recommend do it using Hombrew. 12$ brew tap caskroom/fonts$ brew cask install font-meslo-nerd-font #if you want to install Meslo font          Color configuration in iTerm2  Finally you can configure the colors in iTerm2. Usually people use of of the presets iTerm have, or the ones you can download. But I have tweaked a little bit the colors and I have my own configuration. Now you are ready to use iTerm2 with your new configuration. Setting Zsh as your default shell First you need to check what version, if any, of Zsh you have installed. 1$ zsh --versionin my case and right now my version is 5.4.2, but you can check which is the last version in the wikipedia page. Now you have to check that you have Zsh in your list of authorized shells. You have check running opening the file /etc/shells with atom: 1$ atom /etc/shellsYou have to see something similar to this. 1234567891011# List of acceptable shells for chpass(1).# Ftpd will not allow users to connect who are not using# one of these shells./bin/bash/bin/csh/bin/ksh/bin/sh/bin/tcsh/bin/zsh/usr/local/bin/bashIf you don’t have the line 10, add it and save the file. Now you run the following command to make Zsh your default shell: 12$ chsh -s$(which zsh)Keeping Terminal with the previous config Since I have iTerm2 with Oh My Zsh, I like to keep Terminal with Bash. Since we’ve set as a default terminal Zsh we need to set up manually to use Bash. Open Terminal and launch the options screen Cmd + ;. In the General tap you can find which shell use terminal. Choose command and type /bin/bash.           Terminal with Bash  Done, now you can enjoy the best of the two worlds. Enjoying a new, more flexible and customizable shell as default, while keeping your old one, just in case you felt nostalgic.             I was about to upload my patched Monaco font, but then I realize that I can’t post any modification of the Monaco font since it’s copyrighted by Apple. However, you can easily patch your copy of the font for your personal use with the script provided by Nerd Fonts. I faced some problems when I tried to patch it myself, basically related to the height of the patched font, which ended up different than the original font. If this is your case, you can just download FontForge —brew cask install fontforge— and modify those parameters to be equal to the original ones &#8617;       ","categories": ["Professional","Technology"],
        "tags": ["how to","macOS","shell"],
        "url": "https://luisspuerto.net/blog/2018/01/09/iterm2-oh-my-zsh-powerlevel9k-monaco-nerd-complete-font/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/Screen-Shot-2017-12-19-at-11.20.07.png"},{
        "title": "Install R 100% Homebrew Edition With OpenBlas & OpenMP — My Version",
        "excerpt":"Update Friday, 10th of May 2018: If you want to install R with all the capabilities you need to read this post too, and perhaps this one too. Update Tuesday, 27th of March 2018: I just found out that seems you don’t just need to run sudo R CMD javareconf to configure Java an R, at least with the versions of Java 9.0.4 and R 3.4.4. Update Thursday, 22nd of March 2018: I have to add -fopenmp to both clang and clang++ variables in my makevars to be able to build data.table package correctly. This is not exactly what the Data Table wiki recommends. I update the section about the Data Table Package accordingly. As you know I’m a big fan of Homebrew as a manager of part of the software of my Mac, since it make things easier. There are a lot of guides out there about how to have a R installation 100% Homebrew and some people, like me, like to have this kind of setup because it’s convenient and for the sake of lear a little bit more about how R works in more detail. However, Homebrew setup isn’t officially supported by the R Core Team, so if you find problems with your R installation you aren’t going to get support from them. Nevertheless, you are going to be able to get support from Homebrew and of course, from the regular channels to get help for R, like the mail list. The biggest advantage, besides of the regular advantages of installing something with HomeBrew, is you can create your own version of R, you can compile it, therefore you can compile it with steroids, so you can take advantage of the OpenBlas and OpenMP libraries. OpenBLAS &amp; OpenMP OpenBLAS is a open implementation of the BLAS (Basic Linear Algebra Subprograms) API. Basically, it optimizes your processor when you are doing mathematical operations, like when you are using R. It’s usually a huge leap in performance when you begin to make complex mathematical operations. OpenMP is a library for Open Multi-Processing, or in other words, be able to use all the cores of your processor when you are compiling C, C++, and Fortran. If also make R to process faster since some packages are able to use all the cores of your computer after you compile them with OpenMP. In other words, you are going to increase your performance a lot with this setup, as Mauricio Vargas demonstrate in his last two post (Why is R slow? some explanations and MKL/OpenBLAS setup to try to fix this and Is Microsoft R Open faster than CRAN R?). We also did a small test since we wanted to get this setup in one of our computers, a MacBook Air from 2013. So, we used the MicroBenchmarks package with the below script (from Alexej Gossmann’s Blog) and we got the following results. 1234567891011121314151617181920212223242526library(microbenchmark)set.seed(2017)n &lt;- 10000p &lt;- 100X &lt;- matrix(rnorm(n*p), n, p)y &lt;- X %*% rnorm(p) + rnorm(100)check_for_equal_coefs &lt;- function(values) {  tol &lt;- 1e-12  max_error &lt;- max(c(abs(values[[1]] - values[[2]]),                     abs(values[[2]] - values[[3]]),                     abs(values[[1]] - values[[3]])))  max_error &lt; tol}mbm &lt;- microbenchmark(\"lm\" = { b &lt;- lm(y ~ X + 0)$coef },               \"pseudoinverse\" = {                 b &lt;- solve(t(X) %*% X) %*% t(X) %*% y               },               \"linear system\" = {                 b &lt;- solve(t(X) %*% X, t(X) %*% y)               },               check = check_for_equal_coefs)mbmWe got this results on a Macbook Pro 2010:       1234567# Base R benchmarks resultsUnit: milliseconds          expr      min       lq     mean   median       uq      max neval            lm 299.5747 319.5861 339.4531 324.8694 331.7090 521.0330   100 pseudoinverse 326.1059 344.3830 358.1566 351.7829 359.7690 508.8802   100 linear system 199.0780 206.6064 218.7704 210.2198 218.2907 327.6886   1001234567# R with openblas and LLVMUnit: milliseconds          expr       min        lq      mean    median        uq      max neval            lm 262.22400 272.39873 287.72378 277.65483 286.07772 361.0826   100 pseudoinverse  60.50899  62.65356  82.10815  70.40881  75.11090 169.7922   100 linear system  38.01025  39.48672  52.82579  45.81922  49.36025 121.0351   100I really think the results speak for themselves. Caveats Of course there are some problems when you have this kind of install. The first one is the complication of the install process. If it were as simple as install R binaries from CRAN I wouldn’t be doing this guide. The second one and more important, you are going to need to compile the packages you install from now on, without exception. You aren’t going to be able to install the binaries of the packages anymore. This has advantages and disadvantages. The main advantage is that they are going to make use of the libraries you have installed in your your system like OpenBLAS, OpenMP or LLVM, to mention some. However, this means that you are going to need some other libraries to compile and you have to have them correctly linked, like Java or libxml2 or some of the packages aren’t going to compile and you aren’t going to be able to have it on your system. In case you get any problem internet is your friend. You can look for the error R is returning when it tries to compile. If you are the first one to get that error you can ask in communities like Stackoverflow or the mail list for R help. All of these is going to make you understand R much better and your are going to be a better R user. So take it with patience and consider it like an advance course for R. Take into account that sometimes even the CRAN install binaries pose problems, mostly with it’s link to Java. Before I decided to have this kind of install with R I had in the past multiple problems with Java and rJava package. So nothing is perfect, but you didn’t decided to use R because it was simple, did you? How to install? I’ve used as inspiration for this guide mainly two main sources. On one hand, Bhaskar Karambelar’s installation guide, and on the other Mauricio Vargas’ one. Bhaskar’s one was the first I used, more than 6 months ago, while we were in the United Stated, and really worked well in that moment. Problem with it is, it installs a lot or libraries to program in C/C++ what unless you are a C/C++ programmer you aren’t going to use, although you never know. At that moment, I installed everything due to lack of knowledge, but probably right now I wouldn’t. It’s up to you if you want to install those libraries and programing languages. However, I have more than enough space in my hard drive and I don’t mind to have then, perhaps they are going to to be useful in the future. Besides, this has been a way to discover then and know more about C/C++ programing. Mauricio’s guide goes more to the point and it just helps you to install a really fast and quick version of R that use OpenMP and OpenBlas. Through this guide I just want to try to show you how I ended with my installation, that is an updated mixture of both guides.  However, take into account that mine guide is going to be a little bit different, even more taking into account that I use Zsh as my shell. Homebrew You probably have Homebrew already installed, if you don’t, please, install it. Then, I recommend you to connect to the cask tap if you haven’t done it already: 1$ brew tap caskroom/cask # Tap to install regular app with user interface (GUI)As you probably you’ve noticed, I don’t tap a lot of repos that Bhaskar taped. This is mainly because those taps are deprecated and its formulae are now included in the Homebrew Core. I decided not to tap other repos because I’m not going to use them. I recommend to add the following lines in your Zsh and/or Bash profiles running the following: 123456789# For zshecho '# Setting language and localization variablesexport LC_ALL=en_US.UTF-8export LANG=en_US.UTF-8' &gt;&gt; ~/.zshrc# For bashecho '# Setting language and localization variablesexport LC_ALL=en_US.UTF-8export LANG=en_US.UTF-8' &gt;&gt; ~/.bash_profileUninstalling previous R install If you already have R installed I recommend you to uninstall R completely. Before you do it, you perhaps want to do a copy of your installed packages, just make a list because you are going to need to compile all of them with this homebrew install. You can run the following code in R to make a copy of your packages. 12345678910111213# How to list installed packajespackage_matrix &lt;- installed.packages()package_df &lt;- data.frame(package_matrix)package_list &lt;- package_df[is.na(package_df$Priority), \"Package\"]packages &lt;- as.character(package_list)write(packages, file = \"packages\")save(packages, file = \"packages.RData\")Now you are going to have a file in your working folder packages.RData that is going to store a variable with a list of all your packages. To reinstall all the packages you just need to load that file in R and run: 1install.packages(packages)Now that you have a list of your installed packages you can delete R from your system. Run the following on terminal: 1$ sudo rm -rf /Library/Frameworks/R.framework /Applications/R.app /usr/local/bin/R /usr/local/bin/RscriptXCode Command Line Tools You need to have installed the Command Line Tools for XCode. Please be aware that if you already has installed, XCode you probably still need to install the CLT. The best way to know is running the following command in terminal: 1$ xcode-select --installC/C++ Compilers and Libraries Now, you need to install the C/C++ necessary compilers and other useful libraries. 1$ brew install gcc ccache cmake pkg-config autoconf automakeYou can 1234567$ cd /usr/local/bin$ ln -s gcov-7 gcov$ ln -s gcc-7 gcc$ ln -s g++-7 g++$ ln -s cpp-7 cpp$ ln -s c++-7 c++$ cd ~You can ask fo the versions to check if everything is correctly installed. You have to get something similar to this: 1234567891011121314151617$ gcc --versiongcc (Homebrew GCC 7.2.0) 7.2.0Copyright (C) 2017 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.$ gfortran -vUsing built-in specs.COLLECT_GCC=gfortranCOLLECT_LTO_WRAPPER=/usr/local/Cellar/gcc/7.2.0/libexec/gcc/x86_64-apple-darwin17.2.0/7.2.0/lto-wrapperTarget: x86_64-apple-darwin17.2.0Configured with: ../configure --build=x86_64-apple-darwin17.2.0 --prefix=/usr/local/Cellar/gcc/7.2.0 --libdir=/usr/local/Cellar/gcc/7.2.0/lib/gcc/7 --enable-languages=c,c++,objc,obj-c++,fortran --program-suffix=-7 --with-gmp=/usr/local/opt/gmp --with-mpfr=/usr/local/opt/mpfr --with-mpc=/usr/local/opt/libmpc --with-isl=/usr/local/opt/isl --with-system-zlib --enable-checking=release --with-pkgversion='Homebrew GCC 7.2.0' --with-bugurl=https://github.com/Homebrew/homebrew-core/issues --disable-nls --with-native-system-header-dir=/usr/include --with-sysroot=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdkThread model: posixgcc version 7.2.0 (Homebrew GCC 7.2.0)$ ccache --vccache version 3.3.4You can check also if the OpenMP from GCC is working running the following on terminal: 12345678910$ cat &gt; omp-test.c &lt;&lt;\"END\"#include &lt;omp.h&gt;#include &lt;stdio.h&gt;int main() {    #pragma omp parallel    printf(\"Hello from thread %d, nthreads %d\\n\", omp_get_thread_num(), omp_get_num_threads());}ENDgcc -fopenmp -o omp-test omp-test.c./omp-testAnd you should get something similar to: 12345678Hello from thread 1, nthreads 8Hello from thread 6, nthreads 8Hello from thread 4, nthreads 8Hello from thread 2, nthreads 8Hello from thread 5, nthreads 8Hello from thread 0, nthreads 8Hello from thread 3, nthreads 8Hello from thread 7, nthreads 8Miscellaneous graphical libraries -optional 1$ brew install freetype fontconfig pixman gettextSome of these libraries aren’t strictly necessary for R, but they are to install other related apps like QGIS, GRASS or PostGIS. I think that if you don’t want to install then you don’t need to do it right now, since that software install its on dependencies SSL/SSH Libraries -optional If you already have Git you probably have OpenSSL, the other two are optional. 1$ brew install openssl libressl libssh212345$ /usr/local/opt/openssl/bin/openssl versionOpenSSL 1.0.2n  7 Dec 2017$ /usr/local/opt/libressl/bin/openssl versionLibreSSL 2.2.7Libxml2 It’s highly recomendable to install this library since it’s somehow necessary to install some packages depending on the version of your macOS system. It’s really small (10 mb) so you are losing nothing installing it. 12$ brew install libxml2$ brew link libxml2 --forceBoost -optional Boost is one of those libraries that you only install if you program in C/C++. If you want to install it you need to have Libxml2 installed and then proceed as following: 12$ brew install icu4c libiconv libxslt$ brew install boost --with-icu4c --without-singleThen you can test if it’s correctly installed 123456789101112$ cat &gt; first.cpp &lt;&lt;END#include&lt;iostream&gt;#include&lt;boost/any.hpp&gt;int main(){    boost::any a(5);    a = 1.61803;    std::cout &lt;&lt; boost::any_cast&lt;double&gt;(a) &lt;&lt; std::endl;}ENDclang++ -I/usr/local/include -L/usr/local/lib  -o first first.cpp./first11.61803123456789101112131415161718$ cat &gt; second.cpp &lt;&lt;END#include&lt;iostream&gt;#include &lt;boost/filesystem.hpp&gt;int main(){    boost::filesystem::path full_path( boost::filesystem::current_path() );    if ( boost::filesystem::exists( \"second.cpp\" ) )    {        std::cout &lt;&lt; \"Found second.cpp file in \" &lt;&lt; full_path &lt;&lt; std::endl;    } else {        std::cerr &lt;&lt; \"Argh!, Something not working\" &lt;&lt; std::endl;        return 1;    }}ENDclang++ -I/usr/local/include -L/usr/local/lib  -o second second.cpp \\    -lboost_filesystem-mt -lboost_system-mt./second1Found second.cpp file in \"/Users/brewmaster\"GPG &amp; Git I’ve already explained how to install GPG in a previous post to use it with Git. How to install Git was also explained. X-Server You are going to probably need X-Server down the road. 1$ brew cask install xquartzLatex Latex is a set of applications and libraries to be able to write beautiful mathematical formulas and documents, mainly. But can be use to write any kind of documents. 1$ brew cask install mactexJava If you don’t have Java installed it’s a good moment to do so and to do it with Homebrew. 1$ brew cask install java1234$ java -versionjava version \"9.0.1\"Java(TM) SE Runtime Environment (build 9.0.1+11)Java HotSpot(TM) 64-Bit Server VM (build 9.0.1+11, mixed mode)Python It’s recommended to install Python 2 and 3 as a complement to R although R itself doesn’t use it. 123456$ brew install python$ sudo easy_install pip$ pip install --upgrade pip setuptools$ pip install markdown rpy2$ python -V # checking the versionPython 2.7.10rply2 is probably to give you an error untill you install R. You can try to install it right now and if it give you the error install again lately. 1234$ brew install python3$ pip3 install --upgrade pip setuptools wheel$ python3 -V # Checking the versionPython 3.6.4R &amp; related We are going to install some things before we install R itself. Pandoc is really useful when you have R to convert documents in different formats. Cairo is a graphical library that can be use for in R and it’s need for QGIS. Libsvg and librsvg are optional Important!: If you want to have R with all the capabilities you need to install Cairo with the instructions in this post. 1$ brew install pandoc cairo libsvg librsvgOpenBLAS Let’s install OpenBLAS, this is one of the key pieces of this installation. 1$ brew install openblas --with-openmpNow you can test if OpenBlas has been correctly installed. 12345678910111213141516171819202122232425$ cat &gt; test-openblas.c &lt;&lt;\"END\"#include &lt;cblas.h&gt;#include &lt;stdio.h&gt;void main(){  int i=0;  double A[6] = {1.0,2.0,1.0,-3.0,4.0,-1.0};  double B[6] = {1.0,2.0,1.0,-3.0,4.0,-1.0};  double C[9] = {.5,.5,.5,.5,.5,.5,.5,.5,.5};  cblas_dgemm(CblasColMajor, CblasNoTrans, CblasTrans,      3,3,2,1,A, 3, B, 3,2,C,3);  for(i=0; i&lt;9; i++)    printf(\"%lf \", C[i]);  printf(\"\\n\");}ENDclang -L/usr/local/opt/openblas/lib \\    -I/usr/local/opt/openblas/include \\    -lopenblas -lpthread \\    -o test-openblas test-openblas.c./test-openblas111.000000 -9.000000 5.000000 -9.000000 21.000000 -1.000000 5.000000 -1.000000 3.000000Armadillo and other libraries -optional Now, you can also install, if you want, Armadillo, which is other library that it’s useful if you program in C/C++ and take advantage of OpenBLAS. 12$ brew install eigen armadillo v8-315$ brew link v8-315 --forceYou can test Armadillo with the following code since the new Armadillo doesn’t provide examples, or at least I haven’t found them. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265$ cat &gt; example1.cpp &lt;&lt;END#include#include \"armadillo\"using namespace arma;using namespace std;int main(int argc, char** argv)  {  cout &lt;&lt; \"Armadillo version: \" &lt;&lt; arma_version::as_string() &lt;&lt; endl;  // directly specify the matrix size (elements are uninitialised)  mat A(2,3);  // .n_rows = number of rows    (read only)  // .n_cols = number of columns (read only)  cout &lt;&lt; \"A.n_rows = \" &lt;&lt; A.n_rows &lt;&lt; endl;  cout &lt;&lt; \"A.n_cols = \" &lt;&lt; A.n_cols &lt;&lt; endl;  // directly access an element (indexing starts at 0)  A(1,2) = 456.0;  A.print(\"A:\");  // scalars are treated as a 1x1 matrix,  // hence the code below will set A to have a size of 1x1  A = 5.0;  A.print(\"A:\");  // if you want a matrix with all elements set to a particular value  // the .fill() member function can be used  A.set_size(3,3);  A.fill(5.0);  A.print(\"A:\");  mat B;  // endr indicates \"end of row\"  B &lt;&lt; 0.555950 &lt;&lt; 0.274690 &lt;&lt; 0.540605 &lt;&lt; 0.798938 &lt;&lt; endr    &lt;&lt; 0.108929 &lt;&lt; 0.830123 &lt;&lt; 0.891726 &lt;&lt; 0.895283 &lt;&lt; endr    &lt;&lt; 0.948014 &lt;&lt; 0.973234 &lt;&lt; 0.216504 &lt;&lt; 0.883152 &lt;&lt; endr    &lt;&lt; 0.023787 &lt;&lt; 0.675382 &lt;&lt; 0.231751 &lt;&lt; 0.450332 &lt;&lt; endr;  // print to the cout stream  // with an optional string before the contents of the matrix  B.print(\"B:\");  // the &lt;&lt; operator can also be used to print the matrix  // to an arbitrary stream (cout in this case)  cout &lt;&lt; \"B:\" &lt;&lt; endl &lt;&lt; B &lt;&lt; endl;  // save to disk  B.save(\"B.txt\", raw_ascii);  // load from disk  mat C;  C.load(\"B.txt\");  C += 2.0 * B;  C.print(\"C:\");  // submatrix types:  //  // .submat(first_row, first_column, last_row, last_column)  // .row(row_number)  // .col(column_number)  // .cols(first_column, last_column)  // .rows(first_row, last_row)  cout &lt;&lt; \"C.submat(0,0,3,1) =\" &lt;&lt; endl;  cout &lt;&lt; C.submat(0,0,3,1) &lt;&lt; endl;  // generate the identity matrix  mat D = eye&lt;mat&gt;(4,4);  D.submat(0,0,3,1) = C.cols(1,2);  D.print(\"D:\");  // transpose  cout &lt;&lt; \"trans(B) =\" &lt;&lt; endl;  cout &lt;&lt; trans(B) &lt;&lt; endl;  // maximum from each column (traverse along rows)  cout &lt;&lt; \"max(B) =\" &lt;&lt; endl;  cout &lt;&lt; max(B) &lt;&lt; endl;  // maximum from each row (traverse along columns)  cout &lt;&lt; \"max(B,1) =\" &lt;&lt; endl;  cout &lt;&lt; max(B,1) &lt;&lt; endl;  // maximum value in B  cout &lt;&lt; \"max(max(B)) = \" &lt;&lt; max(max(B)) &lt;&lt; endl;  // sum of each column (traverse along rows)  cout &lt;&lt; \"sum(B) =\" &lt;&lt; endl;  cout &lt;&lt; sum(B) &lt;&lt; endl;  // sum of each row (traverse along columns)  cout &lt;&lt; \"sum(B,1) =\" &lt;&lt; endl;  cout &lt;&lt; sum(B,1) &lt;&lt; endl;  // sum of all elements  cout &lt;&lt; \"sum(sum(B)) = \" &lt;&lt; sum(sum(B)) &lt;&lt; endl;  cout &lt;&lt; \"accu(B)     = \" &lt;&lt; accu(B) &lt;&lt; endl;  // trace = sum along diagonal  cout &lt;&lt; \"trace(B)    = \" &lt;&lt; trace(B) &lt;&lt; endl;  // random matrix -- values are uniformly distributed in the [0,1] interval  mat E = randu&lt;mat&gt;(4,4);  E.print(\"E:\");  cout &lt;&lt; endl;  // row vectors are treated like a matrix with one row  rowvec r;  r &lt;&lt; 0.59499 &lt;&lt; 0.88807 &lt;&lt; 0.88532 &lt;&lt; 0.19968;  r.print(\"r:\");  // column vectors are treated like a matrix with one column  colvec q;  q &lt;&lt; 0.81114 &lt;&lt; 0.06256 &lt;&lt; 0.95989 &lt;&lt; 0.73628;  q.print(\"q:\");  // dot or inner product  cout &lt;&lt; \"as_scalar(rq) = \" &lt;&lt; as_scalar(rq) &lt;&lt; endl;  // outer product  cout &lt;&lt; \"q*r =\" &lt;&lt; endl;  cout &lt;&lt; q*r &lt;&lt; endl;  // multiply-and-accumulate operation  // (no temporary matrices are created)  cout &lt;&lt; \"accu(B % C) = \" &lt;&lt; accu(B % C) &lt;&lt; endl;  // sum of three matrices (no temporary matrices are created)  mat F = B + C + D;  F.print(\"F:\");  // imat specifies an integer matrix  imat AA;  imat BB;  AA &lt;&lt; 1 &lt;&lt; 2 &lt;&lt; 3 &lt;&lt; endr &lt;&lt; 4 &lt;&lt; 5 &lt;&lt; 6 &lt;&lt; endr &lt;&lt; 7 &lt;&lt; 8 &lt;&lt; 9;  BB &lt;&lt; 3 &lt;&lt; 2 &lt;&lt; 1 &lt;&lt; endr &lt;&lt; 6 &lt;&lt; 5 &lt;&lt; 4 &lt;&lt; endr &lt;&lt; 9 &lt;&lt; 8 &lt;&lt; 7;  // comparison of matrices (element-wise)  // output of a relational operator is a umat  umat ZZ = (AA &gt;= BB);  ZZ.print(\"ZZ =\");  // 2D field of arbitrary length row vectors  // (fields can also store abitrary objects, e.g. instances of std::string)  field&lt;rowvec&gt; xyz(3,2);  xyz(0,0) = randu(1,2);  xyz(1,0) = randu(1,3);  xyz(2,0) = randu(1,4);  xyz(0,1) = randu(1,5);  xyz(1,1) = randu(1,6);  xyz(2,1) = randu(1,7);  cout &lt;&lt; \"xyz:\" &lt;&lt; endl;  cout &lt;&lt; xyz &lt;&lt; endl;  // cubes (\"3D matrices\")  cube Q( B.n_rows, B.n_cols, 2 );  Q.slice(0) = B;  Q.slice(1) = 2.0 * B;  Q.print(\"Q:\");  return 0;  }ENDclang++   -O2   -o example1  example1.cpp  -larmadillo -framework Accelerate./example1You are going to get something like: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127Armadillo version: 8.300.3 (Tropical Shenanigans)A.n_rows = 2A.n_cols = 3A:  1.8965e-256  6.9531e-310  6.9531e-310  6.9531e-310  4.9407e-324   4.5600e+02A:   5.0000A:   5.0000   5.0000   5.0000   5.0000   5.0000   5.0000   5.0000   5.0000   5.0000B:   0.5560   0.2747   0.5406   0.7989   0.1089   0.8301   0.8917   0.8953   0.9480   0.9732   0.2165   0.8832   0.0238   0.6754   0.2318   0.4503B:   0.5560   0.2747   0.5406   0.7989   0.1089   0.8301   0.8917   0.8953   0.9480   0.9732   0.2165   0.8832   0.0238   0.6754   0.2318   0.4503C:   1.6679   0.8241   1.6218   2.3968   0.3268   2.4904   2.6752   2.6858   2.8440   2.9197   0.6495   2.6495   0.0714   2.0261   0.6953   1.3510C.submat(0,0,3,1) =   1.6679   0.8241   0.3268   2.4904   2.8440   2.9197   0.0714   2.0261D:   0.8241   1.6218        0        0   2.4904   2.6752        0        0   2.9197   0.6495   1.0000        0   2.0261   0.6953        0   1.0000trans(B) =   0.5560   0.1089   0.9480   0.0238   0.2747   0.8301   0.9732   0.6754   0.5406   0.8917   0.2165   0.2318   0.7989   0.8953   0.8832   0.4503max(B) =   0.9480   0.9732   0.8917   0.8953max(B,1) =   0.7989   0.8953   0.9732   0.6754max(max(B)) = 0.973234sum(B) =   1.6367   2.7534   1.8806   3.0277sum(B,1) =   2.1702   2.7261   3.0209   1.3813sum(sum(B)) = 9.2984accu(B)     = 9.2984trace(B)    = 2.05291E:   7.8264e-06   5.3277e-01   6.7930e-01   8.3097e-01   1.3154e-01   2.1896e-01   9.3469e-01   3.4572e-02   7.5561e-01   4.7045e-02   3.8350e-01   5.3462e-02   4.5865e-01   6.7886e-01   5.1942e-01   5.2970e-01r:   0.5950   0.8881   0.8853   0.1997q:   0.8111   0.0626   0.9599   0.7363as_scalar(r*q) = 1.53501q*r =   0.4826   0.7203   0.7181   0.1620   0.0372   0.0556   0.0554   0.0125   0.5711   0.8524   0.8498   0.1917   0.4381   0.6539   0.6518   0.1470accu(B % C) = 20.9962F:   3.0479   2.7206   2.1624   3.1958   2.9261   5.9957   3.5669   3.5811   6.7118   4.5424   1.8660   3.5326   2.1213   3.3968   0.9270   2.8013ZZ =        0        1        1        0        1        1        0        1        1xyz:[field column 0]   0.6711   0.0077   0.3834   0.0668   0.4175   0.6868   0.5890   0.9304   0.8462[field column 1]   0.5269   0.0920   0.6539   0.4160   0.7012   0.9103   0.7622   0.2625   0.0475   0.7361   0.3282   0.6326   0.7564   0.9910   0.3653   0.2470   0.9826   0.7227Q:[cube slice 0]   0.5560   0.2747   0.5406   0.7989   0.1089   0.8301   0.8917   0.8953   0.9480   0.9732   0.2165   0.8832   0.0238   0.6754   0.2318   0.4503[cube slice 1]   1.1119   0.5494   1.0812   1.5979   0.2179   1.6602   1.7835   1.7906   1.8960   1.9465   0.4330   1.7663   0.0476   1.3508   0.4635   0.9007You can also test V8 12$ echo 'quit()' | v8V8 version 3.15.11.18 [sample shell]R Important!: If you want to have R with all the capabilities you have to follow the instructions in this post, then you can continue. Let’s finally install R. 1$ brew install R --with-openblas --with-javaThen if you are using english (american english) as your main language I recommend you to run the following: 1$ defaults write org.R-project.R force.LANG en_US.UTF-8Java9+R First you have to insert the following line in your Zsh and/or Bash profiles. 1234567# For zshecho '# Setting $JAVA_HOMEexport JAVA_HOME=\"$(/usr/libexec/java_home)\"' &gt;&gt; ~/.zshrc# For bashecho '# Setting $JAVA_HOMEexport JAVA_HOME=\"$(/usr/libexec/java_home)\"' &gt;&gt; ~/.bash_profileAnd then run the following command in the terminal: 1$ sudo R CMD javareconf JAVA_CPPFLAGS='-I/System/Library/Frameworks/JavaVM.framework/Headers -I/Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/' # this is a specific command for Java 9.0.1It seems that with Java 9.0.4 and R 3.4.4 you can run instead just: 1$ sudo R CMD javareconfor perhaps: 1$ sudo R CMD javareconf JAVA_CPPFLAGS='-I/$JAVA_HOME'You have to get something similar to this: 12345678910111213141516171819202122/usr/local/Cellar/r/3.4.3/lib/R/bin/javareconf: line 66: -I/Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/: No such file or directoryJava interpreter : /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Home/bin/javaJava version     : 9.0.1Java home path   : /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/HomeJava compiler    : /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Home/bin/javacJava headers gen.: /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Home/bin/javahJava archive tool: /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Home/bin/jarNon-system Java on macOStrying to compile and link a JNI programdetected JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwindetected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm/usr/local/opt/llvm/bin/clang -I/usr/local/Cellar/r/3.4.3/lib/R/include -DNDEBUG -I/Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Home/include/darwin  -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC  -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o conftest.o/usr/local/opt/llvm/bin/clang -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/Cellar/r/3.4.3/lib/R/lib -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o conftest.so conftest.o -L/Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Home/lib/server -ljvm -L/usr/local/Cellar/r/3.4.3/lib/R/lib -lR -lintl -Wl,-framework -Wl,CoreFoundationJAVA_HOME        : /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/HomeJava library path: $(JAVA_HOME)/lib/serverJNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwinJNI linker flags : -L$(JAVA_HOME)/lib/server -ljvmUpdating Java configuration in /usr/local/Cellar/r/3.4.3/lib/RDone.Folder for R Packages Let’s create our own folder to store the installed packages for R. This way R, or us, doesn’t have to move all the packages every time we install a new R version. Run the following in terminal. 1234$ mkdir -p $HOME/Library/R/3.x/library$ cat &gt; $HOME/.Renviron &lt;&lt;ENDR_LIBS_USER=$HOME/Library/R/3.x/libraryENDYou should also add this variable to your zsh and/or bash profiles. 12345  # For zshecho 'export R_LIBS_USER=$HOME/Library/R/3.x/library' &gt;&gt; ~/.zshrc# For bashecho 'export R_LIBS_USER=$HOME/Library/R/3.x/library' &gt;&gt; ~/.bash_profileLLVM LLVM or _Low Level Virtual Machine _is a library that allow us to compile faster some R packages using OpenMP and also make that those packages use OpenMP when we are normally using R. To install it you run on your terminal the following: 1$ brew install llvmThen insert the LLVM location to your path in your Zsh and/or Bash profiles: 12345# For zshecho 'export PATH=/usr/local/opt/llvm/bin:$PATH' &gt;&gt; ~/.zshrc# For bashecho 'export PATH=/usr/local/opt/llvm/bin:$PATH' &gt;&gt; ~/.bash_profileData Table Package The package Data Table need a specific makevars file. Makevars file is the file that tells R how and with what libraries it has to compile the packages we download from source. So we are going to install Data Table first, with that specific configuration and then set the final makevars file. 12345678$ mkdir ~/.R$ echo \"CC=/usr/local/opt/llvm/bin/clang -fopenmpCXX=/usr/local/opt/llvm/bin/clang++ -fopenmp# -O3 should be faster than -O2 (default) level optimisation ..CFLAGS=-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipeCXXFLAGS=-g -O3 -Wall -pedantic -std=c++11 -mtune=native -pipeLDFLAGS=-L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/libCPPFLAGS=-I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include\" &gt;&gt; ~/.R/MakevarsNow we can install Data Table package on terminal. To do so just run on terminal: 1234$ R --vanilla &lt;&lt; EOFinstall.packages('data.table', repos='http://cran.us.r-project.org')q()EOFSetting the final Makevars First, we delete the previous makevars file. 1$ rm ~/.R/MakevarsSet the final Makevars file. 1234567$ echo \"CC=/usr/local/opt/llvm/bin/clangCXX=/usr/local/opt/llvm/bin/clang++# -O3 should be faster than -O2 (default) level optimisation ..CFLAGS=-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipeCXXFLAGS=-g -O3 -Wall -pedantic -std=c++11 -mtune=native -pipeLDFLAGS=-L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/libCPPFLAGS=-I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include\" &gt;&gt; ~/.R/MakevarsAs you probably have noticed the change is just the -fopenmp flag on the second line. In case you have to reinstall, or update Data Table, you just have to add that flag and then delete it. Really easy and you can even do it from RStudio. RStudio When you install R from Homebrew and you compile it, you don’t have anymore the R shell as an application on your Applications folder. But you can install any other graphical interface like RStudio. To do it you just run in your terminal: 1$ brew cask install rstudioUsually RStudio is able to recognize R install and you don’t need to do anything else. Additional related languages -optional You can also install some additional related languages like: Node.js From Wikipedia:   Node.js is an open-source, cross-platform JavaScript run-time environment that executes JavaScript code outside the browser. To install it just run: 1$ brew install node phantomjs casperjsScala From Wikipedia:   Scala (/ˈskɑːlɑː/ SKAH-lah)[9] is a general-purpose programming language providing support for functional programming and a strong static type system. Designed to be concise,[10] many of Scala’s design decisions aimed to address criticisms of Java.[8] To install it just run in your terminal: 1$ brew install scalagolang From Wikipedia:   Go (often referred to as Golang) is a programming language created at Google[12] in 2009 by Robert Griesemer, Rob Pike, and Ken Thompson.[10] Go is a statically typed, compiled language in the tradition of C, with memory safety, garbage collection, structural typing,[3] and CSP-style concurrency.[13] To install it just run in your terminal: 1$ brew install golangYou need to modify your zsh and/or bash profile like the following 12345678910111213# For zshecho '## Path for Golangexport GOPATH=$HOME/golangexport GOROOT=/usr/local/opt/go/libexecexport PATH=$PATH:$GOPATH/binexport PATH=$PATH:$GOROOT/bin' &gt;&gt; ~/.zshrc# For bashecho '## Path for Golangexport GOPATH=$HOME/golangexport GOROOT=/usr/local/opt/go/libexecexport PATH=$PATH:$GOPATH/binexport PATH=$PATH:$GOROOT/bin' &gt;&gt; ~/.bash_profileSome GIS Libraries &amp; Soft -optional You can also install some GIS libraries. This libraries could be mandatory if you are going to install geographical packages: 1234$ brew tap osgeo/osgeo4mac # Tap for geospatial software$ brew install postgresql geos proj$ brew install gdal2 --with-complete --with-opencl --with-armadillo --with-unsupported --with-libkml --with-postgresql$ brew install postgis --with-guiShell Profiles You’ve been adding things to your Zsh and/or Bash profiles. I recommend you to make those profiles tidy, it’s going to be easier to modify things in the future. This is how I have then: 12345678910111213141516171819202122# Setting language and localization variablesexport LC_ALL=en_US.UTF-8export LANG=en_US.UTF-8# Setting $JAVA_HOMEexport JAVA_HOME=\"$(/usr/libexec/java_home)\"# Setting $PATH## If you come from bash you might have to change your $PATH.export PATH=$HOME/bin:$PATHexport PATH=/usr/local/sbin:$PATH# export PATH=/usr/local/bin:$PATH## Path for LLVM installexport PATH=/usr/local/opt/llvm/bin:$PATH## Path for Golangexport GOPATH=$HOME/golangexport GOROOT=/usr/local/opt/go/libexecexport PATH=$PATH:$GOPATH/binexport PATH=$PATH:$GOROOT/bin# Setting R variablesexport R_LIBS_USER=$HOME/Library/R/3.x/libraryYou can see those files running the following: 1234567891011# If you have atom.# zsh$ atom ~/.zshrc# bash$ atom ~/.bash_profile# If you don't have atom#zsh$ open -a TextEdit ~/.zshrc#bash$ open -a TextEdit ~/.bash_profileThe End Now you can begin to use your new R. ","categories": ["Professional","RStats","Technology"],
        "tags": ["homebrew","how to","optimization","RSoft","RStats"],
        "url": "https://luisspuerto.net/blog/2018/01/12/install-r-100-homebrew-edition-with-openblas-openmp-my-version/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/R-Homebrew.jpg"},{
        "title": "Convert your Pi in an AirPlay receiver",
        "excerpt":"I recently needed to convert my Raspberry Pi 3 into a AirPlay receiver because I didn’t have any of my AirPort Express at hand and I wanted to play just music —not the entire collection of sounds my computer produce— on one of my old Hi-Fi Self Stereo System. So I searched on the internet and saw that it was totally possible to do it and I try it. I used as a source this article and I want share with you what steps I specifically followed. Preliminaries Let’s download some packages we are going to need as dependencies. 1$ sudo apt-get update &amp;&amp; upgrade1$ sudo apt-get install autoconf libtool libdaemon-dev libasound2-dev libpopt-dev libconfig-dev avahi-daemon libavahi-client-dev libssl-devShairport sync To convert our Pi in a AirPlay device we need a software that is call Shairport Sync. We are going to need to compile it for our system, so we need to download the source code and then compile. To download it just run on the Pi’s terminal: 1$ cd ~/Downloads # I like to download my soft in Downloads folder.1$ git clone https://github.com/mikebrady/shairport-sync.gitCompile Now that we have download the shairport-sync repository to our Pi, we can proceeded to compile it. First or all we need to move to the Shairport Sync folder and then we can proceed to configure the compilation process. 1$ cd ~/Downloads/shairport-sync1$ autoreconf -i -f1$ ./configure --with-alsa --with-avahi --with-ssl=openssl --with-systemd --with-metadataNow that we have configured it, we can proceded to compile and install it. 1$ make1$ sudo make installFinal config When the config and installing process finish we can proceed to configure the software to use it. The main thing we need to do is create a group of users that can access to the hardware and then create a user on that group that will use the software. 1$ sudo groupadd -r shairport-sync &gt;/dev/null1$ sudo useradd -r -M -g shairport-sync -s /usr/bin/nologin -G audio shairport-sync &gt;/dev/nullWe also need to set up shairport sync to start on startup. 1$ sudo systemctl enable shairport-syncIf we want to start right away to using it we can manually start it with the following command. 1$ sudo service shairport-sync startYou are going to be able to find the Pi among the devices that offer AirPlay from your iOS device or your Mac. The name of the device is going to be the hostname you set up for your Pi using the raspi-config interface, if you haven’t changed it, it’s going to be RaspberryPi. Tune up           Tuning-Up Audio. Source: Wikimedia Commons  If you try to use your Pi as a AirPort Express right away you probably going find out that the sound quality leaves a lot to be desired —very low and quite distorted. However, you can do some tune-ups in the settings to improve this, but don’t thing we are going to be able to make it sound like a real AirPort Express. Update Raspberry Pi Firmware One of the first things we can do to improve the quality of the sound is to update the sound driver of the Pi. To do it, you need to update the firmware of the Pi. You can read more about this in this forum thread. Please, keep in mind that while you are updating the firmware you must not lose power in the Pi. To update the firmware you run the following command: 1$ sudo rpi-updateOnce the update process finish you need to turn off the Raspberry and take the SD card out of it and insert the card in a computer card reader. We are going to modify the boot config file of the Pi and and to do it we are going to open with a text editor the config file that it’s located on /boot/config.txt. Then you need to add the following variable to the end of the file: 1audio_pwm_mode=2Save the file, put the card back on the Pi and turn it on. Audio jack as main audio Now, we also need to set up the audio jack as the main audio output. Just run the following command: 1$ amixer cset numid=3 1Shairport Sync db range There is a final setting we need to configure and it’s related to the audio range in which Shairport Sync operates. To do it we need to open the config file of Shariport Sync, therefore run the following command on the Pi’s terminal to open it with Nano. 1$ sudo nano /usr/local/etc/shairport-sync.confThen we need to look for the following variable: 1//      volume_range_db = 60 ;and change it to 1volume_range_db = 30;Save and close Nano, Ctrl + X then Y and finally press return. You need to reboot the Pi to make sure that new configuration is properly loaded. 1$ sudo rebootBottom line As you are going to soon find out the quality of sound isn’t exactly the same as with an AirPort Express, but this tweak allow you to use your Pi as one. It can be handy if you are traveling, you have your Pi with you, and you want to plug your music into some audio device or speakers. If you wand to use your Raspberry for to play audio there are other options out there. One is RuneAudio which is a dedicated OS to play music on the Pi and the other is to install Kodi since Kodi can play AirPlay.           Activating Airplay in Kodi  ","categories": ["Personal","Technology"],
        "tags": ["macOS","raspberry pi"],
        "url": "https://luisspuerto.net/blog/2018/01/18/convert-you-pi-in-an-airplay-receiver/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/speakers-raspberry.jpg"},{
        "title": "Sunsets in the land of the magic light",
        "excerpt":"Yesterday I was wandering with my car… warming it up, when I notice one of the most incredible sunsets I’ve ever seen in ages, between the trees in the south side of the road. I tried to think quickly where I could get a better look of the Sun and I finally came out with the perfect place where I can get a really nice view, fast and without eve get out of the car. Eastward of Avaranta beach in Joensuu, in Nuottaniemi, in a place called Siilaisenlahti on lake Pyhäselkä, there is a place where people unload and load their boats in Summer. From there you have a perfect view, with no trees interfering, and without even get out of the car. It’s a pity I couldn’t reach the place earlier, because the view I had when I was on the road was even more stunning. After I took the shot and share it on my social networks, it started to make me remember a sunset shot that the rover Spirit took in 2005 on Mars.           Sunset on Mars, source NASA and Astronomy Picture of the Day.  Among the pictures that google images served me there was a little more elaborated sunset on Mars with people on it…           The Blue Sunset. Source: Wanderers a Short film by Erik Wernquist  It’s incredible how a sunset can make our mind fly away and dream with a close future when we can wander freely on the Solar System. It’s also incredible how a sunset in two different neighbor planets on the Solar System can look quite alike. Perhaps Mars is going to be our next home… and soon we’er going to be able to enjoy those sunsets on first hand. Wanderers, is a magic short film that show us that future with the incredible voice of Carl Sagan as background. You mind just can’t, but wander into those places.   Wanderers — a short film by Erik Wernquist from Erik Wernquist on Vimeo.   For all its material advantages, the sedentary life has left us edgy, unfulfilled. Even after 400 generations in villages and cities, we haven’t forgotten. The open road still softly calls, like a nearly forgotten song of childhood. We invest far-off places with a certain romance. This appeal, I suspect, has been meticulously crafted by natural selection as an essential element in our survival. Long summers, mild winters, rich harvests, plentiful game—none of them lasts forever. It is beyond our powers to predict the future   Your own life, or your band’s, or even your species’ might be owed to a restless few—drawn, by a craving they can hardly articulate or understand, to undiscovered lands and new worlds.   Herman Melville, in Moby Dick, spoke for wanderers in all epochs and meridians: “I am tormented with an everlasting itch for things remote. I love to sail forbidden seas …”   Maybe it’s a little early. Maybe the time is not quite yet. But those other worlds—promising untold opportunities—beckon.   Silently, they orbit the Sun, waiting.   Source: Pale Blue Dot, Introduction. Pages 18 to 24. Because wer are natural wanderers and explorers. We always crave for go a little bit far and beyond. I hope we never forgot that appeal.     We used to look up and wonder our place in the stars.     ","categories": ["Personal"],
        "tags": ["exploration","Finland","landscapes","photos"],
        "url": "https://luisspuerto.net/blog/2018/01/24/sunsets-in-the-land-of-the-magic-light/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/IMG_4707.jpg"},{
        "title": "Delete all the snapshots from the local time machine",
        "excerpt":"Sometimes you need to delete all the snapshots that the macOS time machine do locally just because you want to get rid of something of because you need to reclaim that space. Before one could use sudo tmutil disablelocal to delete everything and then sudo tmutil enablelocal to enable the local snapshots again —since they are useful. However, that option is no longer available. So if you run 12345678$ sudo tmutil listlocalsnapshotscom.apple.TimeMachine.2018-03-03-144538com.apple.TimeMachine.2018-03-03-154712com.apple.TimeMachine.2018-03-03-170903com.apple.TimeMachine.2018-03-03-181447com.apple.TimeMachine.2018-03-04-094245com.apple.TimeMachine.2018-03-04-110835com.apple.TimeMachine.2018-03-04-121348You probably end up with a similar list as mine, or perhaps even longer. If you waned to free some space, you need to use the command tmutil deletelocalsnapshots and introduce the date os each of the snapshot one by one to delete them, which it’s quite a pain in the ***. Lucky, someone in the MacRumors forum came with a clever idea of using the terminal and the grep command. If you run: 12345678$ tmutil listlocalsnapshotdates / |grep 20|while read f; do tmutil deletelocalsnapshots $f; doneDeleted local snapshot '2018-03-03-144538'Deleted local snapshot '2018-03-03-154712'Deleted local snapshot '2018-03-03-170903'Deleted local snapshot '2018-03-03-181447'Deleted local snapshot '2018-03-04-094245'Deleted local snapshot '2018-03-04-110835'Deleted local snapshot '2018-03-04-121348'You are going to get rid of all those snapshots in no time. Learn how to use the terminal commands kids… it’s going to say ","categories": ["Technology"],
        "tags": ["how to","macOS"],
        "url": "https://luisspuerto.net/blog/2018/03/04/delete-all-the-snapshots-from-the-local-time-machine/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/240086966_1f04572a86_z.jpg"},{
        "title": "Jekyll",
        "excerpt":"Some months ago my wife brought to my attention Jekyll, which is a blog aware static-site __generator, or in other words it’s a piece of software that allows you to beautiful generate static websites. At that moment, I didn’t play too much attention to it, and just look for some comparisons between it and WordPress and I came to the conclusion that it wasn’t worth even a try.           GitHub Octocat with the Jekyll test tube ready for the transformation  However, after some months and seeing some examples of what you can do with it I think I’m going to give it another shot. Most of the webs you can see there are quite simple, just a couple of static pages and perhaps a simple blog. However, that doesn’t mean that you can’t build complex and beautiful websites with it —as some of the examples can proof— after all it’s just HTML. I’m not an HTML expert, quite the opposite. I have little experience programing on it and it was mostly long time ago when I begun to browse internet. However, since little by little I learning how to program in R and some shell commands, I think I’m going to give a try. Jekyll has been developed by the GitHub team and for that reason they play quite good together. Some of the advantages of it are the following:   It’s free and open source.  It’s cheap. You can host your web almost anywhere for free. AWS or GitHub Pages offer you free tiers where almost anyone page can be hosted. So you don’t have to deal with expensive hosting.  It’s fast. Everything is really lightweight so you don’t need to a lot of things to optimize how fast it loads  It’s simple. You don’t have to deal with databases.  It’s blog aware. Just following some simple formatting rules Jekyll can create for you a blog.  You can use Git to post. Since everything is a file and nothing is store in a database you can just use git to track your changes and post content.  Uses markdown, so pretty simple to post content.  You can use themes  You can use plugins.Probably, people that have been using it for longer can give you a more compressive list of its advantages. In my case, I just going give a try and try to generate something similar to my current web with it. My playground is going to be jekyll.luisspuerto.net, which is hosted in GitHub Pages. There are a lot of documentation about it in its official page and I just found a couple of youtube videos [1 &amp; 2] that look quite interesting. There is also an extensive community that can always give you a hand if you run into trouble or get stuck. Just to share with you some of the resources I just found in a minute of searching. Let’s see what I can achieve. ","categories": ["Technology"],
        "tags": ["blogging","coding","jekyll","markdown","static web"],
        "url": "https://luisspuerto.net/blog/2018/03/04/jekyll/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/jekyll.png"},{
        "title": "QGIS on macOS with Homebrew",
        "excerpt":"Update Monday, 26th of March: Almost the next day or the following day I published this post KyngChaos just published the QGIS 3 release for macOS. You can download here. Just a couple days ago I was about to write a post about how difficult, or almost impossible, is to install the last versions of QGIS on macOS right now. Everything started, I believe, when gdal package got update at the beginning of the week and that broke my install of QGIS 2 even thought, and to be honest, I really don’t know if all this mess was caused for that update, or by the update of the python formulae in Homebrew. Anyhow, usually these problems are solved just rebuilding the app from source using the new packages, but in this occasion that solution wasn’t working. Homebrew decided that on the first of March the behavior of the Python formulae and the name, and I believe the name of the formulae, was going to change to be more consistent. To sum a little bit up, after the change python was going to point to python3 in your shell and python2 is going point to so python2 —or something like that. However, the change in the command in the CLI  broke a truckload of third party software, and seems that also wasn’t compliant with Python’s policy. So… they decided to change some things back —CLI commands, no formulae names— and now seems that python ➜ python2 and python3 ➜ python3. If you are confused, don’t worry, am I also. Besides, since I’m not an expert in the matter and I’ve perhaps missed something in all this chaos. In consequence… I really don’t know!. Anyhow and right now, with the current state of Homebrew and the OSGeo/homebrew-osgeo4mac tap, it’s quite difficult to install the last versions of QGIS in macOS. A few weeks ago, QGIS released QGIS 3 Girona, however it’s only possible to install it right now in Windows and Linux. Usually on macOS the releases has been a little bit slower than in other platforms basically because QGIS has really few developers able to work on macOS and seems that things aren’t as easy as in other platforms. Traditionally, Homebrew has come to the rescue with OSGeo/homebrew-osgeo4mac tap, which you can build your own version of QGIS, but that repo hasn’t been update almost since the beginning of December. This time the delay not only mean that the macOS users not only can’t install the last small incremental change version, but that for more than 3 weeks we aren’t able to install the last version, which means a big leap from version 2 to 3. This left the macOS users a little bit hanging although we still can download the official build for macOS in the KyngChaos{.reference.external} download page, where you can find the 2.18.14 version. The problem is that version isn’t even the last version of the long-term repository release, which is 2.18.17. Nevertheless, this weekend I was able to rebuild the last version of the LTR of QGIS 2 and the developer version of QGIS3. I really don’t know how stable is the QGIS 3 developer version, but at least at first sight everything works and the app even open faster than the QGIS 2. How to install the last version of QGIS 2? What I did was just reinstall python, python2, gdal, gdal2, and finally qgis2. More or less as follows: 12345$ brew reinstall python2 python bison &amp;&amp;brew reinstall gdal2 \\    --with-armadillo --with-complete --with-libkml \\    --with-opencl --with-postgresql --with-unsupported$ brew reinstall qgis2 --with-grass --with-saga-gis-ltsAfter that and compiling here and there, I was able to open QGIS.app again. This left me with QGIS in /usr/local/Cellar/qgis2/2.18.14. But I want to have QGIS.app in /Applications folder so I have two options. First one is run in the following command in the terminal, as advised by Homebrew: 1$ brew linkapps [--local]However, I prefer to move the actual app to the /Applications folder and create a symbolic link on the /Cellar folder. 12$ mv -f /usr/local/Cellar/qgis2/2.18.14/QGIS.app /Applications$ ln -s /Applications/QGIS.app /usr/local/Cellar/qgis2/2.18.14/QGIS.appYet, weren’t we going to install the last version of QGIS? This isn’t the last version. OK… QGIS 2.18.17 To install the last version you need to change the the QGIS formulae to make it to download the last version from the LTR. Since Homebrew isn’t anything more than a git with Ruby scripts I recommend you to make a branch in the repository and change the formula. You aren’t going to change anything in Homebrew, but in a branch of tap, in the OSGeo/homebrew-osgeo4mac tap. I did the following. First, I create a branch and checked out on it. 123$ cd /usr/local/Homebrew/Library/Taps/osgeo/homebrew-osgeo4mac$ git checkout -b QGIS2.18.17$ brew edit qgis2Now you can edit the formula to be able to install QGIS 2.18.17. ~You can see how I modify mine~~1 below that has highlighted the lines I’ve changed. 1&lt;pre class=\"nums:true lang:ruby mark:12-13 decode:true\" title=\"qgis2.rb\" data-url=\"https://raw.githubusercontent.com/luisspuerto/homebrew-osgeo4mac/QGIS2.18.17/Formula/qgis2.rb\"&gt;Now you just commit. 12$ git stage Formula/qgis2.rb$ git commit -m \"qgis update to 2.18.17\"And now you just reinstall QGIS and move to /Applications: 123$ brew reinstall qgis2 --with-grass --with-saga-gis-lts$ mv -f /usr/local/Cellar/qgis2/2.18.17/QGIS.app /Applications$ ln -s /Applications/QGIS.app /usr/local/Cellar/qgis2/2.18.17/QGIS.app          QGIS 2.18.17 splash screen            QGIS 2.18.17 interface  Matplotlib Since Homebrew/homebrew-science has been deprecated and some of the formulae wasn’t migrated to the Homebrew/homebrew-core this left us with a message at the end of the QGIS’ compilation asking us to install matplotlib via pip. The following Python modules are needed by QGIS during run-time: 1234567The following Python modules are needed by QGIS during run-time:    matplotlib, pyparsingYou can install manually, via installer package or with `pip` (if availble):    pip install &lt;module&gt;  OR  pip-2.7 install &lt;module&gt;I had a problem and when I tried to install using pip install matplotlib threw me an error, though. 1234567891011121314151617181920212223242526272829303132Collecting matplotlib  Using cached matplotlib-2.2.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlRequirement already satisfied: subprocess32 in /usr/local/lib/python2.7/site-packages (from matplotlib)Requirement already satisfied: backports.functools-lru-cache in /usr/local/lib/python2.7/site-packages (from matplotlib)Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python2.7/site-packages (from matplotlib)Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python2.7/site-packages (from matplotlib)Requirement already satisfied: numpy&gt;=1.7.1 in /usr/local/lib/python2.7/site-packages (from matplotlib)Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python2.7/site-packages (from matplotlib)Requirement already satisfied: pytz in /usr/local/lib/python2.7/site-packages (from matplotlib)Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python2.7/site-packages (from matplotlib)Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python2.7/site-packages (from matplotlib)Requirement already satisfied: setuptools in /usr/local/lib/python2.7/site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib)Installing collected packages: matplotlibException:Traceback (most recent call last):  File \"/usr/local/lib/python2.7/site-packages/pip/basecommand.py\", line 215, in main    status = self.run(options, args)  File \"/usr/local/lib/python2.7/site-packages/pip/commands/install.py\", line 342, in run    prefix=options.prefix_path,  File \"/usr/local/lib/python2.7/site-packages/pip/req/req_set.py\", line 784, in install    **kwargs  File \"/usr/local/lib/python2.7/site-packages/pip/req/req_install.py\", line 851, in install    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)  File \"/usr/local/lib/python2.7/site-packages/pip/req/req_install.py\", line 1064, in move_wheel_files    isolated=self.isolated,  File \"/usr/local/lib/python2.7/site-packages/pip/wheel.py\", line 345, in move_wheel_files    clobber(source, lib_dir, True)  File \"/usr/local/lib/python2.7/site-packages/pip/wheel.py\", line 323, in clobber    shutil.copyfile(srcfile, destfile)  File \"/usr/local/Cellar/python@2/2.7.14_3/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 97, in copyfile    with open(dst, 'wb') as fdst:IOError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/site-packages/matplotlib/legend.pyc'Basically I had a ownership problem, that can be solve using sudo. 1$ sudo pip install matplotlibOr fixing the ownership like this: 1$ sudo chown -R $(echo $USER) ~/Library/Caches/pipNow, I was able to install. How to install QGIS 3? Well, this is a little bit more challenging, but just a little bit. The only version of a Homebrew formula that is available to install QGIS 3 is the developer version one that is in this qgis/homebrew-qgisdev repo-tap. So I just have to tap that repo: 1$ brew tap qgis/homebrew-qgisdevHowever, I needed to make changes in the formula to be able to install because it has a dependency on Matplotlib on Homebrew/homebrew-science and as we learned before that formula doesn’t exist anymore. In this case, it isn’t like in the QGIS 2, that it builds anyway and then ask you to install Matplotlib. It just doesn’t build and throws an error. I have two options here. I can just delete or comment the line where the dependency is called, or I can replace it for the legacy formula, which is located in the brewsci/homebrew-science tap. Either way I proceeded in the same way as I did previously. First, I created a branch and edited the formulae. 123$ cd /usr/local/Homebrew/Library/Taps/qgis/homebrew-qgisdev$ git checkout -b matplotlib-fix$ brew edit qgis3-devYou can check how I’ve edited mine. The important part is in the highlighted 86-87 lines. Then, I just committed my edits 12$ git add Formula/qgis3-dev.rb$ git commit -m \"fix for matplotlib\"Before I tried to build I have to do two more tweaks to be able to compile without errors. First I have to reinstall Bison. 1$ brew reinstall bisonAnd then I have to modify the file /usr/local/bin/pyrcc5 and change pythonw2.7 to python3. 12#!/bin/shexec python3 -m PyQt5.pyrcc_main ${1+\"$@\"}Now I could build QGIS 3 developer edition: 1$ brew install --no-sandbox qgis3-dev --with-grass --with-saga-gis-lts          QGIS 3 dev splash screen            QGIS 3 interface  After I finished building the QGIS 3, I moved the app from the Homebrew Cellar to the /Applications folder in the same way I moved QGIS 2, but since I want to keep QGIS 2 and QGIS 3, in the process I renamed the app to QGIS 3.app. 12$ mv /usr/local/opt/qgis3-dev/QGIS.app /Applications/QGIS\\ 3.app$ ln -s /Applications/QGIS\\ 3.app /usr/local/opt/qgis3-dev/QGIS.appFinal thoughts I hope that in the near future the situation improve and we can enjoy the last version of QGIS on macOS in a easier way. Perhaps even without needed to compile. However, in this very moment isn’t the case. You have to take into account that with this method you are installing the QGIS 3 developer version, so probably isn’t going to be really stable, or perhaps you are going to have no problem. I guess that you can install the stable version using the QGIS3-dev formulae, you just have to change the values branch =&gt; to \"release-3_0\" in line 37 and version to \"3.0\" on line 38. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590class Qgis3DevUnlinkedFormulae &lt; Requirement  fatal true  satisfy(:build_env =&gt; false) { !qt4_linked &amp;&amp; !pyqt4_linked &amp;&amp; !txt2tags_linked }  def qt4_linked    (Formula[\"qt\"].linked_keg/\"lib/QtCore.framework/Versions/4\").exist?  rescue    return false  end  def pyqt4_linked    (Formula[\"pyqt\"].linked_keg/\"lib/python2.7/site-packages/PyQt\").exist?  rescue    return false  end  def txt2tags_linked    Formula[\"txt2tags\"].linked_keg.exist?  rescue    return false  end  def message    s = \"Compilation can fail if these formulae are installed and linked:\\n\\n\"    s += \"Unlink with `brew unlink qt` or remove with `brew uninstall qt`\\n\" if qt4_linked    s += \"Unlink with `brew unlink pyqt` or remove with `brew uninstall pyqt`\\n\" if pyqt4_linked    s += \"Unlink with `brew unlink txt2tags` or remove with `brew uninstall txt2tags`\\n\" if txt2tags_linked    s  endendclass Qgis3Dev &lt; Formula  desc \"User friendly open source Geographic Information System\"  homepage \"https://www.qgis.org\"  url \"https://github.com/qgis/QGIS.git\", :branch =&gt; \"release-3_0\"  version \"3.0\"  option \"without-ninja\", \"Disable use of ninja CMake generator\"  option \"without-debug\", \"Disable debug build, which outputs info to system.log or console\"  option \"without-qt5-webkit\", \"Build without webkit based functionality\"  option \"without-pyqt5-webkit\", \"Build without webkit python bindings\"  option \"without-server\", \"Build without QGIS Server (qgis_mapserv.fcgi)\"  option \"without-postgresql\", \"Build without current PostgreSQL client\"  option \"with-globe\", \"Build with Globe plugin, based upon osgEarth\"  option \"with-grass\", \"Build with GRASS 7 integration plugin and Processing plugin support (or install grass-7x first)\"  option \"with-oracle\", \"Build extra Oracle geospatial database and raster support\"  option \"with-orfeo5\", \"Build extra Orfeo Toolbox for Processing plugin\"  option \"with-r\", \"Build extra R for Processing plugin\"  option \"with-saga-gis-lts\", \"Build extra Saga GIS for Processing plugin\"  # option \"with-qt-mysql\", \"Build extra Qt MySQL plugin for eVis plugin\"  option \"with-qspatialite\", \"Build QSpatialite Qt database driver\"  option \"with-api-docs\", \"Build the API documentation with Doxygen and Graphviz\"  option \"with-3d\", \"Build with 3D Map View panel\"  depends_on Qgis3DevUnlinkedFormulae  # core qgis  depends_on \"cmake\" =&gt; :build  depends_on \"ninja\" =&gt; [:build, :recommended]  depends_on \"bison\" =&gt; :build  depends_on \"flex\" =&gt; :build  if build.with? \"api-docs\"    depends_on \"graphviz\"    depends_on \"doxygen\"  end  depends_on :python3  depends_on \"qt\" # keg_only  depends_on \"osgeo/osgeo4mac/qt5-webkit\" =&gt; :recommended # keg_only  depends_on \"sip\"  depends_on \"pyqt\"  depends_on \"osgeo/osgeo4mac/pyqt5-webkit\" =&gt; :recommended  depends_on \"qca\"  depends_on \"qtkeychain\"  depends_on \"qscintilla2\"  depends_on \"qwt\"  depends_on \"qwtpolar\"  depends_on \"gsl\"  depends_on \"sqlite\" # keg_only  depends_on \"expat\" # keg_only  depends_on \"proj\"  depends_on \"spatialindex\"  # depends_on \"homebrew/science/matplotlib\" # deprecated  depends_on \"brewsci/science/matplotlib\"  depends_on \"fcgi\" if build.with? \"server\"  # use newer postgresql client than Apple's, also needed by `psycopg2`  depends_on \"postgresql\" =&gt; :recommended  depends_on \"libzip\"  # needed for PKI authentication methods that require PKCS#8-&gt;PKCS#1 conversion  depends_on \"libtasn1\"  # core providers  depends_on \"osgeo/osgeo4mac/gdal2\" # keg_only  depends_on \"osgeo/osgeo4mac/gdal2-python\" # keg_only  depends_on \"osgeo/osgeo4mac/oracle-client-sdk\" if build.with? \"oracle\"  # TODO: add MSSQL third-party support formula?, :optional  # core plugins (c++ and python)  if build.with?(\"grass\") || (HOMEBREW_PREFIX/\"opt/grass7\").exist?    depends_on \"osgeo/osgeo4mac/grass7\"    depends_on \"gettext\" # keg_only  end  # Not until osgearth is Qt5-ready  # if build.with? \"globe\"  #   # this is pretty borked with OS X &gt;= 10.10+  #   depends on \"open-scene-graph\"  #   depends on \"homebrew/science/osgearth\"  # end  depends_on \"gpsbabel\" =&gt; :optional  # TODO: remove \"pyspatialite\" when PyPi package supports spatialite 4.x  #       or DB Manager supports libspatialite &gt;= 4.2.0 (with mod_spatialite)  # TODO: what to do for Py3 and pyspatialite?  # depends on \"pyspatialite\" # for DB Manager  # depends on \"qt-mysql\" =&gt; :optional # for eVis plugin (non-functional in 2.x?)  # core processing plugin extras  # see `grass` above  depends_on \"osgeo/osgeo4mac/orfeo5\" =&gt; :optional  depends_on \"r\" =&gt; :optional  depends_on \"osgeo/osgeo4mac/saga-gis-lts\" =&gt; :optional  # TODO: LASTools straight build (2 reporting tools), or via `wine` (10 tools)  # TODO: Fusion from USFS (via `wine`?)  # TODO: add one for Py3  #       (only necessary when macOS ships a Python3 or 3rd-party isolation is needed)  # resource \"pyqgis-startup\" do  #   url \"https://gist.githubusercontent.com/dakcarto/11385561/raw/e49f75ecec96ed7d6d3950f45ad3f30fe94d4fb2/pyqgis_startup.py\"  #   sha256 \"385dce925fc2d29f05afd6508bc1f46ec84c0bc607cc0c8dfce78a4bb93b9c4e\"  #   version \"2.14.0\"  # end  needs :cxx11  def install    ENV.cxx11    # when gdal2-python.rb loaded, PYTHONPATH gets set to 2.7 site-packages...    #   clear it before calling any local python3 functions    ENV[\"PYTHONPATH\"] = nil    if ARGV.debug?      puts \"python_exec: #{python_exec}\"      puts \"py_ver: #{py_ver}\"      puts \"brewed_python?: #{brewed_python?}\"      puts \"python_site_packages: #{python_site_packages}\"      puts \"python_prefix: #{python_prefix}\"      puts \"qgis_python_packages: #{qgis_python_packages}\"      puts \"gdal_python_packages: #{gdal_python_packages}\"      puts \"gdal_python_opt_bin: #{gdal_python_opt_bin}\"      puts \"gdal_opt_bin: #{gdal_opt_bin}\"    end    # Vendor required python3 pkgs if they are missing    # TODO: this should really be a requirements.txt in src tree    py_req = %w[      future      psycopg2      python-dateutil      httplib2      pytz      six      nose2      pygments      jinja2      pyyaml      requests      owslib    ].freeze    orig_user_base = ENV[\"PYTHONUSERBASE\"]    ENV[\"PYTHONUSERBASE\"] = libexec/\"python\"    system HOMEBREW_PREFIX/\"bin/pip3\", \"install\", \"--user\", *py_req    ENV[\"PYTHONUSERBASE\"] = orig_user_base    # Set bundling level back to 0 (the default in all versions prior to 1.8.0)    # so that no time and energy is wasted copying the Qt frameworks into QGIS.    # Install custom widgets Designer plugin to local qt plugins prefix    mkdir lib/\"qt/plugins/designer\"    inreplace \"src/customwidgets/CMakeLists.txt\",              \"${QT_PLUGINS_DIR}/designer\", lib/\"qt/plugins/designer\".to_s    # Fix custom widgets Designer module install path    mkdir lib/\"python#{py_ver}/site-packages/PyQt5\"    inreplace \"CMakeLists.txt\",              \"${PYQT5_MOD_DIR}\", lib/\"python#{py_ver}/site-packages/PyQt5\".to_s    # Install db plugins to local qt plugins prefix    if build.with? \"qspatialite\"      mkdir lib/\"qt/plugins/sqldrivers\"      inreplace \"src/providers/spatialite/qspatialite/CMakeLists.txt\",                \"${QT_PLUGINS_DIR}/sqldrivers\", lib/\"qt/plugins/sqldrivers\".to_s    end    if build.with? \"oracle\"      inreplace \"src/providers/oracle/ocispatial/CMakeLists.txt\",                \"${QT_PLUGINS_DIR}/sqldrivers\", lib/\"qt/plugins/sqldrivers\".to_s    end    args = std_cmake_args    args &lt;&lt; \"-DCMAKE_BUILD_TYPE=RelWithDebInfo\" if build.with? \"debug\" # override    cmake_prefixes = %w[      qt5      qt5-webkit      qscintilla2      qwt      qwtpolar      qca      gdal2      gsl      geos      proj      libspatialite      spatialindex      expat      sqlite      libzip      flex      bison      fcgi    ].freeze    # Force CMake to search HB/opt paths first, so headers in HB/include are not found instead;    # specifically, ensure any gdal v1 includes are not used    args &lt;&lt; \"-DCMAKE_PREFIX_PATH=#{cmake_prefixes.map { |f| Formula[f.to_s].opt_prefix }.join(\";\")}\"    args += %w[      -DENABLE_TESTS=FALSE      -DENABLE_MODELTEST=FALSE      -DQGIS_MACAPP_BUNDLE=0      -DQGIS_MACAPP_INSTALL_DEV=FALSE      -DWITH_QWTPOLAR=TRUE      -DWITH_INTERNAL_QWTPOLAR=FALSE      -DWITH_ASTYLE=FALSE      -DWITH_QSCIAPI=TRUE      -DWITH_STAGED_PLUGINS=TRUE      -DWITH_GRASS=FALSE      -DWITH_CUSTOM_WIDGETS=TRUE    ]    args &lt;&lt; \"-DWITH_QTWEBKIT=#{build.with?(\"qt5-webkit\") ? \"TRUE\" : \"FALSE\"}\"    # Prefer opt_prefix for CMake modules that find versioned prefix by default    # This keeps non-critical dependency upgrades from breaking QGIS linking    args &lt;&lt; \"-DGDAL_LIBRARY=#{Formula[\"gdal2\"].opt_lib}/libgdal.dylib\"    args &lt;&lt; \"-DGEOS_LIBRARY=#{Formula[\"geos\"].opt_lib}/libgeos_c.dylib\"    args &lt;&lt; \"-DGSL_CONFIG=#{Formula[\"gsl\"].opt_bin}/gsl-config\"    args &lt;&lt; \"-DGSL_INCLUDE_DIR=#{Formula[\"gsl\"].opt_include}\"    args &lt;&lt; \"-DGSL_LIBRARIES='-L#{Formula[\"gsl\"].opt_lib} -lgsl -lgslcblas'\"    args &lt;&lt; \"-DWITH_SERVER=#{build.with?(\"server\") ? \"TRUE\" : \"FALSE\"}\"    args &lt;&lt; \"-DPOSTGRES_CONFIG=#{Formula[\"postgresql\"].opt_bin}/pg_config\" if build.with? \"postgresql\"    args &lt;&lt; \"-DWITH_GRASS7=#{(build.with?(\"grass\") || brewed_grass7?) ? \"TRUE\" : \"FALSE\"}\"    if build.with?(\"grass\") || brewed_grass7?      # this is to build the GRASS Plugin, not for Processing plugin support      grass7 = Formula[\"grass7\"]      args &lt;&lt; \"-DGRASS_PREFIX7='#{grass7.opt_prefix}/grass-base'\"      # Keep superenv from stripping (use Cellar prefix)      ENV.append \"CXXFLAGS\", \"-isystem #{grass7.prefix.resolved_path}/grass-base/include\"      # So that `libintl.h` can be found (use Cellar prefix; should not be needed anymore with QGIS 2.99+)      # ENV.append \"CXXFLAGS\", \"-isystem #{Formula[\"gettext\"].include.resolved_path}\"    end    args &lt;&lt; \"-DWITH_GLOBE=#{build.with?(\"globe\") ? \"TRUE\" : \"FALSE\"}\"    if build.with? \"globe\"      osg = Formula[\"open-scene-graph\"]      opoo \"`open-scene-graph` formula's keg not linked.\" unless osg.linked_keg.exist?      # must be HOMEBREW_PREFIX/lib/osgPlugins-#.#.#, since all osg plugins are symlinked there      args &lt;&lt; \"-DOSG_PLUGINS_PATH=#{HOMEBREW_PREFIX}/lib/osgPlugins-#{osg.version}\"    end    args &lt;&lt; \"-DWITH_ORACLE=#{build.with?(\"oracle\") ? \"TRUE\" : \"FALSE\"}\"    if build.with? \"oracle\"      oracle_opt = Formula[\"oracle-client-sdk\"].opt_prefix      args &lt;&lt; \"-DOCI_INCLUDE_DIR=#{oracle_opt}/include/oci\"      args &lt;&lt; \"-DOCI_LIBRARY=#{oracle_opt}/lib/libclntsh.dylib\"    end    args &lt;&lt; \"-DWITH_QSPATIALITE=#{build.with?(\"qspatialite\") ? \"TRUE\" : \"FALSE\"}\"    args &lt;&lt; \"-DWITH_APIDOC=#{build.with?(\"api-docs\") ? \"TRUE\" : \"FALSE\"}\"    args &lt;&lt; \"-DWITH_3D=#{build.with?(\"3d\") ? \"TRUE\" : \"FALSE\"}\"    # nix clang tidy runs    args &lt;&lt; \"-DCLANG_TIDY_EXE=\"    # if using Homebrew's Python, make sure its components are always found first    # see: https://github.com/Homebrew/homebrew/pull/28597    ENV[\"PYTHONHOME\"] = python_prefix    # handle custom site-packages for keg-only modules and packages    ENV.append_path \"PYTHONPATH\", python_site_packages    ENV.append_path \"PYTHONPATH\", libexec/\"python/lib/python/site-packages\"    # handle some compiler warnings    # ENV[\"CXX_EXTRA_FLAGS\"] = \"-Wno-unused-private-field -Wno-deprecated-register\"    # if ENV.compiler == :clang &amp;&amp; (MacOS::Xcode.version &gt;= \"7.0\" || MacOS::CLT.version &gt;= \"7.0\")    #   ENV.append \"CXX_EXTRA_FLAGS\", \"-Wno-inconsistent-missing-override\"    # end    ENV.prepend_path \"PATH\", libexec/\"python/bin\"    mkdir \"build\" do      # editor = \"/usr/local/bin/bbedit\"      # cmake_config = Pathname(\"#{Dir.pwd}/#{name}_cmake-config.txt\")      # cmake_config.write [\"cmake ..\", *args].join(\" \\\\\\n\")      # system editor, cmake_config.to_s      # raise      system \"cmake\", \"-G\", build.with?(\"ninja\") ? \"Ninja\" : \"Unix Makefiles\", *args, \"..\"      # system editor, \"CMakeCache.txt\"      # raise      system \"cmake\", \"--build\", \".\", \"--target\", \"all\", \"--\", \"-j\", Hardware::CPU.cores      system \"cmake\", \"--build\", \".\", \"--target\", \"install\", \"--\", \"-j\", Hardware::CPU.cores    end    # Fixup some errant lib linking    # TODO: fix upstream in CMake    dy_libs = [lib/\"qt/plugins/designer/libqgis_customwidgets.dylib\"]    dy_libs &lt;&lt; lib/\"qt/plugins/sqldrivers/libqsqlspatialite.dylib\" if build.with? \"qspatialite\"    dy_libs.each do |dy_lib|      MachO::Tools.dylibs(dy_lib.to_s).each do |i_n|        %w[core gui native].each do |f_n|          sufx = i_n[/(qgis_#{f_n}\\.framework.*)/, 1]          next if sufx.nil?          i_n_to = \"#{opt_prefix}/QGIS.app/Contents/Frameworks/#{sufx}\"          puts \"Changing install name #{i_n} to #{i_n_to} in #{dy_lib}\" if ARGV.debug?          dy_lib.ensure_writable do            MachO::Tools.change_install_name(dy_lib.to_s, i_n.to_s, i_n_to, :strict =&gt; false)          end        end      end    end    # Update .app's bundle identifier, so other installers doesn't get confused    inreplace prefix/\"QGIS.app/Contents/Info.plist\",              \"org.qgis.qgis3\", \"org.qgis.qgis3-hb-dev\"    py_lib = lib/\"python#{py_ver}/site-packages\"    py_lib.mkpath    ln_s \"../../../QGIS.app/Contents/Resources/python/qgis\", py_lib/\"qgis\"    ln_s \"QGIS.app/Contents/MacOS/fcgi-bin\", prefix/\"fcgi-bin\" if build.with? \"server\"    doc.mkpath    mv prefix/\"QGIS.app/Contents/Resources/doc/api\", doc/\"api\" if build.with? \"api-docs\"    ln_s \"../../../QGIS.app/Contents/Resources/doc\", doc/\"doc\"    # copy PYQGIS_STARTUP file pyqgis_startup.py, even if not isolating (so tap can be untapped)    # only works with QGIS &gt; 2.0.1    # doesn't need executable bit set, loaded by Python runner in QGIS    # TODO: for Py3    # (libexec/\"python\").install resource(\"pyqgis-startup\")    bin.mkdir    qgis_bin = bin/name.to_s    touch qgis_bin.to_s # so it will be linked into HOMEBREW_PREFIX    qgis_bin.chmod 0755    post_install  end  def post_install    # configure environment variables for .app and launching binary directly.    # having this in `post_intsall` allows it to be individually run *after* installation with:    #    `brew postinstall -v &lt;formula-name&gt;`    app = prefix/\"QGIS.app\"    tab = Tab.for_formula(self)    opts = tab.used_options    # define default isolation env vars    pthsep = File::PATH_SEPARATOR    pypth = python_site_packages.to_s    pths = %w[      /usr/bin      /bin      /usr/sbin      /sbin      /opt/X11/bin      /usr/X11/bin      #{opt_libexec}/python/bin    ]    # unless opts.include?(\"with-isolation\")    #   pths = ORIGINAL_PATHS.dup    #   pyenv = ENV[\"PYTHONPATH\"]    #   if pyenv    #     pypth = pyenv.include?(pypth) ? pyenv : pypth + pthsep + pyenv    #   end    # end    unless pths.include?(HOMEBREW_PREFIX/\"bin\")      pths = pths.insert(0, HOMEBREW_PREFIX/\"bin\")    end    # set install's lib/python#{py_ver}/site-packages first, so app will work if unlinked    pypths = %W[      #{opt_lib}/python#{py_ver}/site-packages      #{opt_libexec}/python/lib/python/site-packages      #{pypth}    ]    pths.insert(0, gdal_opt_bin)    pths.insert(0, gdal_python_opt_bin)    pypths.insert(0, gdal_python_packages)    if opts.include?(\"with-gpsbabel\")      pths.insert(0, Formula[\"gpsbabel\"].opt_bin.to_s)    end    envars = {      :PATH =&gt; pths.join(pthsep),      :PYTHONPATH =&gt; pypths.join(pthsep),      :GDAL_DRIVER_PATH =&gt; \"#{HOMEBREW_PREFIX}/lib/gdalplugins\",      :GDAL_DATA =&gt; \"#{Formula[\"gdal2\"].opt_share}/gdal\",    }    # handle multiple Qt plugins directories    qtplgpths = %W[      #{Formula[\"qt\"].opt_prefix}/plugins      #{HOMEBREW_PREFIX}/lib/qt/plugins    ]    envars[:QT_PLUGIN_PATH] = qtplgpths.join(pthsep)    proc_algs = \"Contents/Resources/python/plugins/processing/algs\"    if opts.include?(\"with-grass\") || brewed_grass7?      grass7 = Formula[\"grass7\"]      # for core integration plugin support      envars[:GRASS_PREFIX] = \"#{grass7.opt_prefix}/grass-base\"      begin        inreplace app/\"#{proc_algs}/grass7/Grass7Utils.py\",                  \"'/Applications/GRASS-7.{}.app/Contents/MacOS'.format(version)\",                  \"'#{grass7.opt_prefix}/grass-base'\"        puts \"GRASS 7 GrassUtils.py has been updated\"      rescue Utils::InreplaceError        puts \"GRASS 7 GrassUtils.py already updated\"      end    end    unless opts.include?(\"without-globe\")      osg = Formula[\"open-scene-graph\"]      envars[:OSG_LIBRARY_PATH] = \"#{HOMEBREW_PREFIX}/lib/osgPlugins-#{osg.version}\"    end    # TODO: add for Py3    # if opts.include?(\"with-isolation\") || File.exist?(\"/Library/Frameworks/GDAL.framework\")    #   envars[:PYQGIS_STARTUP] = opt_libexec/\"python/pyqgis_startup.py\"    # end    # envars.each { |key, value| puts \"#{key.to_s}=#{value}\" }    # exit    # add env vars to QGIS.app's Info.plist, in LSEnvironment section    plst = app/\"Contents/Info.plist\"    # first delete any LSEnvironment setting, ignoring errors    # CAUTION!: may not be what you want, if .app already has LSEnvironment settings    dflt = `defaults read-type \\\"#{plst}\\\" LSEnvironment 2&gt; /dev/null`    `defaults delete \\\"#{plst}\\\" LSEnvironment` if dflt    kv = \"{ \"    envars.each { |key, value| kv += \"'#{key}' = '#{value}'; \" }    kv += \"}\"    `defaults write \\\"#{plst}\\\" LSEnvironment \\\"#{kv}\\\"`    # add ability to toggle high resolution in Get Info dialog for app    hrc = `defaults read-type \\\"#{plst}\\\" NSHighResolutionCapable 2&gt; /dev/null`    `defaults delete \\\"#{plst}\\\" NSHighResolutionCapable` if hrc    `defaults write \\\"#{plst}\\\" NSHighResolutionCapable \\\"True\\\"`    # leave the plist readable; convert from binary to XML format    `plutil -convert xml1 -- \\\"#{plst}\\\"`    # make sure plist is readble by all users    plst.chmod 0644    # update modification date on app bundle, or changes won't take effect    touch app.to_s    # add env vars to launch script for QGIS app's binary    qgis_bin = bin/name.to_s    rm_f qgis_bin if File.exist?(qgis_bin) # install generates empty file    bin_cmds = %W[#!/bin/sh\\n]    # setup shell-prepended env vars (may result in duplication of paths)    unless pths.include? HOMEBREW_PREFIX/\"bin\"      pths.insert(0, HOMEBREW_PREFIX/\"bin\")    end    # even though this should be affected by with-isolation, allow local env override    pths &lt;&lt; \"$PATH\"    pypths &lt;&lt; \"$PYTHONPATH\"    envars[:PATH] = pths.join(pthsep)    envars[:PYTHONPATH] = pypths.join(pthsep)    envars.each { |key, value| bin_cmds &lt;&lt; \"export #{key}=#{value}\" }    bin_cmds &lt;&lt; opt_prefix/\"QGIS.app/Contents/MacOS/QGIS \\\"$@\\\"\"    qgis_bin.write(bin_cmds.join(\"\\n\"))    qgis_bin.chmod 0755  end  def caveats    s = &lt;&lt;-EOS.undent      Bottles support only Homebrew's Python3      QGIS is built as an application bundle. Environment variables for the      Homebrew prefix are embedded in QGIS.app:        #{opt_prefix}/QGIS.app      You may also symlink QGIS.app into /Applications or ~/Applications:        brew linkapps [--local]      To directly run the `QGIS.app/Contents/MacOS/QGIS` binary use the wrapper      script pre-defined with Homebrew prefix environment variables:        #{opt_bin}/#{name}      NOTE: Your current PATH and PYTHONPATH environment variables are honored            when launching via the wrapper script, while launching QGIS.app            bundle they are not.      For standalone Python3 development, set the following environment variable:        export PYTHONPATH=#{qgis_python_packages}:#{gdal_python_packages}:#{python_site_packages}:$PYTHONPATH    EOS    s += &lt;&lt;-EOS.undent      If you have built GRASS 7 for the Processing plugin set the following in QGIS:        Processing-&gt;Options: Providers-&gt;GRASS GIS 7 commands-&gt;GRASS 7 folder to:           #{HOMEBREW_PREFIX}/opt/grass7/grass-base    EOS    s  end  test do    output = `#{bin}/#{name.to_s} --help 2&gt;&amp;1` # why does help go to stderr?    assert_match /^QGIS is a user friendly/, output  end  private  def brewed_grass7?    Formula[\"grass7\"].opt_prefix.exist?  end  def python_exec    if brewed_python?      Formula[\"python3\"].opt_bin/\"python3\"    else      py_exec = `which python3`.strip      raise if py_exec == \"\"      py_exec    end  end  def py_ver    `#{python_exec} -c 'import sys;print(\"{0}.{1}\".format(sys.version_info[0],sys.version_info[1]))'`.strip  end  def brewed_python?    Formula[\"python3\"].linked_keg.exist?  end  def python_site_packages    HOMEBREW_PREFIX/\"lib/python#{py_ver}/site-packages\"  end  def python_prefix    `#{python_exec} -c 'import sys;print(sys.prefix)'`.strip  end  def qgis_python_packages    opt_lib/\"python#{py_ver}/site-packages\".to_s  end  def gdal_python_packages    Formula[\"gdal2-python\"].opt_lib/\"python#{py_ver}/site-packages\".to_s  end  def gdal_python_opt_bin    Formula[\"gdal2-python\"].opt_bin.to_s  end  def gdal_opt_bin    Formula[\"gdal2\"].opt_bin.to_s  end  def module_importable?(mod)    `#{python_exec} -c 'import sys;sys.path.insert(1, \"#{gdal_python_packages}\"); import #{mod}'`.strip  endendAnyhow, I think I’m going to keep the 3.1 version for a while.             No, you can see that because I deteletd the branch… Sorry. &#8617;       ","categories": ["GIS","Personal","Technology"],
        "tags": ["homebrew","macOS","qgis"],
        "url": "https://luisspuerto.net/blog/2018/03/12/qgis-on-macos-with-homebrew/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/QGIS_logo_2017.svg.png"},{
        "title": "Updating to R 3.4.4 \"Someone to Lean On\"",
        "excerpt":"Just today yesterday Last Thursday —took me more that I expected to have a moment to write finish this post— R was updated to 3.4.4 and this new released is called “Someone to Lean On”, which is —as all the rest are— a reference to Peanuts comic. These are the released notes:   NEW FEATURES:       Sys.timezone() tries more heuristics on Unix-alikes and so is more likely to succeed (especially on Linux).  For the slowest method, a warning is given recommending that TZ is set to avoid the search.    The version of LAPACK included in the sources has been updated to 3.8.0 (for the routines used by R, a very minor bug-fix change).    parallel::detectCores(logical = FALSE) is ignored on Linux systems, since the information is not available with virtualized OSes.    INSTALLATION on a UNIX-ALIKE:       Configure will use pkg-config to find the flags to link to jpeg if available (as it should be for the recently-released jpeg-9c and libjpeg-turbo).  (This amends the code added in R 3.3.0 as the module name in jpeg-9c is not what that tested for.)    DEPRECATED AND DEFUNCT:       Sys.timezone(location = FALSE) (which was a stop-gap measure for Windows long ago) is deprecated.  It no longer returns the value of environment variable TZ (usually a location).    Legacy support of make macros such as CXX1X is formally deprecated: use the CXX11 forms instead.    BUG FIXES:    power.prop.test() now warns when it cannot solve the problem, typically because of impossible constraints. (PR#17345)    removeSource() no longer erroneously removes NULL in certain cases, thanks to D’enes T’oth.    nls(`NO [mol/l]` ~ f(t)) and nls(y ~ a) now work.  (Partly from PR#17367)    R CMD build checks for GNU cp rather than assuming Linux has it. (PR#17370 says ‘Alpine Linux’ does not.)    Non-UTF-8 multibyte character handling fixed more permanently  (PR#16732).    sum(, ) is more consistent. (PR#17372)    rf() and rbeta() now also work correctly when ncp is not scalar, notably when (partly) NA.  (PR#17375)    R CMD INSTALL now correctly sets C++ compiler flags when all source files are in sub-directories of src.  If you are on macOS and you want to enjoy the improvements and the bug fixings, you just can download the binary from CRAN or if you are a Homebrew user you just can update with the following command 1$ brew update &amp;&amp; brew upgradeThis time the binaries for macOS came almost as the same time as the binaries for the rest of the platforms and I really welcome the change and the diligence. Sometimes I feel as a macOS user a second class user in some open source projects, since they release the new versions a little bit later on macOS than in the rest of the platforms. However, I really appreciate the work that all these people put in develop R and to bring to it to the macOS ecosystem. I acknowledge that they are doing a non-payed job and they are doing it for the community of users, which is incredible remarkable. On the other hand, this time Homebrew was the one falling back a little bit, and on Thursday afternoon the formula to install R hadn’t been updated yet. So I just, just decided to update myself and make my first contribution to the Homebrew project. Update a Homebrew formula isn’t rocket science, and they even have a script to make things easier, so I really encourage you to update Homebrew formula and contribute to the community. In the next post I’ll try to explain the procedure of how to update a Homebrew formula. Happy data analysis with the new R. ","categories": ["Professional","RStats","Technology"],
        "tags": ["data science","homebrew","RStats"],
        "url": "https://luisspuerto.net/blog/2018/03/19/updating-to-r-3-4-4-someone-to-lean-on/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/someoonetoleanon.jpg"},{
        "title": "How I updated the R formula in Homebrew",
        "excerpt":"As I just explained in my last post, the last version of R —3.4.4 “Someone to Lean on”— was rolled out las Thursday and this time I was the one that updated the Homebrew’s formula to reflect the new version. I just decided to give it a try and update for first time a Homebrew’s formula since no one had updated it yet on Thursday afternoon and this way I would be able to install the new version with Homebrew. As I’ve already mentioned, I really encourage anyone to contribute to Homebrew’s community and try to keep the formulae update. Homebrew also encourage this, since as more people keep an eye on formula and update them, the better for the community. How can you update a Homebrew formula? The first and foremost important thing is to check if someone already filed a pull request for that same formulae, or in other words, if that formula is in the process of being updated. If no one is updating that formula, it’s opportunity to contribute and update it for the benefit of the community. Before you begin, you need to update Homebrew to get the last version: 1$ brew updateWhen you have the last version of Homebrew, you can edit your formula. If you just going to update the formula because there is a new version of the software that the formula installs, the best way to go is to use the script Homebrew provided to update formulae. In the case of R formula —r.rb— the syntax was as follows. 1$ brew bump-formula-pr --strict R with --url=https://cran.r-project.org/src/base/R-3/R-3.4.4.tar.gz and --sha256=b3e97d2fab7256d1c655c4075934725ba1cd7cb9237240a11bb22ccdad960337In this case, the URL and the sha256 was provided by Peter Dalgaard in the R 3.4.4 announcement. However, you have to take into account that https urls are preferred, so I had to recommit to follow that guidelines. If you don’t have the sha256, you can calculate it yourself downloading the file and then running the following command that for me was as follows: 1$ openssl sha -sha256 ~/Downloads/R-3.4.4.tar.gzWhen you have those two parameters, you are ready to run the command. What the command does is basically create a fork of Homebrew in your account of Github, and then create a branch where it’s going to upload the modified formula. Then, it just makes a pull request to Homebrew/homebrew-core.  If everything is ok, they’ll accept your changes and the new formula will be accessible to everyone after they run $ brew update. On the other hand, if you have to make modifications in the formula you are submitting in your pull request —as I needed to make— you just do them using Git. 123$ cd /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core # go to your local repo for Homebrew$ git branch # here you select the branch with the name of the update you are creating$ brew edit R # your preferred editor with openNow, you can make the necessary changes and when you are done you just save the file and 123$ git add R.rb # in this specific case$ git commit -m \"fixed the previous error\"$ git push YourForkOfTheRepo TheNameOfTheBranchIf you want to test your version of the formula this is easy, you just stay in the branch where the modified formula is and run: 1$ brew upgrade R          Updating R with Homebrew  Use someone else’s formula You can even use this updated formula to update the R of someone computer while they accept your pull request —if you are in a hurry or you are antsy guy. To do so you can use hub. 1234$ brew install hub$ brew update$ cd $(brew --repository)$ hub pull someone_elseOr you can directly install the formula that is their repo in GitHub: 1$ brew install https://raw.github.com/user/repo/branch/formula.rbIn my case: 1$ brew install https://github.com/luisspuerto/homebrew-core/blob/r-3.4.4/Formula/r.rbOr pull the formula from the pull request: 1$ brew pull https://github.com/Homebrew/homebrew-core/pull/1234In my case: 1$ brew pull https://github.com/Homebrew/homebrew-core/pull/25321However, I don’t recommend you to do something like this and install the someone’s formula unless you really know the person. You never know what it’s in the install script. Usually, pull request are resolved within hours and it’s much better practice to wait until the Homebrew maintainers review the updated formula and approve it. ","categories": ["RStats","Technology"],
        "tags": ["data science","homebrew","RStats"],
        "url": "https://luisspuerto.net/blog/2018/03/19/how-i-updated-the-r-formula-in-homebrew/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/R-Homebrew.jpg"},{
        "title": "Why don't I like Facebook anymore?",
        "excerpt":"          #deletefacebook from TechCrunch post.  It’s funny, but I was on my way to write this post about why I don’t like Facebook anymore and suddenly the Cambridge Analytica scandal about Facebook just explode the last weekend. At the moment of writing this post, the front page of Reddit has a good number of posts about the scandal and r/Technology —the screenshot— is full of post about the issue. Not to mention that are also a couple of good posts in r/Politics, r/Worldnews and r/News. And of course all over the Internet too. There is even a hashtag in Twitter —#DeleteFacebook— with an even other hashtags associated —like #cambridgeanalytics— where people look for advice to delete their data from Facebook accounts and are vowing they are going to delete their accounts. All of this scandal started —I think— with this article on The Guardian, where an ex-employee and co-founder of Cambridge Analytica denounced how they harvested information from about 50 million of Facebook accounts. Not so much, if you take into account that Facebook has 2.2. billion of users. All of this touches me a little bit closer, since I really believe that Data Science —yes this is what Cambridge Analytica was doing, Data Science— is here to help people to improve their lives and to understand better our world and lives, not to try to swing elections. Basically, what they were doing was to understand the psychological profiles of those Facebook profiles and then they crafted messages that appealed to their most inner core values to make them vote or change their vote in the elections. In other words “information warfare” at the service of political ideologies, or perhaps in this case not even that, just at the service of the powerful. Something, that surprisingly —or unsurprisingly— has been already depicted on media.           I bet these two don’t have a Facebook account  However, this is not a post about how bad Facebook is, about your privacy or conspiracy theories about how they  and other social media platforms and networks want to harvest your data to sell it and to control you. Don’t worry, I’m not going to ask you to delete your Facebook, Twitter, Google+ or [put here whatever social network you are concerned about] accounts, get a tinfoil hat and hide in your basement. That is totally up to you, and how crazy you are about the issue, and I really think it’s a really personal decision. I still believe that social networks, Facebook included, are services that really can help us to connect with other people all over the world, organize events or make us discover what is going on in our city, university or whatever social group or circle you are involved. I don’t think that hiding is the answer either, but exactly one of the exacts reactions they want us to have. They want us to shut up, get quiet, be scared, follow their commands and continue with our lives. When we don’t share our ideas —political or not— our good moments, our photos, our lives… because we’re scare of what other people may think or what we can lose, then we are losing and they are winning. Do we really want to live in a society where what you shared in a social network, or any other public platform, at some point could be the difference between have some job, or be attacked by others? If we lose our freedom of speak up about what we think isn’t right them we turned our society into a kind of social dictatorship. Honest and respectful debate always helps, no mater the topic. Perhaps you are wondering who are they… well this is going to be a shock perhaps, but they are you and me and the next guy and other guy a little bit away. They is society, and it’s a system, we’re we all interact. Perhaps some people has a longer lever than others, or even have more than one lever, or even they have some other people working for them with their levers, but we all are they and we can interact in the system. So, we all part and solution of the problem. Nevertheless, Facebook has lost its appeal for me and I no longer interested in spend a lot of time there. I would even say that my life has improved since I’m there just a couple of times a week and just for a couple of minutes. I just find it boring and no longer fits my communication and social needs. Why? Well there are several reasons and I’ll try to explain them next. Facebook isn’t the correct format for me anymore I don’t feel interested to share content on Facebook anymore because I find if too simple. Although it’s more painful, it takes me more effort, I prefer blogging. Blogging allows me to create more complex post and develop a much great deal of ideas in comparison with Facebook. Facebook is designed to share small pieces of text without almost any formatting. This makes really difficult to create and explain complex ideas. Also usually when you write too much, Facebook just hide it and put a button to expand the text. It’s true that you can share other content and not only photos in Facebook, but I find other networks more suitable to do it. If I just want to share a couple of photos, usually Instagram fits the bill much better and if want to share a whole album Flickr looks better suited for that.           Facebook update box  Before Facebook came out that was the way we shared content, using multiple open services. After ponder how Facebook has contributed to share that content I think that with nothing positive or worthy. More the contrary, our content now is trapped in a platform that unless you have an account you see or share with others. It’s stuck there forever. I really like the kind of interaction a blog provides. More meaningful, real and open. It allows me share content in more rich and diverse ways. Facebook is an attention whore This’s something that I really detest from Facebook with all my soul and I think it has become more acute lately. I really don’t know if it’s because this has been always the case, but since now I spend much much less time there —so they are trying to lure me back— or because they’ve deployed that policy lately to try to keep people engaged to the platform. I abhor it so much that I finally deleted the app from my iPhone and iPad because to get rid of the notifications and red bubbles. Facebook want you to be inside of its interface as much as you can, so if you don’t hang out there for a bit, it’s going to create for you fake notifications to lure you into the application. At least in my case they where in the form of “friend has publish a photo” or “random friend has updated their state for a while”, when I have disable those kind of notifications in my profile. I’ve read somewhere that this is supposedly a bug in Facebook, but I really doubt it. A big company like Facebook seldom make that kind of errors, and even less they keep for so long.  This is clearly a designed feature to lure you again inside. Other typical notifications were about some event that this or the other friend were about to attend and they were totally not interesting for me. Why? Whyyyyy? Almost, 99% of those notifications had zero interest for me and were really annoying in the end. Ads everywhere and in hiding in multiple forms Facebook is full of ads. They are the source of their revenue. They have ads in the sidebar, featured groups, pages, someone you perhaps know has liked some page, a featured post here and there… I despise that. I understand that as a company needs revenue to run their payroll and their servers, but at least in my opinion this is too much for me. Google has a much better approach, trying to be as less intrusive as possible. Normally, I use a script on my browser —F.B. Purity— that, on top of the ad blocker, remove all those annoyances. However I can’t have it on my mobile and my tablet. It would be fine if they had some ad here and there, but not every three post or something like that. For me the most annoying thing are when Facebook pretend that an advertisement could be disguised as an interaction from one of your friends. Please don’t do that, don’t build fake stories to fill the timeline. Toxic or silly conversation       Facebook has become a political tool, proof of this is just the last weekend scandal about Cambridge Analytical, and that is the less obvious way. And I say less obvious because they were doing it on the hiding.  However, there’re much most obvious ways to use Facebook —or Twitter— as a political tool. There is an incredible amount of pages and groups which aim is to discuss politics promote political ideas, or rather, be a battering ram against the opposite political group. There is a lot of toxic people and conversation there and a lot of disrespect for other. Besides, conversations can get pretty hairy easily, and you can easily be called names quick just to express your opinion with respect. Suddenly, people get angry or offended really fast and they don’t behave like they were talking to other human being but just to their computers. Computers and technology facilitate communication, but it also make it easy to forget that in the other side there is someone with feelings. On the other hand, Facebook is full of content that doesn’t have any interested for me and due the way Facebook is design it ended in my timeline. I really care about my friends and what is going on with their lives,  but I even care more when we are able to be together in the same spacetime, have a beer and talk. In other words, meaningful and real social interaction. Time consuming Facebook is a time-consuming machine and it’s been designed for that, to trap us inside and keeps us browsing and browsing the life of others. That doesn’t have any sense for me, doesn’t produce anything or have any outcome and in the end keep me separate from others. I like much more to spend time writing in English this blog about what I care and like, and using it to improve my English skills. When the web 2.0 came out everyone talked about being a prosumer —producer and consumer. I think that facebook has make us to be just consumers. Consumers of the life of others instead of producing out own life. I prefer Twitter or Reddit Although Twitter has some of the same problems that Facebook has, I prefer it because it’s much simpler. You have a small set of characters —240— so you have to be brief and direct and it’s mean to be use in real time. You don’t browse your the timeline so much back in time, perhaps just one hour or so, so you don’t spend too much time there. What it’s important is now &amp; here.  You can have a richer timeline in Twitter since it’s totally open, or most people use it that way. You don’t need to be friend of someone, you just follow them. I can interact there not only with friends and family, but almost with anyone, which is great. Personal and professional interactions also mix up, which make it more real. Everyone is at the same level. Twitter has also ads and fake notifications —someone and some other have liked some third person post. However, they are easily avoidable if you use a third-party app, as I do —TweetBot. I also like Reddit a lot. Reddit is really organic and mostly anonymous. You don’t even need to have an email account to register. I almost find gems in Reddit everyday. However, I don’t know if I would call reddit a social network, or just a place where people share stuff and other vote how worthy it’s and make comments about it. Reddit is composed of subreddits, that are like thematic sub-forums or something like that. The mechanic of Reddit is really simple. Someone post something, usually a piece of text, which could be more complex than anything you can post in Facebook, or a link to something —image, gif, video, or other webpage. From there on things begin to become pretty wild and organic. Every post could be voted —positively or negatively— there are comments, people commenting in those comments and so on… Comments can be voted too. This creates a pretty interesting democratic structure where the most interesting content —for the community— get up in the page and the less interesting is buried to the bottom. It isn’t perfect, of course, but since it’s pretty democratic and free, the outcome is quite interesting and sometimes unpredictable. It isn’t free of toxicity and a week ago or so, the New Yorker, whose parent company owns Reddit, published an article about their struggle to keep things free of trolls and toxic conversation. There has been also pretty mess up things, like when they thought that they have capture the Boston bomber and other pretty similar things. Mobs and circle-jerking are dangerous everywhere. Bottom line As a result, I really think that I’m going to use less and less Facebook. I don’t think that I’m going to delete my account or just stop to use it. Facebook is still a valuable tool for me, it allows me to connect with my friends around the globe, specially with the Spanish ones. However, I encourage you to use other way to contact me, like email, messaging or just phone me if you know my number. What probably is going to change is the way I interact there and the time I’m going to spend around, and I’m probably to spend more and more time creating post in this blog and less just browsing Facebook. ","categories": ["Personal","Technology"],
        "tags": ["blogs","data science","facebook","privacy","social media"],
        "url": "https://luisspuerto.net/blog/2018/03/21/why-dont-i-like-facebook-anymore/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/Facebook-dislike.jpg"},{
        "title": "Updating Homebrew, R and Python pip packages + Ruby Gems + macOS",
        "excerpt":"Update Monday 2nd of April 2018: I decided to add to this post how to update the RubyGems since they are a key feature of Jekyll. Update Thursday, 19th of April 2018 11.00 UTC+3: I added info about how to update on the CLI the App Store Apps and macOS software updates. In the post about Homebrew I think I’ve already posted how I update Homebrew packages with a single comment in the terminal. However these days I update more software via terminal, mainly packages, because it’s really handy run just a couple of commands and then see how the software it’s updated automatically and easily. Homebrew packages To update Homebrew packages I run: 1$ brew update &amp;&amp; brew upgrade &amp;&amp; brew cleanup &amp;&amp; brew prune &amp;&amp; brew cu -ay &amp;&amp; brew cask cleanup  brew update updates Homebrew itself and download the last version of the formulae  brew upgrade updates the packages you have installed that have new formulae.  brew cleanup cleans the cache of old versions of packages.  brew prune clean the old symbolic links form `/usr/bin/`.  brew cu -ay uses buo/homebrew-cask-upgrade to update casks. -ay flag is all and yes update all outdated apps.  brew cask cleanup clean the old caches of the updated apps.If for some reason you don’t want to update an specific package in Homebrew, you can _pin _in to an specific version or the current version. 1$ brew pin &lt;formulae&gt;R packages To update R packages I run: 1234# to see what are the old packages$ Rscript --vanilla -e \"old.packages(repos = 'cloud.r-project.org')\"# to directly update$ Rscript --vanilla -e \"update.packages(ask = F, repos = 'cloud.r-project.org')\"Update R packages on terminal is done using the command Rscript that allows us to send commands to R using the shell. I use the flag --vanilla that combine --no-save, --no-restore, --no-site-file--no-init-file and --no-environ. In other words a way to load R faster and with a standard configuration. I like to run old.packages first because I like to see a list first of the packages I’m going to update and then update. I do this because some packages —data.table— need a different makevars than the rest of the packages so just in case I needed to change the makevars and rebuild that package. I really think it would be cool to be able also _pin _packages in R, but I haven’t found any way to do so at system wide level. You can do easily at project level with the package Packrat. However, I really think it would be really nice to have email notifications when new versions of packages hit CRAN repository and some function to pin packages to the current version. Python pip To update all the packages from pip and pip itself I run: 12$ pip install --upgrade pip &amp;&amp; pip freeze --local | grep -v '^\\-e' | cut -d = -f 1  | xargs -n1 pip install -U$ pip3 install --upgrade pip &amp;&amp; pip3 freeze --local | grep -v '^-e' | cut -d = -f 1  | xargs -n1 pip3 install -UI took the idea from here. pip is the package manager for packages written in Python. You can read a little bit more on the Wikipedia. RubyGems RubyGems is a package manager for Gems that are packages written in Ruby language. Homebrew is written in Ruby and Jekyll too, the latter make use of several RubyGems for functionalities and extensions. To update the RubyGems you run the following command: 1$ gem updateApp Store and macOS software updates Although these ones are really easy and you can update them just using the Mac App Store app in your Mac, it’s possible to trigger the update checking and the update itself through CLI. macOS has a command that allow you to make this happen softwareupdate. You can run it like this: 123456$ softwareupdate -l ## to list all the updates$ softwareupdate -i ## to install updates$ softwareupdate -ia ## to install all updates$ softwareupdate -iR ## to automatically restart if necessary by the update$ softwareupdate -ir ## install only the recommended updates$ softwareupdate -d ## only download the updatesAs you see it’s quite thorough and you can see more options with running man softwareupdate. If you want something more complex you can install mas-cli, which is a Mac App Store command line interface. Install you just run: 1$ brew install masThen, you can run in your command line the following to update: 123456$ mas list ## List your Mac App Store apps$ mas search &lt;app&gt; ## Search for an app$ mas install &lt;app-number&gt; ## Install an specific app$ mas outdated ## shows the outdated apps$ mas upgrade ## Upgrade all your apps$ mas upgrade &lt;app-number&gt; ## Upgrade an specific app","categories": ["RStats","Technology"],
        "tags": ["app store","homebrew","packages","python","RStats","rubygems"],
        "url": "https://luisspuerto.net/blog/2018/03/22/updating-homebrew-r-and-python-pip-packages-ruby-gems-macos/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/Homebrew-R-Python-Ruby-macOS.png"},{
        "title": "R and Java 10",
        "excerpt":"Update 27th of March 2018 at 17.28 UTC+3: After talk a little bit on the R mail lists [1][2], it’s seems that it’s a know issue and they are on the way to fix this. Till them we have to stick to Java 9.0.4 to work with R. Update 4th of April 2018 at 17.55 UTC+3: The rJava author just fix this in an update that haven’t been fed to CRAN yet, bu you can install from source from his repo on rforge.net using the following command: 1install.packages('rJava', repos = 'http://rforge.net')Java 10 was just released a week ago on 20 March 2018 and I just updated to it using Homebrew Cask. However, I haven’t been able to make it work with R. As you know, I have a complete install of R with Homebrew, which I’m very happy with since it’s it easier to manage —in my opinion— and it’s faster. I would say also that R and Java are infamous for their bad relations and it’s not the first time that me and a whole bunch of people are driven nuts for not be able to configure it appropriately, even more in macOS. In the moment of writing this post I’m on R 3.4.4 on macOS 10.13.3 with Java 10 and 9.0.4 installed. First, I have to tell that I’m puzzle by something that it’s really intrigued, R CMD javarenconf and sudo R CMD javarendonf doesn’t yield the same result: 123456789101112131415161718192021222324$ R CMD javareconfJava interpreter : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javaJava version     : 10Java home path   : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/HomeJava compiler    : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javacJava headers gen.: /usr/bin/javahJava archive tool: /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/jarNon-system Java on macOStrying to compile and link a JNI programdetected JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwindetected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm/usr/local/opt/llvm/bin/clang  -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include/darwin  -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC  -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o conftest.o/usr/local/opt/llvm/bin/clang++ -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o conftest.so conftest.o -L/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/lib/server -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework -Wl,CoreFoundationJAVA_HOME        : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/HomeJava library path: $(JAVA_HOME)/lib/serverJNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwinJNI linker flags : -L$(JAVA_HOME)/lib/server -ljvmUpdating Java configuration in /usr/local/Cellar/r/3.4.4/lib/Roverride rw-r--r--  root/admin for /usr/local/Cellar/r/3.4.4/lib/R/etc/Makeconf? (y/n [n]) yoverride rw-r--r--  root/admin for /usr/local/Cellar/r/3.4.4/lib/R/etc/ldpaths? (y/n [n]) yDone.12345678910111213141516171819202122$ sudo R CMD javareconfJava interpreter : /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javaJava version     : 9.0.4Java home path   : /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/HomeJava compiler    : /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javacJava headers gen.: /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javahJava archive tool: /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/jarNon-system Java on macOStrying to compile and link a JNI programdetected JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwindetected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm/usr/local/opt/llvm/bin/clang  -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG -I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include/darwin  -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC  -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o conftest.o/usr/local/opt/llvm/bin/clang++ -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o conftest.so conftest.o -L/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/lib/server -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework -Wl,CoreFoundationJAVA_HOME        : /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/HomeJava library path: $(JAVA_HOME)/lib/serverJNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwinJNI linker flags : -L$(JAVA_HOME)/lib/server -ljvmUpdating Java configuration in /usr/local/Cellar/r/3.4.4/lib/RDone.I really don’t understand why… with root privileges it uses Java 9.0.4 and without it uses Java 10 and it’s not only my computer but all the rest of the Mac computers I have around, one of it with El Capitan instead of High Sierra. If you know why is like this please tell me. This problem has the consequence that if I choose Java 10 —or configure R with Java without root privileges— R and Java doesn’t behave properly. In other words, I’m not able to build rJava properly. 1234567891011121314151617181920212223warning: [options] bootstrap class path not set in conjunction with -source 6warning: [options] source value 6 is obsolete and will be removed in a future releasewarning: [options] target value 1.6 is obsolete and will be removed in a future releasewarning: [options] To suppress warnings about obsolete options, use -Xlint:-options.Note: Some input files use or override a deprecated API.Note: Recompile with -Xlint:deprecation for details.Note: Some input files use unchecked or unsafe operations.Note: Recompile with -Xlint:unchecked for details.4 warnings/usr/bin/javah -d . -classpath . org.rosuda.JRI.RengineUnable to locate an executable at \"/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah\" (-1)make[2]: *** [org_rosuda_JRI_Rengine.h] Error 2make[1]: *** [src/JRI.jar] Error 2make: *** [jri] Error 2ERROR: compilation failed for package ‘rJava’* removing ‘/Users/lpuerto/Library/R/3.x/library/rJava’* restoring previous ‘/Users/lpuerto/Library/R/3.x/library/rJava’The downloaded source packages are in    ‘/private/var/folders/wf/41gjf2mx7m7fmvfd8dr22_5h0000gn/T/RtmpT2kJMY/downloaded_packages’Warning message:In install.packages(\"rJava\", repos = \"cloud.r-project.org\") :  installation of package ‘rJava’ had non-zero exit statusIf we look closer to the error we can see that the source of the problem are, most probably, the highlighted lines —10 and 11— which mainly say javah can’t be found. I checked in /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/ and it’s true that there isn’t a javah there. However, if I go the the Java 10 release notes they mention:   tools/javah➜ JEP 313 Remove the Native-Header Generation Tool (javah)As previously announced, the native-header tool, javah, has been removed.Native headers can now be generated by using the Java compiler, javac, with the -h option.   See JDK-8182758 In other words, javah isn’t missing, they removed it on purpose. They stated there a way to create headers with Java, using the Java compiler, javac, with the -h option. I’ve tried to to parse the this when running R CMD javareconf as: 1234567891011121314151617181920212223$ R CMD javareconf JAVAH=\"/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javac -h\"/usr/local/Cellar/r/3.4.4/lib/R/bin/javareconf: line 66: -h: command not foundJava interpreter : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javaJava version     : 10Java home path   : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/HomeJava compiler    : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javacJava headers gen.: /usr/bin/javahJava archive tool: /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/jarNon-system Java on macOStrying to compile and link a JNI programdetected JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwindetected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm/usr/local/opt/llvm/bin/clang  -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include/darwin  -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC  -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o conftest.o/usr/local/opt/llvm/bin/clang++ -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o conftest.so conftest.o -L/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/lib/server -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework -Wl,CoreFoundationJAVA_HOME        : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/HomeJava library path: $(JAVA_HOME)/lib/serverJNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwinJNI linker flags : -L$(JAVA_HOME)/lib/server -ljvmUpdating Java configuration in /usr/local/Cellar/r/3.4.4/lib/RDone.But I haven’t succeeded since it’s using the /usr/bin/javah as the header generator, resulting again as an error when building rJava. Perhaps I’m not doing it right or it’s something more I should do. If you have any idea, you are more than welcomed. I’ve opened a question in stackoverflow and a issue in rJava. ","categories": ["RStats","Technology"],
        "tags": ["config","error","homebrew","java","RStats"],
        "url": "https://luisspuerto.net/blog/2018/03/28/r-and-java-10/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/Java10RError.jpg"},{
        "title": "MBP wakes up from sleep to back screen",
        "excerpt":"As you know, I have had problems with my old MacBook Pro Late 2011 and its dGPU which I’ve been able to patch to make the computer work again. In the beginning, the side effect of the fix was not to be able to wake up properly the Mac from sleep mode. The computer woke up to a black or grey screen and the fans started to work at full speed to finally turn off itself. This was cause because on the wake up process the computer decided to stuck to the faulty dGPU instead to the iGPU. Luckily, this problem was solve as you can see in the final fix. However, my Mac still wakes up to a black screen from time to time. This isn’t a new behavior at all, just happen to come up more often. Perhaps, in the past, this problem happened once per month or two months or even once every six months. Basically, the computer wakes up from sleep mode to a black screen that remains black no matter you do or what key you punch, while the computer seems to perfectly work in the dark. In this case, the fans don’t run at full speed and seems that the computer can stay like that for long. I haven’t tried, but I guess you can even log in remotely. If your Mac happen to have the iconic glowing apple in the lid you can put there a source of light —the flashlight of your smartphone for example— and you’ll probably be able to see the login screen —just the part around the Apple logo. Basically, what is going on in most of the cases, is the computer wakes up but it doesn’t turn on the blacklight of the screen for some reason. This is a quite a common problem on MacBooks and if you search on internet about it you are going to find multiple solutions. Till now, none of them has really worked for me, but if you have this problem perhaps some of them are going to work for your, so why not to give it a try. Reset SMC and PRAM/NVRAM This is the most common solution you are going to find our there since perhaps the problem is related to those basic configurations. Yet, in my case I can’t do that —or I rather not— because the solution for disable the dGPU of my MPB is partly a setting on the NVRAM, so if I reset it I need to reapply the whole thing again, or at least that. If you want to give it a try to can reset those settings with this directions:   SMC: shutdown, unplug everything except power, now hold leftShift + Ctrl + Opt/Alt + Power for about 10” and release at the same time.  PRAM/NVRAM: with the power cord on, power on and immediately later and before the chime hold cmd + Opt/Alt + P + R at the same time until you hear the chime for the second time.Making it sleep again Some people argue that the problem is related to the the lid itself that becomes a little bit faulty, either in the hinge or in the magnet, so it doesn’t send the proper signal to the computer to wake up when you open the lid. In in this camp I’ve seen like a couple of solutions. Try to log in and make it sleep again Since you computer seems to work properly but the screen if not receiving backlight, so it remains black, you can log in and command your computer to sleep again to reattempt to wake up properly this time. You can check if this is your case, if your lid’s Apple logo is not glowing chances are that the problem is just the backlight. You can put a source of light there —the flashlight of your smartphone, as suggested before— and see in you can spot the login screen. That means your computer is up and running perfectly. Then, you can type your password, log in and after that push the power button for just a couple of seconds —no more or you are going to turn off the computer and we are trying to avoid that. That we’re trying to accomplish here is to make to show up the power / shut down menu in macOS. If we’ve succeeded we can hit the S key next and your computer should sleep again.           macOS power / shut down menu  If your computer doesn’t go to sleep, don’t worry, mine either. I haven’t been able to make this solution yet a single time. Push the power button and close the lid When you see that your Mac doesn’t wake up in the correct way, one of the most obvious behaviors is close the lid again —like trying to make this a bad dream— and open again, to give another try. Also pushing buttons here and there, scape key —let me get out of this nightmare, I don’t want to lose my 150 pages document that I didn’t save before and I’ve been working the whole week when I sent the Mac to sleep— and the power button and go on and so for. That has worked for me in the past sometimes, not always. Sometimes the computer turned the screen on again and some others it just reboots. Some people say that the correct way to do this just push the power button and close the lid, to open it again after a couple of seconds. But I haven’t try this yet. I don’t remember if the times I’ve succeeded to be back to life the computer I’ve followed that sequence by any chance. Who knows!! Changing energy parameters Other solution I’ve read about is just change the way your Mac sleeps. You Mac can be sent to sleep in two ways, simple sleep or Safe Sleep —the last one is/was called hibernation in windows— so macOS has three different setups for sleeping —only simple sleep, only safe sleep or both. You can see your config using the command: 1234567891011121314151617181920212223242526272829303132$ sudo pmset -g custom  Battery Power:   lidwake              0   standbydelay         4200   standby              0   ttyskeepawake        1   hibernatemode        0   gpuswitch            1   hibernatefile        /var/vm/sleepimage   displaysleep         2   sleep                10   acwake               0   halfdim              1   sms                  1   lessbright           1   disksleep            10  AC Power:   lidwake              0   standbydelay         4200   standby              0   ttyskeepawake        1   hibernatemode        0   gpuswitch            1   hibernatefile        /var/vm/sleepimage   womp                 0   displaysleep         10   networkoversleep     0   sleep                0   acwake               0   halfdim              1   sms                  1   disksleep            10The variable that holds this setting is hibernatemode and  0 is simple sleep, 3 is both and 25 is just safe sleep. In essence what is going on here is:   Simple Sleep — `hibernatemode 0`: Your computer keeps all the info in the RAM and stops all the rest of the computer. The RAM still has power and if you happen to run our of battery —after quite long time— you lose everything —not really, but let’s be catastrophical and think in the worse picture. However, you usually you don’t let your Mac sleeping and unplugged for more than a week, do you? I think the battery in this state can last more than a week, let be conservative here. This mode is the quickest, and usually your Mac is sleeping just after a couple of seconds you close the lid.  Both — hibenatemode 3: This is the standard mode and how most of the MacBooks behave. When you close the lid the Mac just normally sleep, but before it’s going to save its state in the sleepimage. If it doesn’t run out of battery, it usually wakes up normally, from the info in the RAM and you continue working as usually. If it runs out of battery it’s going to switch to safe sleep before it loses power. In this case when you open the lid you have to push the power button and your Mac is going to recover from the sleepimage. This is the safest… since it’s redundant, but it’s is slower than just sleep. This in modern MacBooks with SSD is call Standby Mode, and instead of waiting till the total lost of power between 1 h or 3h —depending on the year model— it goes to safe sleep.  Safe Sleep — hibernatemode 25: This is the hibernation mode in windows, in other words, the computer saves everything to the sleepimage and them disconnect power from everything. This mode is also really safe, perhaps safer than the previous one for some people and cases, but it’s the slowest. Usually the sleep process is the same than in the previous one, but it’s always going to wake up from the sleepimage, regardless of it has run out of battery or not. So it’s going to take more or less time depending of the capacity of your machine to read the sleepimage.There is more info about the sleep modes here.           Waking up from safe sleep  Some people argue that the back screen problem is related to the sleep image or the hibernatemode 3, so you have two options, change to hibernatemode 0 —the one I have right now— or to hibernatemode 25. If the problem is in the sleepimage the obvious candidate is the zero mode, but I’ve tried it and I’ve just woken up to a back screen. On the other hand,  while I was trying to fix the dGPU problem I had set the 25 mode for long, but sometimes it also woke up to the back screen. So this isn’t working for me. To change the sleep behavior you can run the following commands 123456# Just sleep mode$ sudo pmset -a hibernationmode 0# Sleep mode + safe sleep$ sudo pmset -a hibernationmode 3# Just safe sleep$ sudo pmset -a hibernationmode 25-a is for all —when you are on power ac and battery— but you can specify different settings. -b for battery and -c wall power. If you decide to go for hibernatemode 0 you can also delete de sleepimage and sabe some space in your hard drive. 1$ sudo rm -f /var/vm/sleepimageThe lidwake (on test) Since some people say that the problem is related to the lid I’ve decided to change the way the computer wakes up. Instead of waking it up when I open the lid I going to wake up it pushing a key after opening the lid. You can achieve this changing the lidwake parameter to 0: 1$ sudo pmset -a lidwake 0The normal value is 1. Let’s see how this pan out and I’m able to stop the back screen wake up. Final thoughts The issue isn’t incredible problematic, even more right now that in modern system is really difficult to lose data because a force reboot. However, isn’t a normal behavior and is something that Apple should take a look to it. Seems that the problem extents across several generation of Macs and for some people has become more acute with High Sierra. Perhaps this is my case, but I don’t really know. I’ve installed High Sierra around beginning of November and in the beginning of December my dGPU crashed. So it’s difficult for me if this behavior has increased due to the crash, due to High Sierra or just because my Mac is old. ","categories": ["Personal","Technology"],
        "tags": ["dGPU","high sierra","macOS"],
        "url": "https://luisspuerto.net/blog/2018/04/13/mbp-wakes-up-from-sleep-to-back-screen/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/apple-wake-up.jpg"},{
        "title": "R 3.5 \"Joy in Playing\"",
        "excerpt":"          The joy is (in the) playing  Last Monday, 23rd of April, R was updated to its version 3.5, codenamed The Joy in Playing, which as the rest of the releases, make reference to a Peanuts’ cartoon. Since it’s a minor release (3.x) and not just a patch, it’s advisable to reinstall all your packages, in some cases, to make then work properly. For example, and in my case, since I’ve built all of them as a consequence of my Homebrew install, some of them where throwing me the following message 1Error: package ‘XXXXXXXXXXX’ was installed by an R version with different internals; it needs to be reinstalled for use with this R versionSo, to reinstall all the packages that haven’t been build for your current R build, you can run the following command. (Be careful, rebuild all your packages could take time and resources, so it’s recommendable to do it at some moment that you aren’t using your machine) 1update.packages(ask = F, repos = 'cloud.r-project.org', checkBuild = T)I would recommend to run it twice, since some packages have dependencies and they need to be installed first and I don’t know if the command follows a specific installation order to avoid this errors like this —in other words, if the dependencies aren’t installed first to this specific release, the installation is going to fail. It doesn’t hurt to run the command again since if all the packages were rebuilt with the current R version they aren’t going to be reinstalled. Java and rJava configuration In some of my machines I hadn’t configured the new Java 10 with the prerelease rJava so Java 10 can be run properly in R. If this is your case remember to run: 1$ R CMD javareconfso you yield something similar to: 1234567891011121314151617181920Java interpreter : /Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/Home/bin/javaJava version     : 10.0.1Java home path   : /Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/HomeJava compiler    : /Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/Home/bin/javacJava headers gen.: /usr/bin/javahJava archive tool: /Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/Home/bin/jartrying to compile and link a JNI programdetected JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwindetected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm/usr/local/opt/llvm/bin/clang  -I\"/usr/local/Cellar/r/3.5.0/lib/R/include\" -DNDEBUG -I/Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/Home/include/darwin  -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC  -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o conftest.o/usr/local/opt/llvm/bin/clang -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/Cellar/r/3.5.0/lib/R/lib -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o conftest.so conftest.o -L/Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/Home/lib/server -ljvm -L/usr/local/Cellar/r/3.5.0/lib/R/lib -lR -lintl -Wl,-framework -Wl,CoreFoundationJAVA_HOME        : /Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/HomeJava library path: $(JAVA_HOME)/lib/serverJNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwinJNI linker flags : -L$(JAVA_HOME)/lib/server -ljvmUpdating Java configuration in /usr/local/Cellar/r/3.5.0/lib/RDone.So you can install / build rJava prerelease with the following command 1install.packages('rJava', repos = 'http://rforge.net')devEMF In another machine I wasn’t being able to install devEMF package. You can see the specific error I was getting in this Stack Overflow question. The problem was the makevars file, which is crafted to use the LLVM. I commented all of the lines to build the package and all set. Seems that for some reason LLVM isn’t supported to build this package in this version of R (or it isn’t supported at all). 12345678# Remove the comment on -fopenmp for compiling data.table packag`akevars\"&gt;# Remove the comment on -fopenmp for compiling data.table packagakevars\"&gt;# Remove the comment on -fopenmp for compiling data.table packag`e# CC=/usr/local/opt/llvm/bin/clang #-fopenmp# CXX=/usr/local/opt/llvm/bin/clang++ #-fopenmp# -O3 should be faster than -O2 (default) level optimisation ..# CFLAGS=-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe# CXXFLAGS=-g -O3 -Wall -pedantic -std=c++11 -mtune=native -pipe# LDFLAGS=-L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib# CPPFLAGS=-I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/includeRemember to uncomment them after you finish the build. 12345678# Remove the comment on -fopenmp for compiling data.table packageCC=/usr/local/opt/llvm/bin/clang #-fopenmpCXX=/usr/local/opt/llvm/bin/clang++ #-fopenmp# -O3 should be faster than -O2 (default) level optimisation ..CFLAGS=-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipeCXXFLAGS=-g -O3 -Wall -pedantic -std=c++11 -mtune=native -pipeLDFLAGS=-L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/libCPPFLAGS=-I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/includedata.table Don’t forget that data.table package has also specific makevars necessities if you are building it, as you should, with LLVM. Remember that the flag -fopenmp has to be present / uncommented in the lines related to C and C++ compilers. 12CC=/usr/local/opt/llvm/bin/clang -fopenmpCXX=/usr/local/opt/llvm/bin/clang++ -fopenmpRemember to re-comment or delete the -fopenmp after you build data.table. ","categories": ["Professional","RStats","Technology"],
        "tags": ["homebrew","how to","RSoft","RStats"],
        "url": "https://luisspuerto.net/blog/2018/04/28/r-3-5-joy-in-playing/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/4421de17ce2dc4cd3843ba00b224fbe0-header.jpeg"},{
        "title": "The ciabatta recipe",
        "excerpt":"Lately I’ve been extending my baking skills and I’ve been practicing the ciabatta recipe from Iban Yarza’s book, Pan Casero, which I think is delicious. I say extending my baking skills because it’s the first time I’ve tried a preferment recipe and more specifically poolish. Poolish have zero complications in comparison with the straight doughs, but it’s true that in general you need extra time and the final dough is more sticky since it’s more moisturized. So you are going to need to have some experience working with dough if you don’t want to end up full of dough and even, depending how brave you are, your kitchen. What you are going to need for this recipe is the same as with the previous ones, plus a tray or container to handle the dough after we finish the kneading. I recommend to review the preliminaries for baking post for a full description of the methods. Take into account that the amount of yeast is specify for 12, 8 and 3 hours for the bulk fermentation of the poolish. On top of that you are going to need around 2 hours of mixing — kneading — proofing ** after the polish is ready, plus the usually **40-50’ of baking. Ingredients For the poolish   Flour: 450 gr (60%).  Water: 450 gr (60%).  Yeast: 1 to 7 gr of fresh yeast (see below) depending on how much we want to leave the poolish resting — fermenting.          0.9 gr for 12 hour fermentation (0.12%).      3 gr for 8 hour fermentation (0.4%).      7 gr for 3 hours fermentation (0.93%).      For the final dough   Poolish: 900 gr (60%).  Flour: 300 gr of flour (100% = 60% from poolish + 40% from the final dough)  Water: 120 gr of water (76% = 60% from poolish + 16% from the final dough)  Salt: 15 gr of salt (2%)As you probably have noted the proportions are a little bit weir, this is because, as always, they are the percentage of the full amount of flour. So, if we want to end up with a 750 gr. of bread —in this case two loaves of ~375 gr.— you need the 60% of flour for the poolish and the same amount of water. From there on, you have to complete the quantities for the final dough. Directions   You measure 450 gr. of flour and put into a bowl at least the double and preferably the triple of that volume.  Measure 450 gr. of warm water (37 ºC) and mix it with the yeast. When dissolved, pour into the flour and mix it, with a spoon if you want, until homogenous.  When the mixture has double the volume (in 3, 8 or 12 hours) pour the 300 gr. flour, 120 gr. of water and the 15 gr. of salt in the poolish and mix everything with your hands using the pincer method. Be aware that the dough is really sticky, so have at hand a spoon to clean your hand when you are done.  Now you have two options, you can take the dough out of the bowl and use the French kneading method for 10’ or you can take the easy way and practice the folding like 5-6 times every 10’ for the next 30’. The aim here is to develop the gluten so the dough doesn’t just flat out in the oven tray and it’s able to rise. If you don’t have experience with the French kneading I just recommend you to leave the dough in the bowl and practice the folding. A great way to avoid the dough to sticks to your hand is set it like a paddle —put your fingers tight together— and dip it in cold water before you begin to fold every 10’. I usually go a little bit the extra mile and I do the first folding repetition extra long and fold the dough for about 5’ minutes.  After you’ve developed the gluten you take out the dough from the bowl and set in on a tray where you’ve spread olive oil so the dough doesn’t stick to it. There you fold it like a small package using the 4 sides and turn it over with the seam downwards for 30’.  After 30’ you repeat the operation, fold again like a small package using the 4 sides and turn it over, but this time let it rest for an hour.          Poolish fermenting and dough resting  At this point you could think to preheat the oven to 250 ºC so it’s ready after an hour. Remember to put a container with water inside so there is humidity when you introduce the bread. Preheat the oven tray too.   After an hour you take the dough out of the tray / container —genteelly so you don’t ruin the air pockets— and put in the counter where you have sprinkle some flour. You can cut the dough in half longwise so you end up with a couple of strips of dough that are like a small mattresses.  Now, you take the tray out of the oven and put parchment paper over it —without burn yourself— and after that you put the two stripes of dough.  Bake them in the oven for about 20’ and remove the water.  You can reduce a little bit the temperature now to around 230 ºC and bake for another 10’.          Loaves in the oven    After 10’ I usually turn around the loaves so they get well baked on the bottom and bake for another 10’.  Finally, turn off the oven and open the door a little bit leaving the bread there for an additional 10’.  Take the loaves out and let them rest over the rack for at least half an hour.  Enjoy your ciabatta.","categories": ["Personal","Recipes"],
        "tags": ["bread","how to"],
        "url": "https://luisspuerto.net/blog/2018/04/29/the-ciabatta-recipe/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/IMG_5302.jpg"},{
        "title": "MBP wakes up from sleep to back screen —  Solution",
        "excerpt":"A couple of weeks ago I wrote about the problem I have with my old MacBook Pro wakening from sleeping to a black screen. I also pointed out that I was testing a solution related to the lid. I can tell that since I’ve testing this solution I haven’t suffered any wake up to a black screen, so I guess that the problem is related to the lid, either to the hinge or to the magnet that trigger the wake up and the sleep processes. I’m doing two things to prevent the black screen behavior. First I’m sleeping the computer using the command line: 1$ sudo shutdown -s nowI’ve also change the hibernation mode of the machine to zero, in other words, it doesn’t save the state in a file in the hard drive. I’ve also deleted that file from my hard drive. 1$ sudo rm -f /var/vm/sleepimageFinally I’ve disable the options to wake up the computer when you connect to power source and when you open the lid. 1$ sudo pmset -a lidwake 0So, now to wake up the computer I have to hit any key on the computer keyboard or the trackpad after I’ve open the lid. So far it has been working great. ","categories": ["Technology"],
        "tags": ["dGPU","high sierra","macOS"],
        "url": "https://luisspuerto.net/blog/2018/05/02/mbp-wakes-up-from-sleep-to-back-screen-solution/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/apple-wake-up.jpg"},{
        "title": "Homebrew's R doesn't have all the capabilities",
        "excerpt":"A couple of days ago I just found out that when you install R with Homebrew you don’t get all the capabilities that the binary from CRAN have. In other words, you have a kind of second class install, in some regards, and depending on how you do install and for what you are going to use R. 12345678 &gt;capabilities()       jpeg         png        tiff       tcltk         X11        aqua      FALSE       FALSE       FALSE       FALSE       FALSE        TRUE   http/ftp     sockets      libxml        fifo      cledit       iconv       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE        NLS     profmem       cairo         ICU long.double     libcurl       TRUE        TRUE       FALSE        TRUE        TRUE        TRUE1234567&gt;capabilities()       jpeg         png        tiff       tcltk         X11        aqua       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE   http/ftp     sockets      libxml        fifo      cledit       iconv       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE        NLS     profmem       cairo         ICU long.double     libcurl       TRUE        TRUE        TRUE        TRUE        TRUE        TRUEHow did I notice? Well basically I was about to update the sm package in one of my computers and R yield an error similar to this one (sorry I didn’t copy the original one): 123456Error: package or namespace load failed for ‘tcltk’: .onLoad failed in loadNamespace() for 'tcltk', details:  call: fun(libname, pkgname)  error: Tcl/Tk support is not available on this systemIn addition: Warning message:S3 methods ‘as.character.tclObj’, ‘as.character.tclVar’, ‘as.double.tclObj’, ‘as.integer.tclObj’, ‘as.logical.tclObj’, ‘as.raw.tclObj’, ‘print.tclObj’, ‘[[.tclArray’, ‘[[&lt;-.tclArray’, ‘$.tclArray’, ‘$&lt;-.tclArray’, ‘names.tclArray’, ‘names&lt;-.tclArray’, ‘length.tclArray’, ‘length&lt;-.tclArray’, ‘tclObj.tclVar’, ‘tclObj&lt;-.tclVar’, ‘tclvalue.default’, ‘tclvalue.tclObj’, ‘tclvalue.tclVar’, ‘tclvalue&lt;-.default’, ‘tclvalue&lt;-.tclVar’, ‘close.tkProgressBar’ were declared in NAMESPACE but not foundAs you can see I’ve highlighted the key line, R doesn’t have tcltk available and running in that system and if you run capabilities() in the R console you’ll probably get something similar to the first code-block. After researching a little bit about the problem [1 &amp; 2], I found out what I’ve already said, Homebrew R isn’t build with those capabilities. Why? Well…   It seems that those capabilities are optional when you build R from source and build R with those capabilities / options on Homebrew’s bottle server is “error prone”.  To have some of the missing capabilities you must have in your system X11/XQuartz, which isn’t installed in every Mac, because it’s not longer provided as macOS basic installation.  You can install X11/XQuartz, but you have to do it with Homebrew Cask, since it can’t be build from source. As a consequence is a off project dependency and they don’t want to rely on that.  Homebrew seems to be heading to a option-less direction where the formulas aren’t going to have any option at all. So if you want to have options or different kind of build they encourage you to have your own tap.Whether you agree or not, you have to understand that the maintainers of Homebrew-core took this direction for a reason, which is probably they have already too much work to do. Don’t forget they maintain the package manager for free. If you disagree, as I do, at least partly, please be polite. A lot of users have been expressing their disagreement in really bad manners lately and that is not acceptable. Lucky for us users, there is a solution to the problem. You can always create your own tap of Homebrew and tweak the formula to fit your needs, as maintainers suggest. As a result someone already did that and there is already a tap which you can install R with the same formula we installed R when it was in Homebrew Science, but up to day. I’ll explain in my next post how to install R using that tap. ","categories": ["Professional","RStats","Technology"],
        "tags": ["homebrew","RSoft","RStats"],
        "url": "https://luisspuerto.net/blog/2018/05/11/homebrews-r-doesnt-have-all-the-capabilities/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/R-Homebrew.jpg"},{
        "title": "Installing R with Homebrew with all the capabilities",
        "excerpt":"As I explained in my previous post if you installed R with Homebrew you have less capabilities than with a R installed from CRAN’s binary. But, can you have all the capabilities while you still use Homebrew to install R? Yes! However… why you bother to install it with Homebrew at all instead of installing it from CRAN. Well, it’s true that CRAN install it’s easier. You just have to download the binary and that’s it. You can even use Homebrew Cask to install R that way 1$ brew cask install r-appHowever, if you install that way you can’t take advantage of OpenBlas and OpenMP which really enhance the speed of R processing. Well, you can take advantage of OpenMP with CRAN install if you use the coatless professor method. Getting all the capabilities To make this possible we are going to install/reinstall R, and Cairo, with the formulae Seth Fore has in his tap, sethrfore/homebrew-r-srf. These formulae are basically the same on brewsci/homebrew-science, which is a legacy tap (no longer updated), which we all were using to install R with Homebrew before they merge everything to Core. Seth updated both formulae for us, so we can enjoy the last version of R and Cairo while not loosing any capability. You also have to remember that this instructions are just aimed to reinstall R if you have follow my previous instructions to have a 100% R install with Homebrew. And they would replace this section. The first thing you have to do is uninstall R and Cairo if you have them installed: 12$ brew uninstall R$ brew uninstall --ignore-dependencies cairoIf you have Cairo installed, it’s going to protest about dependencies, but don’t worry and we are just going to reinstall it in a minute. When you don’t have R and Cairo in your system you can go ahead. You begin tapping Seth’s tap. 1$ brew tap sethrfore/r-srfActually, you can avoid this step since Seth’s formulae have the same name as Homebrew Core’s one we are forced to install them using the full name of the tap in combination with the formula name. If you don’t have Xquartz already installed in your system you can install with: 1$ brew cask install xquartzNow, you can install Cairo. 1$ brew install sethrfore/r-srf/cairoWhen Cairo finish to build you can proceed with R. 1$ brew install sethrfore/r-srf/r --with-openblas --with-java --with-cairo --with-libtiff --with-pangoTo use the Pango flag --with-pango you must have installed in your system Pango brew install pango. When it end to build, you can use use capabilities() in R console and you have to get something like this: 1234567&gt;capabilities()       jpeg         png        tiff       tcltk         X11        aqua       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE   http/ftp     sockets      libxml        fifo      cledit       iconv       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE        NLS     profmem       cairo         ICU long.double     libcurl       TRUE        TRUE        TRUE        TRUE        TRUE        TRUETo finish I would run: 12345678910111213141516171819202122$ R CMD javareconfJava interpreter : /Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/bin/javaJava version     : 10.0.2Java home path   : /Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/HomeJava compiler    : /Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/bin/javacJava headers gen.: /usr/bin/javahJava archive tool: /Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/bin/jartrying to compile and link a JNI programdetected JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwindetected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm/usr/local/opt/llvm/bin/clang  -I\"/usr/local/Cellar/r/3.5.1/lib/R/include\" -DNDEBUG -I/Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/include/darwin  -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC  -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o conftest.o/usr/local/opt/llvm/bin/clang -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/Cellar/r/3.5.1/lib/R/lib -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o conftest.so conftest.o -L/Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/Home/lib/server -ljvm -L/usr/local/Cellar/r/3.5.1/lib/R/lib -lR -lintl -Wl,-framework -Wl,CoreFoundationld: warning: text-based stub file /System/Library/Frameworks//CoreFoundation.framework/CoreFoundation.tbd and library file /System/Library/Frameworks//CoreFoundation.framework/CoreFoundation are out of sync. Falling back to library file for linking.JAVA_HOME        : /Library/Java/JavaVirtualMachines/jdk-10.0.2.jdk/Contents/HomeJava library path: $(JAVA_HOME)/lib/serverJNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwinJNI linker flags : -L$(JAVA_HOME)/lib/server -ljvmUpdating Java configuration in /usr/local/Cellar/r/3.5.1/lib/RDone.To reconfigure Java on R, just in case. ","categories": ["Professional","RStats","Technology"],
        "tags": ["homebrew","how to","RSoft","RStats"],
        "url": "https://luisspuerto.net/blog/2018/05/11/installing-r-with-homebrew-with-all-the-capabilities/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/R-Homebrew.jpg"},{
        "title": "16 Personalities: Apparently I'm an Entrepreneur",
        "excerpt":"Not long ago, while I was taking a course in Finland, they asked us to take a personality test online called 16 personalities. It wasn’t nothing really official or for much purpose of scrutinize us, but just to know ourselves a little bit more and we can work our strengths and weakness. To my surprise, the test told me that I have an entrepreneurial personality. I never thought about myself in that regard, and in the beginning I thought that it was a lot of bulls**t, like most the so-call psychological test. However, after reading more or less thoroughly over the description I found that I have a lot in common with an entrepreneurial personality. Or at least, my subconscious persona wants to be an entrepreneur. After all, who don’t want to be an entrepreneur these days and start dozen and dozen of companies? be in command, executive and decided? produce something new and exciting everyday, fill with technology with all the bells and whistles? Be part of that breed of people always in the verge of society… When we think in entrepreneurs it comes to our mind people like, Steve Jobs, Sergey Bin and Larry Page, Henry Ford, and dozen of other people that begin to build something in their house’s —or parent’s— garage. It’s funny, because I just finish reading Rework and Remote, where the authors talk about the term entrepreneur as “an outdated and loaded with baggage” one. Some kind of a “members-only club”. They argue that there are a lot of people out there starting new business, who aren’t calling themselves entrepreneurs because they are just doing what they love. So they advocate for a new term… let’s just call them starters. And I kind of agree with them that the term entrepreneur is a term stale and overused, which a lot of people use with pride trying distance from others. Like if they had some kind of pedigree. Something I don’t like at all. But let’s return to the personality test, as they explain in the Our Theory / Our Framework section of the web, they are using the Myers—Briggs Type Indicator —which is an evolution of Carl Jung’s Phycological Types— with the addition of the Big Five personality traits model as an analytical base. They also, of course, add algorithms, models and theories from their own vintage. I’m not a psychologist, a sociologist, or any of the sort, so I can’t, by any means, build an educated critic or something similar. I just can tell you that while reading the profile I was indeed feeling that some parts were related to me, or described myself in some way, but in others it was totally not. Also, I noticed, that while not totally true or untrue, some of the descriptions were appealing, in the sense that if I’m not like that, I would like to be.           General idea of what it seems I’m  If you check the introduction of my profile, they say that I’m an entrepreneur with a role of an explorer and with a strategy of people mastery. It’s funny because I’ve always considered myself an explorer, I always enjoy wondering, and wandering, discovering new places and new people and trying new things. In fact, lately I’m consider the word try by favorite word. Perhaps for that reason I’ve always loved maps —they help you reach new places and imagine. However, I never considered myself a social person or people master. When I was a child I was always really shy, buy my mother always encourage talk to people and be myself. She, on the other hand, has been always a really sociable person and really outspoken, even when she was a child. Perhaps, that is something I have inside of me. They also consider that I’m have a 78% extraverted, 58% observant, 58% thinking, 51% prospecting and 76% assertive personality. As you see, I only have two trails really clearly sided, while in the other three I’m quite balance. These should be translated as that I’m clearly extraverted, so “I usually prefer to be group activities”, and clearly assertive, in other words, I’m self-assured, even-tempered and resistant to stress, and I usually don’t worry too much, but I don’t puss myself too much when I have to archive goals. Both of those trails are true or at least I feel they are true. In relation to the other three. I’m mostly observant (58%), which means I’m really practical, pragmatical and down-to-earch person, focussing in what is happening or has happened. Yet, since I’m not clearly observant I’m also somehow an intuitive (42%) person really interested in ideas and novelty. I’m mainly a thinking individual (53%), in other words, I focus on objectivity and rationality, prioritizing logic over emotions. However, I’m also a feeling being (47%) and I listen to my feelings and like to share with others, preferring cooperation over competition. Finally, I’m a prospecting person (52%) so I’m good at improvising and spotting opportunities, tending to be a flexible, relaxed nonconformists person who prefer keep my options open. Nevertheless, it also means I have a judging (49%) personality and in consequence I’m good planner, like clarity and I have a strong work ethic. Of course things are a little bit more complicated than that and I plan to explain then a little bit further in the following days in a couple of posts. Why? Because I’ve always believed that openness, sharing who you are with others and be ready for assessment, make you always a better person. I’m always ready to upgrade to a better version of myself and I believe that I’m always doing so. I think it could feel into the definition of Peter Senge, Personal Mastery1. Nonetheless, I don’t want to take this kind of test too seriously since all of them are usually fundamentally flawed. You are the one judging yourself —which is clearly biased and has it drawbacks— and sometimes the language is something like the horoscope, always fit you no matter who reads it —Oh! I’m this, and this too, and of course this one.             Personal Mastery is define by Senge as: the discipline of continually clarifying and deepening our personal vision, of focusing our energies, of developing patience, and of seeing reality objectively. From The Fifth Discipline. &#8617;       ","categories": ["Personal","Professional"],
        "tags": ["I'm the entrepreneur","science","work"],
        "url": "https://luisspuerto.net/blog/2018/05/21/16-personalities-apparently-im-an-entrepreneur/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/Luis-Puerto-The-Entreprenour2.jpg"},{
        "title": "New Web in Jekyll",
        "excerpt":"As you probably have noticed, some days ago I rolled out a new version of my website, which you probably think it’s pretty similar to the previous one, at least talking about its external appearance. However, it’s really different in the inside, since it’s a static web build with Jekyll, while the previous one was build on Wordpress. This isn’t a change that occurred to me just out of the blue and some moths ago I made a post about Jekyll where I stated my desire to change to Jekyll, or at least to try,  for several important reasons, being the main ones cost and simplicity. Although building a simple site in Jekyll it’s really straightforward and simple, make a transition from Wordpress to Jekyll has more “curves” on the way than you would expect. Even more when I was trying to mimic my original website as much as possible. I used a Wordpress to Jekyll exporter and although the export was smooth, some of the post had the format messed up and I had to edit them manually. It took me a solid month to have everything more or less ready in a decent way.           luisspuerto.net at 23rd July 2018  Right now, the site is up and running —as you can see— but there are some missing features. I have a TODO list where I’m trying to track down all those features I want to implement and the pending changes I want to make. Some are improvements from the previous version but most of them are missing features that are not implemented in Jekyll right away or they are really basic as you take your Jekyll site out of the box. These shortcomings are usually related to the fact I’m hosting the web in GitHub Pages, which is free, but you have some missing features since they build your page in --safe mode. So, you can’t use custom plugins1. Yet Jekyll provides an archive, categories and tags out of the box, those features aren’t as nice as those provided by a dynamic site. For instance, you need to create yourself the those pages —which isn’t really a problem— but then you need to create manually the pages for each category and tag a page you want to show. However, if you use a plugin like Jekyll Archives all the process is much nicer and the plugin build the all the tag and category pages for you. As you can see right now, I don’t even have an archive page and I’m relying in a paginated chronological archive, what, at this moment, is more than enough. There are a couple of ways to overcome the shortcomings of GitHub pages if you really want to use custom plugins. The first and most obvious one is to build your site locally every time you make a change and then you push it _site folder to GitHub. From there on, you can go the extra mile and make everything automatically in the server side, whether you use a Continuous Integration service or you use somethings more complex like Netlify or others2. I’ll probably try to implement the Travis CI method and then research other more sophisticated ways to deploy. I’m taking this as a way of learning about Jekyll platform —liquid— html, css and a little bit of other things like javascript and ruby —ruby looks like a really useful language that I would love to learn in the future. Even I improve my Git skills since to publish in Jekyll you need to push. I wanted to roll out the site before it was fully finished because I find interesting to share how I finish to build the site. I really think we live in a society where we are too fixated on the final product but usually we don’t share how we arrive to it, something that sometimes it’s even more important. This particular idea is one of the characteristics I like the most from Git and GitHub, and all other repo hostings. You can share all the changes with others and understand how and why to reached the final “product”. I hope you enjoy also “the way”, most of the times as satisfying as “the end”.             You can see a list of the allowed plugins here. &#8617;               There are several other services besides the ones explained in the Jekyll documentation. If you research a little bit you are going to find several more options. Jenkins seems also to be able to build Jekyll. &#8617;       ","categories": ["Personal","Technology"],
        "tags": ["jekyll","blogging","coding","markdown","static web"],
        "url": "https://luisspuerto.net/blog/2018/07/23/new-web-in-jekyll/",
        "teaser":"https://luisspuerto.net/assets/images/blog/2018/jekyll.png"}]
